{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter tuning for neural network\n",
    "\n",
    "> Back Propagation Implementation - December 2024\n",
    ">\n",
    "> *Andrea Pujals Bocero*\n",
    ">\n",
    "> NEC First Assignment - Universitat Rovira i Virgili\n",
    "\n",
    "This notebook explores different combinations of hyperparameters to identify the best configuration for a neural network. \n",
    "We will evaluate at least 10 combinations of the following hyperparameters:\n",
    "\n",
    "- **Number of layers**\n",
    "- **Layer structure**\n",
    "- **Number of epochs**\n",
    "- **Learning rate**\n",
    "- **Momentum**\n",
    "- **Activation function**\n",
    "\n",
    "Metrics evaluated:\n",
    "- **Mean Absolute Percentage Error (MAPE)**\n",
    "- **Mean Absolute Error (MAE)**\n",
    "- **Mean Squared Error (MSE)**\n",
    "\n",
    "Plots included:\n",
    "- Scatter plots of predicted vs true values for representative combinations.\n",
    "- Training and validation loss evolution over epochs.\n"
   ],
   "id": "cfe1b2958f493ac7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T09:54:34.913995Z",
     "start_time": "2024-12-05T09:54:34.904122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from models.NeuralNet import NeuralNet  # Import my neural network implementation\n",
    "import itertools"
   ],
   "id": "435fa92d04938c4c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T09:54:48.631539Z",
     "start_time": "2024-12-05T09:54:48.603023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#read and parse the .csv features file for A1-turbine normalized data\n",
    "df = pd.read_csv('A1-synthetic.csv', decimal=\".\")\n",
    "df.describe()"
   ],
   "id": "84eb0aaa71a26d06",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                v1           v2           v3           v4           v5  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.968392    11.005370     0.511468     2.417192   100.108795   \n",
       "std      28.418028     0.584090     0.283292     1.147284     4.893623   \n",
       "min     -49.942910    10.000103     0.000147     1.002395    85.147019   \n",
       "25%     -23.938244    10.510135     0.267591     1.258367    96.934414   \n",
       "50%       2.852507    10.990934     0.515436     3.042135    99.920497   \n",
       "75%      25.494062    11.517569     0.757415     3.498211   103.482385   \n",
       "max      49.889593    11.999189     0.999727     3.999776   116.239538   \n",
       "\n",
       "                v6           v7           v8           v9            z  \n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
       "mean      2.726705    78.148504     0.313000    13.868300     6.367773  \n",
       "std       0.275193     5.016537     0.463946     3.253272     3.841009  \n",
       "min       1.974029    62.554174     0.000000    10.100000    -0.791114  \n",
       "25%       2.540117    74.814175     0.000000    10.861926     3.124304  \n",
       "50%       2.710712    78.101481     0.000000    13.089869     5.665139  \n",
       "75%       2.902578    81.604561     1.000000    16.366096     9.260205  \n",
       "max       3.600914    94.502170     1.000000    22.033951    16.080230  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.968392</td>\n",
       "      <td>11.005370</td>\n",
       "      <td>0.511468</td>\n",
       "      <td>2.417192</td>\n",
       "      <td>100.108795</td>\n",
       "      <td>2.726705</td>\n",
       "      <td>78.148504</td>\n",
       "      <td>0.313000</td>\n",
       "      <td>13.868300</td>\n",
       "      <td>6.367773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.418028</td>\n",
       "      <td>0.584090</td>\n",
       "      <td>0.283292</td>\n",
       "      <td>1.147284</td>\n",
       "      <td>4.893623</td>\n",
       "      <td>0.275193</td>\n",
       "      <td>5.016537</td>\n",
       "      <td>0.463946</td>\n",
       "      <td>3.253272</td>\n",
       "      <td>3.841009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-49.942910</td>\n",
       "      <td>10.000103</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>1.002395</td>\n",
       "      <td>85.147019</td>\n",
       "      <td>1.974029</td>\n",
       "      <td>62.554174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>-0.791114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-23.938244</td>\n",
       "      <td>10.510135</td>\n",
       "      <td>0.267591</td>\n",
       "      <td>1.258367</td>\n",
       "      <td>96.934414</td>\n",
       "      <td>2.540117</td>\n",
       "      <td>74.814175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.861926</td>\n",
       "      <td>3.124304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.852507</td>\n",
       "      <td>10.990934</td>\n",
       "      <td>0.515436</td>\n",
       "      <td>3.042135</td>\n",
       "      <td>99.920497</td>\n",
       "      <td>2.710712</td>\n",
       "      <td>78.101481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.089869</td>\n",
       "      <td>5.665139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.494062</td>\n",
       "      <td>11.517569</td>\n",
       "      <td>0.757415</td>\n",
       "      <td>3.498211</td>\n",
       "      <td>103.482385</td>\n",
       "      <td>2.902578</td>\n",
       "      <td>81.604561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.366096</td>\n",
       "      <td>9.260205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49.889593</td>\n",
       "      <td>11.999189</td>\n",
       "      <td>0.999727</td>\n",
       "      <td>3.999776</td>\n",
       "      <td>116.239538</td>\n",
       "      <td>3.600914</td>\n",
       "      <td>94.502170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.033951</td>\n",
       "      <td>16.080230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T09:54:51.097627Z",
     "start_time": "2024-12-05T09:54:51.022190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df_scaled.describe()"
   ],
   "id": "455b1d9e503e36fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                v1           v2           v3           v4           v5  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.509967     0.502863     0.511535     0.472011     0.481202   \n",
       "std       0.284657     0.292178     0.283411     0.382762     0.157389   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.260483     0.255133     0.267556     0.085399     0.379107   \n",
       "50%       0.528840     0.495642     0.515506     0.680507     0.475146   \n",
       "75%       0.755635     0.759080     0.757586     0.832666     0.589703   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                v6           v7           v8           v9            z  \n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
       "mean      0.462648     0.488116     0.313000     0.315763     0.424322  \n",
       "std       0.169153     0.157022     0.463946     0.272606     0.227665  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.347958     0.383749     0.000000     0.063845     0.232075  \n",
       "50%       0.452818     0.486644     0.000000     0.250535     0.382676  \n",
       "75%       0.570753     0.596294     1.000000     0.525065     0.595763  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.509967</td>\n",
       "      <td>0.502863</td>\n",
       "      <td>0.511535</td>\n",
       "      <td>0.472011</td>\n",
       "      <td>0.481202</td>\n",
       "      <td>0.462648</td>\n",
       "      <td>0.488116</td>\n",
       "      <td>0.313000</td>\n",
       "      <td>0.315763</td>\n",
       "      <td>0.424322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.284657</td>\n",
       "      <td>0.292178</td>\n",
       "      <td>0.283411</td>\n",
       "      <td>0.382762</td>\n",
       "      <td>0.157389</td>\n",
       "      <td>0.169153</td>\n",
       "      <td>0.157022</td>\n",
       "      <td>0.463946</td>\n",
       "      <td>0.272606</td>\n",
       "      <td>0.227665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.260483</td>\n",
       "      <td>0.255133</td>\n",
       "      <td>0.267556</td>\n",
       "      <td>0.085399</td>\n",
       "      <td>0.379107</td>\n",
       "      <td>0.347958</td>\n",
       "      <td>0.383749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063845</td>\n",
       "      <td>0.232075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.528840</td>\n",
       "      <td>0.495642</td>\n",
       "      <td>0.515506</td>\n",
       "      <td>0.680507</td>\n",
       "      <td>0.475146</td>\n",
       "      <td>0.452818</td>\n",
       "      <td>0.486644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250535</td>\n",
       "      <td>0.382676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.755635</td>\n",
       "      <td>0.759080</td>\n",
       "      <td>0.757586</td>\n",
       "      <td>0.832666</td>\n",
       "      <td>0.589703</td>\n",
       "      <td>0.570753</td>\n",
       "      <td>0.596294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.525065</td>\n",
       "      <td>0.595763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T09:54:52.762040Z",
     "start_time": "2024-12-05T09:54:52.743739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns = df_scaled.shape[1]\n",
    "\n",
    "input_columns = df_scaled.columns[0 : 9] # Select the first 9 columns\n",
    "features = df_scaled[input_columns].values\n",
    "\n",
    "output_column = df_scaled.columns[9] # Select the 10th column (index 9) as the target\n",
    "targets = df_scaled[output_column].values\n",
    "\n",
    "print(features.shape)\n",
    "print(targets.shape)"
   ],
   "id": "a3d985dde837acc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 9)\n",
      "(1000,)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T09:54:53.987396Z",
     "start_time": "2024-12-05T09:54:53.938312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size = 0.2, random_state= 42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "id": "36250cc5a80ab798",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 9)\n",
      "(200, 9)\n",
      "(800,)\n",
      "(200,)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T09:54:55.192936Z",
     "start_time": "2024-12-05T09:54:55.169588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hyperparameter_search(X_train, y_train, X_val, y_val, param_grid):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter search for the given neural network class.\n",
    "    \"\"\"\n",
    "    param_combinations = list(itertools.product(*param_grid.values()))\n",
    "    results = []\n",
    "\n",
    "    for params in param_combinations:\n",
    "        layers, epochs, lr, momentum, activation = params\n",
    "        \n",
    "        # Initialize and train the network\n",
    "        nn = NeuralNet(layers, epochs, lr, momentum, activation, val_split=0.2)\n",
    "        # Call the fit method\n",
    "        train_losses, val_losses = nn.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and evaluate\n",
    "        y_pred = nn.predict(X_val)\n",
    "        mse = ((y_val - y_pred) ** 2).mean()\n",
    "        mae = abs(y_val - y_pred).mean()\n",
    "        epsilon = 1e-7  # A very small value to avoid division by zero\n",
    "        mape = (abs((y_val - y_pred) / (y_val + epsilon))).mean() * 100\n",
    "\n",
    "\n",
    "        results.append({\n",
    "            \"Layers\": layers,\n",
    "            \"Epochs\": epochs,\n",
    "            \"Learning Rate\": lr,\n",
    "            \"Momentum\": momentum,\n",
    "            \"Activation\": activation,\n",
    "            \"MSE\": mse,\n",
    "            \"MAE\": mae,\n",
    "            \"MAPE\": mape,\n",
    "            \"Train Losses\": train_losses,\n",
    "            \"Validation Losses\": val_losses\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ],
   "id": "9dd88d1b32164b1d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T09:54:58.751381Z",
     "start_time": "2024-12-05T09:54:58.734286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"layers\": [\n",
    "        [9, 8, 4, 1],  # Simple\n",
    "        #[9, 16, 8, 1]  # Moderate\n",
    "    ],\n",
    "    \"epochs\": [100, 500],\n",
    "    \"learning_rate\": [0.01, 0.001],\n",
    "    \"momentum\": [0.5, 0.9],\n",
    "    \"activation\": [\"relu\"]  # Activation for hidden layers\n",
    "}"
   ],
   "id": "2d13825e4b452f80",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T09:56:03.943092Z",
     "start_time": "2024-12-05T09:55:00.377986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = hyperparameter_search(X_train, y_train, X_test, y_test, param_grid)\n",
    "\n",
    "# Sort and display results\n",
    "results_sorted = results.sort_values(by=\"MSE\", ascending=True)\n",
    "print(results_sorted)"
   ],
   "id": "728e2248c4bc62a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 2/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 3/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 4/100, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 5/100, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 6/100, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 7/100, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 8/100, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 9/100, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 10/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 11/100, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 12/100, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 13/100, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 14/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 15/100, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 16/100, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 17/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 18/100, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 19/100, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 20/100, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 21/100, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 22/100, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 23/100, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 24/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 25/100, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 26/100, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 27/100, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 28/100, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 29/100, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 30/100, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 31/100, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 32/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 33/100, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 34/100, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 35/100, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 36/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 37/100, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 38/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 39/100, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 40/100, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 41/100, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 42/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 43/100, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 44/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 45/100, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 46/100, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 47/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 48/100, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 49/100, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 50/100, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 51/100, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 52/100, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 53/100, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 54/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 55/100, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 56/100, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 57/100, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 58/100, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 59/100, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 60/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 61/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 62/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 63/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 64/100, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 65/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 66/100, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 67/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 68/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 69/100, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 70/100, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 71/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 72/100, Train Loss: 0.22830748157703568, Val Loss: 0.2161498589965763\n",
      "Epoch 73/100, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 74/100, Train Loss: 0.22830748157703604, Val Loss: 0.2161498589965763\n",
      "Epoch 75/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 76/100, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 77/100, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 78/100, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 79/100, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 80/100, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 81/100, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 82/100, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 83/100, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 84/100, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 85/100, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 86/100, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 87/100, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 88/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 89/100, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 90/100, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 91/100, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 92/100, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 93/100, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 94/100, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 95/100, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 96/100, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 97/100, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 98/100, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 99/100, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 100/100, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Returning from fit...\n",
      "Train Losses: [np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703598), np.float64(0.22830748157703595), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770357), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703573), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703595), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703595), np.float64(0.22830748157703598), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703595), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703595), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.22830748157703584), np.float64(0.22830748157703598), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.22830748157703595), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.22830748157703568), np.float64(0.22830748157703598), np.float64(0.22830748157703604), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.22830748157703593), np.float64(0.22830748157703598), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703573), np.float64(0.22830748157703584), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.22830748157703593), np.float64(0.2283074815770358)]\n",
      "Validation Losses: [np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763)]\n",
      "Epoch 1/100, Train Loss: 0.05216032598843711, Val Loss: 0.05714368270546784\n",
      "Epoch 2/100, Train Loss: 0.049634546226013126, Val Loss: 0.05784588772181822\n",
      "Epoch 3/100, Train Loss: 0.049427310494527, Val Loss: 0.056469642105714826\n",
      "Epoch 4/100, Train Loss: 0.04943661250066286, Val Loss: 0.056454387236460436\n",
      "Epoch 5/100, Train Loss: 0.049630021863750054, Val Loss: 0.05629831099916087\n",
      "Epoch 6/100, Train Loss: 0.05253178097027719, Val Loss: 0.06257836311189355\n",
      "Epoch 7/100, Train Loss: 0.05263047744014368, Val Loss: 0.06271625781133032\n",
      "Epoch 8/100, Train Loss: 0.04935679593221068, Val Loss: 0.05685555679564408\n",
      "Epoch 9/100, Train Loss: 0.05065419435349855, Val Loss: 0.056430638592517006\n",
      "Epoch 10/100, Train Loss: 0.07893132909087072, Val Loss: 0.08780491759252014\n",
      "Epoch 11/100, Train Loss: 0.09303074806692083, Val Loss: 0.10345931959418278\n",
      "Epoch 12/100, Train Loss: 0.0946571206612959, Val Loss: 0.10654488643643999\n",
      "Epoch 13/100, Train Loss: 0.09747699747628978, Val Loss: 0.1096938577940397\n",
      "Epoch 14/100, Train Loss: 0.09231966148405191, Val Loss: 0.10405208842166346\n",
      "Epoch 15/100, Train Loss: 0.09509894615498098, Val Loss: 0.10708647776712946\n",
      "Epoch 16/100, Train Loss: 0.09794290374856959, Val Loss: 0.1099914782233717\n",
      "Epoch 17/100, Train Loss: 0.09828631954740631, Val Loss: 0.1103020979034226\n",
      "Epoch 18/100, Train Loss: 0.09600533452974908, Val Loss: 0.10774635947728792\n",
      "Epoch 19/100, Train Loss: 0.09698554981993789, Val Loss: 0.10886574474040298\n",
      "Epoch 20/100, Train Loss: 0.09675529582043724, Val Loss: 0.108494939814952\n",
      "Epoch 21/100, Train Loss: 0.09473283497360784, Val Loss: 0.10640142942944587\n",
      "Epoch 22/100, Train Loss: 0.09730089201626564, Val Loss: 0.1091748208457171\n",
      "Epoch 23/100, Train Loss: 0.09453877984460494, Val Loss: 0.10562463017536898\n",
      "Epoch 24/100, Train Loss: 0.0948360650262238, Val Loss: 0.10644581674365107\n",
      "Epoch 25/100, Train Loss: 0.09855348135315571, Val Loss: 0.11053063098782344\n",
      "Epoch 26/100, Train Loss: 0.09700724945701633, Val Loss: 0.10878147563228749\n",
      "Epoch 27/100, Train Loss: 0.09505150065578306, Val Loss: 0.10584424710836739\n",
      "Epoch 28/100, Train Loss: 0.09647803971885266, Val Loss: 0.10828772869970843\n",
      "Epoch 29/100, Train Loss: 0.0967766779941424, Val Loss: 0.10845470682605717\n",
      "Epoch 30/100, Train Loss: 0.09560026439683693, Val Loss: 0.10729192157180455\n",
      "Epoch 31/100, Train Loss: 0.09660710660079205, Val Loss: 0.10846889803636561\n",
      "Epoch 32/100, Train Loss: 0.0979271753910628, Val Loss: 0.10987198640103851\n",
      "Epoch 33/100, Train Loss: 0.10008336464185125, Val Loss: 0.11227891791185396\n",
      "Epoch 34/100, Train Loss: 0.09342935489857274, Val Loss: 0.10462320513073793\n",
      "Epoch 35/100, Train Loss: 0.09983354902757027, Val Loss: 0.11194390523516642\n",
      "Epoch 36/100, Train Loss: 0.09934924057087041, Val Loss: 0.11142676117221323\n",
      "Epoch 37/100, Train Loss: 0.09399256540215946, Val Loss: 0.10489934726585248\n",
      "Epoch 38/100, Train Loss: 0.09660025102268613, Val Loss: 0.10824562009284691\n",
      "Epoch 39/100, Train Loss: 0.09867195958502718, Val Loss: 0.11047988729871133\n",
      "Epoch 40/100, Train Loss: 0.09572119983807058, Val Loss: 0.1073568089573121\n",
      "Epoch 41/100, Train Loss: 0.0925552922897987, Val Loss: 0.10363997770569884\n",
      "Epoch 42/100, Train Loss: 0.09618169723233977, Val Loss: 0.10786386800313424\n",
      "Epoch 43/100, Train Loss: 0.09982631681427778, Val Loss: 0.11177915616991373\n",
      "Epoch 44/100, Train Loss: 0.0977539620396929, Val Loss: 0.10951298562372648\n",
      "Epoch 45/100, Train Loss: 0.0992109342451956, Val Loss: 0.11117564283194767\n",
      "Epoch 46/100, Train Loss: 0.09420957762894239, Val Loss: 0.10564726317148355\n",
      "Epoch 47/100, Train Loss: 0.09913916753301022, Val Loss: 0.11118668204363737\n",
      "Epoch 48/100, Train Loss: 0.09589074671268256, Val Loss: 0.10731171998580022\n",
      "Epoch 49/100, Train Loss: 0.0965284751557474, Val Loss: 0.10813892354275714\n",
      "Epoch 50/100, Train Loss: 0.09686023948151756, Val Loss: 0.10848580954549858\n",
      "Epoch 51/100, Train Loss: 0.0977189694299522, Val Loss: 0.10947180923403645\n",
      "Epoch 52/100, Train Loss: 0.09977966407297893, Val Loss: 0.11178363466630431\n",
      "Epoch 53/100, Train Loss: 0.09554935152359756, Val Loss: 0.10706450135631712\n",
      "Epoch 54/100, Train Loss: 0.09682524065243125, Val Loss: 0.10842182370439284\n",
      "Epoch 55/100, Train Loss: 0.09433633057007189, Val Loss: 0.10579601638721871\n",
      "Epoch 56/100, Train Loss: 0.10050090455486471, Val Loss: 0.11255032259621574\n",
      "Epoch 57/100, Train Loss: 0.10240127771833406, Val Loss: 0.11468297635805028\n",
      "Epoch 58/100, Train Loss: 0.09637151386978968, Val Loss: 0.1081150615924015\n",
      "Epoch 59/100, Train Loss: 0.1000524637174229, Val Loss: 0.11201501123852876\n",
      "Epoch 60/100, Train Loss: 0.09638208788551847, Val Loss: 0.10779135035597111\n",
      "Epoch 61/100, Train Loss: 0.10000999708978155, Val Loss: 0.11195930681077007\n",
      "Epoch 62/100, Train Loss: 0.09801397783715327, Val Loss: 0.10976212749400224\n",
      "Epoch 63/100, Train Loss: 0.10008004854865771, Val Loss: 0.11203060868392332\n",
      "Epoch 64/100, Train Loss: 0.09738668507025577, Val Loss: 0.10906566225464927\n",
      "Epoch 65/100, Train Loss: 0.09563008741678594, Val Loss: 0.10709291482642967\n",
      "Epoch 66/100, Train Loss: 0.09407392314524882, Val Loss: 0.10551641364387093\n",
      "Epoch 67/100, Train Loss: 0.09784058801141651, Val Loss: 0.10949227686061763\n",
      "Epoch 68/100, Train Loss: 0.09567252425475493, Val Loss: 0.10725346489448981\n",
      "Epoch 69/100, Train Loss: 0.0928833305414195, Val Loss: 0.10388465956098009\n",
      "Epoch 70/100, Train Loss: 0.10277805435838105, Val Loss: 0.11491368733175461\n",
      "Epoch 71/100, Train Loss: 0.09572953324772436, Val Loss: 0.10703786396564605\n",
      "Epoch 72/100, Train Loss: 0.09740867841447734, Val Loss: 0.10909864399888232\n",
      "Epoch 73/100, Train Loss: 0.10007945887927533, Val Loss: 0.11201368155183485\n",
      "Epoch 74/100, Train Loss: 0.09394824868740408, Val Loss: 0.10518536085651213\n",
      "Epoch 75/100, Train Loss: 0.09848686519669006, Val Loss: 0.11024912450458835\n",
      "Epoch 76/100, Train Loss: 0.09764128405604393, Val Loss: 0.10935918000952433\n",
      "Epoch 77/100, Train Loss: 0.09441356403608432, Val Loss: 0.10543952865475413\n",
      "Epoch 78/100, Train Loss: 0.0950070558287144, Val Loss: 0.10625491517802818\n",
      "Epoch 79/100, Train Loss: 0.09860885233697388, Val Loss: 0.11032246394978201\n",
      "Epoch 80/100, Train Loss: 0.09411790159075994, Val Loss: 0.10518982393488936\n",
      "Epoch 81/100, Train Loss: 0.09938940464416313, Val Loss: 0.11119353132924446\n",
      "Epoch 82/100, Train Loss: 0.10035060473052881, Val Loss: 0.11232427527322354\n",
      "Epoch 83/100, Train Loss: 0.09768900111807621, Val Loss: 0.10938656942459335\n",
      "Epoch 84/100, Train Loss: 0.09737996459325923, Val Loss: 0.1090284415977322\n",
      "Epoch 85/100, Train Loss: 0.09475193564574835, Val Loss: 0.10610591986490786\n",
      "Epoch 86/100, Train Loss: 0.09634325909894789, Val Loss: 0.10787721458371834\n",
      "Epoch 87/100, Train Loss: 0.09967337443409541, Val Loss: 0.11146937056550872\n",
      "Epoch 88/100, Train Loss: 0.10016712687720196, Val Loss: 0.11202380868586656\n",
      "Epoch 89/100, Train Loss: 0.09961066962564497, Val Loss: 0.11138281035545766\n",
      "Epoch 90/100, Train Loss: 0.09883199383220212, Val Loss: 0.11062482336258961\n",
      "Epoch 91/100, Train Loss: 0.09718739628001882, Val Loss: 0.10884278231085702\n",
      "Epoch 92/100, Train Loss: 0.0983871679581733, Val Loss: 0.11002779891408085\n",
      "Epoch 93/100, Train Loss: 0.10013024128978597, Val Loss: 0.111995128863316\n",
      "Epoch 94/100, Train Loss: 0.0963039522410079, Val Loss: 0.10768408303149611\n",
      "Epoch 95/100, Train Loss: 0.09526990813962541, Val Loss: 0.10675889845587702\n",
      "Epoch 96/100, Train Loss: 0.09732423821482977, Val Loss: 0.10886783796150323\n",
      "Epoch 97/100, Train Loss: 0.09962859342845867, Val Loss: 0.11141228047815702\n",
      "Epoch 98/100, Train Loss: 0.09491764886662947, Val Loss: 0.1063240714373959\n",
      "Epoch 99/100, Train Loss: 0.09949042428286355, Val Loss: 0.11135529189402123\n",
      "Epoch 100/100, Train Loss: 0.09710767536040786, Val Loss: 0.10864627386968576\n",
      "Returning from fit...\n",
      "Train Losses: [np.float64(0.05216032598843711), np.float64(0.049634546226013126), np.float64(0.049427310494527), np.float64(0.04943661250066286), np.float64(0.049630021863750054), np.float64(0.05253178097027719), np.float64(0.05263047744014368), np.float64(0.04935679593221068), np.float64(0.05065419435349855), np.float64(0.07893132909087072), np.float64(0.09303074806692083), np.float64(0.0946571206612959), np.float64(0.09747699747628978), np.float64(0.09231966148405191), np.float64(0.09509894615498098), np.float64(0.09794290374856959), np.float64(0.09828631954740631), np.float64(0.09600533452974908), np.float64(0.09698554981993789), np.float64(0.09675529582043724), np.float64(0.09473283497360784), np.float64(0.09730089201626564), np.float64(0.09453877984460494), np.float64(0.0948360650262238), np.float64(0.09855348135315571), np.float64(0.09700724945701633), np.float64(0.09505150065578306), np.float64(0.09647803971885266), np.float64(0.0967766779941424), np.float64(0.09560026439683693), np.float64(0.09660710660079205), np.float64(0.0979271753910628), np.float64(0.10008336464185125), np.float64(0.09342935489857274), np.float64(0.09983354902757027), np.float64(0.09934924057087041), np.float64(0.09399256540215946), np.float64(0.09660025102268613), np.float64(0.09867195958502718), np.float64(0.09572119983807058), np.float64(0.0925552922897987), np.float64(0.09618169723233977), np.float64(0.09982631681427778), np.float64(0.0977539620396929), np.float64(0.0992109342451956), np.float64(0.09420957762894239), np.float64(0.09913916753301022), np.float64(0.09589074671268256), np.float64(0.0965284751557474), np.float64(0.09686023948151756), np.float64(0.0977189694299522), np.float64(0.09977966407297893), np.float64(0.09554935152359756), np.float64(0.09682524065243125), np.float64(0.09433633057007189), np.float64(0.10050090455486471), np.float64(0.10240127771833406), np.float64(0.09637151386978968), np.float64(0.1000524637174229), np.float64(0.09638208788551847), np.float64(0.10000999708978155), np.float64(0.09801397783715327), np.float64(0.10008004854865771), np.float64(0.09738668507025577), np.float64(0.09563008741678594), np.float64(0.09407392314524882), np.float64(0.09784058801141651), np.float64(0.09567252425475493), np.float64(0.0928833305414195), np.float64(0.10277805435838105), np.float64(0.09572953324772436), np.float64(0.09740867841447734), np.float64(0.10007945887927533), np.float64(0.09394824868740408), np.float64(0.09848686519669006), np.float64(0.09764128405604393), np.float64(0.09441356403608432), np.float64(0.0950070558287144), np.float64(0.09860885233697388), np.float64(0.09411790159075994), np.float64(0.09938940464416313), np.float64(0.10035060473052881), np.float64(0.09768900111807621), np.float64(0.09737996459325923), np.float64(0.09475193564574835), np.float64(0.09634325909894789), np.float64(0.09967337443409541), np.float64(0.10016712687720196), np.float64(0.09961066962564497), np.float64(0.09883199383220212), np.float64(0.09718739628001882), np.float64(0.0983871679581733), np.float64(0.10013024128978597), np.float64(0.0963039522410079), np.float64(0.09526990813962541), np.float64(0.09732423821482977), np.float64(0.09962859342845867), np.float64(0.09491764886662947), np.float64(0.09949042428286355), np.float64(0.09710767536040786)]\n",
      "Validation Losses: [np.float64(0.05714368270546784), np.float64(0.05784588772181822), np.float64(0.056469642105714826), np.float64(0.056454387236460436), np.float64(0.05629831099916087), np.float64(0.06257836311189355), np.float64(0.06271625781133032), np.float64(0.05685555679564408), np.float64(0.056430638592517006), np.float64(0.08780491759252014), np.float64(0.10345931959418278), np.float64(0.10654488643643999), np.float64(0.1096938577940397), np.float64(0.10405208842166346), np.float64(0.10708647776712946), np.float64(0.1099914782233717), np.float64(0.1103020979034226), np.float64(0.10774635947728792), np.float64(0.10886574474040298), np.float64(0.108494939814952), np.float64(0.10640142942944587), np.float64(0.1091748208457171), np.float64(0.10562463017536898), np.float64(0.10644581674365107), np.float64(0.11053063098782344), np.float64(0.10878147563228749), np.float64(0.10584424710836739), np.float64(0.10828772869970843), np.float64(0.10845470682605717), np.float64(0.10729192157180455), np.float64(0.10846889803636561), np.float64(0.10987198640103851), np.float64(0.11227891791185396), np.float64(0.10462320513073793), np.float64(0.11194390523516642), np.float64(0.11142676117221323), np.float64(0.10489934726585248), np.float64(0.10824562009284691), np.float64(0.11047988729871133), np.float64(0.1073568089573121), np.float64(0.10363997770569884), np.float64(0.10786386800313424), np.float64(0.11177915616991373), np.float64(0.10951298562372648), np.float64(0.11117564283194767), np.float64(0.10564726317148355), np.float64(0.11118668204363737), np.float64(0.10731171998580022), np.float64(0.10813892354275714), np.float64(0.10848580954549858), np.float64(0.10947180923403645), np.float64(0.11178363466630431), np.float64(0.10706450135631712), np.float64(0.10842182370439284), np.float64(0.10579601638721871), np.float64(0.11255032259621574), np.float64(0.11468297635805028), np.float64(0.1081150615924015), np.float64(0.11201501123852876), np.float64(0.10779135035597111), np.float64(0.11195930681077007), np.float64(0.10976212749400224), np.float64(0.11203060868392332), np.float64(0.10906566225464927), np.float64(0.10709291482642967), np.float64(0.10551641364387093), np.float64(0.10949227686061763), np.float64(0.10725346489448981), np.float64(0.10388465956098009), np.float64(0.11491368733175461), np.float64(0.10703786396564605), np.float64(0.10909864399888232), np.float64(0.11201368155183485), np.float64(0.10518536085651213), np.float64(0.11024912450458835), np.float64(0.10935918000952433), np.float64(0.10543952865475413), np.float64(0.10625491517802818), np.float64(0.11032246394978201), np.float64(0.10518982393488936), np.float64(0.11119353132924446), np.float64(0.11232427527322354), np.float64(0.10938656942459335), np.float64(0.1090284415977322), np.float64(0.10610591986490786), np.float64(0.10787721458371834), np.float64(0.11146937056550872), np.float64(0.11202380868586656), np.float64(0.11138281035545766), np.float64(0.11062482336258961), np.float64(0.10884278231085702), np.float64(0.11002779891408085), np.float64(0.111995128863316), np.float64(0.10768408303149611), np.float64(0.10675889845587702), np.float64(0.10886783796150323), np.float64(0.11141228047815702), np.float64(0.1063240714373959), np.float64(0.11135529189402123), np.float64(0.10864627386968576)]\n",
      "Epoch 1/100, Train Loss: 0.06364850292505377, Val Loss: 0.06554743158118707\n",
      "Epoch 2/100, Train Loss: 0.05063164981172148, Val Loss: 0.05641325560282457\n",
      "Epoch 3/100, Train Loss: 0.049459272535282296, Val Loss: 0.056422620435792464\n",
      "Epoch 4/100, Train Loss: 0.0493705808302211, Val Loss: 0.05662345561041446\n",
      "Epoch 5/100, Train Loss: 0.04935507505056621, Val Loss: 0.05681495217995145\n",
      "Epoch 6/100, Train Loss: 0.04935971880947422, Val Loss: 0.056693986442696985\n",
      "Epoch 7/100, Train Loss: 0.04938403559281621, Val Loss: 0.05657042590273206\n",
      "Epoch 8/100, Train Loss: 0.04935892903969961, Val Loss: 0.05670182859926105\n",
      "Epoch 9/100, Train Loss: 0.049355725933458335, Val Loss: 0.056836413974816376\n",
      "Epoch 10/100, Train Loss: 0.049355052931720635, Val Loss: 0.05676968828961293\n",
      "Epoch 11/100, Train Loss: 0.04936498125919313, Val Loss: 0.0569493254844409\n",
      "Epoch 12/100, Train Loss: 0.04938764403893864, Val Loss: 0.05708972930399199\n",
      "Epoch 13/100, Train Loss: 0.04935712255602665, Val Loss: 0.05686405791009585\n",
      "Epoch 14/100, Train Loss: 0.04935850281739839, Val Loss: 0.05688405946970109\n",
      "Epoch 15/100, Train Loss: 0.04935489798978992, Val Loss: 0.056779146528171225\n",
      "Epoch 16/100, Train Loss: 0.04935571017220119, Val Loss: 0.05683601102975275\n",
      "Epoch 17/100, Train Loss: 0.04935775222262866, Val Loss: 0.05687372671747235\n",
      "Epoch 18/100, Train Loss: 0.04935497766614839, Val Loss: 0.05680978458910298\n",
      "Epoch 19/100, Train Loss: 0.049372413196444434, Val Loss: 0.056614889182602685\n",
      "Epoch 20/100, Train Loss: 0.04935514593019898, Val Loss: 0.056765650940181225\n",
      "Epoch 21/100, Train Loss: 0.049355121170102455, Val Loss: 0.05676665923846572\n",
      "Epoch 22/100, Train Loss: 0.049363130631001326, Val Loss: 0.05666637297951754\n",
      "Epoch 23/100, Train Loss: 0.04936466288374341, Val Loss: 0.056656112348976426\n",
      "Epoch 24/100, Train Loss: 0.049358067750823305, Val Loss: 0.05671139173065221\n",
      "Epoch 25/100, Train Loss: 0.04936016358555022, Val Loss: 0.05668987390191825\n",
      "Epoch 26/100, Train Loss: 0.04935813660256873, Val Loss: 0.056710579470147085\n",
      "Epoch 27/100, Train Loss: 0.04935493772519266, Val Loss: 0.05677614108671445\n",
      "Epoch 28/100, Train Loss: 0.04936928480481719, Val Loss: 0.056629881477193\n",
      "Epoch 29/100, Train Loss: 0.049359454283153734, Val Loss: 0.056696527475764015\n",
      "Epoch 30/100, Train Loss: 0.049360266412533334, Val Loss: 0.05668895041799159\n",
      "Epoch 31/100, Train Loss: 0.04935496119842308, Val Loss: 0.05680876146308276\n",
      "Epoch 32/100, Train Loss: 0.04936357787582983, Val Loss: 0.05666327217502569\n",
      "Epoch 33/100, Train Loss: 0.049355552780332684, Val Loss: 0.05675277643246232\n",
      "Epoch 34/100, Train Loss: 0.049360376890412484, Val Loss: 0.05668796910877698\n",
      "Epoch 35/100, Train Loss: 0.04935498460517295, Val Loss: 0.05681019688196114\n",
      "Epoch 36/100, Train Loss: 0.04935560480739979, Val Loss: 0.0567514397634397\n",
      "Epoch 37/100, Train Loss: 0.04935527506498119, Val Loss: 0.05676094188828569\n",
      "Epoch 38/100, Train Loss: 0.04935647433323043, Val Loss: 0.05685268252375167\n",
      "Epoch 39/100, Train Loss: 0.049355159459600895, Val Loss: 0.056818660700291845\n",
      "Epoch 40/100, Train Loss: 0.049362550020476396, Val Loss: 0.056670541143371125\n",
      "Epoch 41/100, Train Loss: 0.0493605557174046, Val Loss: 0.056686403427333325\n",
      "Epoch 42/100, Train Loss: 0.04936164642990693, Val Loss: 0.05691934774496008\n",
      "Epoch 43/100, Train Loss: 0.049360409466982225, Val Loss: 0.056906593487742574\n",
      "Epoch 44/100, Train Loss: 0.04935938054271654, Val Loss: 0.05669724923159819\n",
      "Epoch 45/100, Train Loss: 0.049367596074848225, Val Loss: 0.05663879578455347\n",
      "Epoch 46/100, Train Loss: 0.049356570741767775, Val Loss: 0.05685449212259269\n",
      "Epoch 47/100, Train Loss: 0.04935879789834607, Val Loss: 0.05670320497800385\n",
      "Epoch 48/100, Train Loss: 0.04937452662316006, Val Loss: 0.05701684796888438\n",
      "Epoch 49/100, Train Loss: 0.04935718450734785, Val Loss: 0.05686505604667847\n",
      "Epoch 50/100, Train Loss: 0.049356270935420214, Val Loss: 0.0567373073032796\n",
      "Epoch 51/100, Train Loss: 0.049355702983108395, Val Loss: 0.056749037359826324\n",
      "Epoch 52/100, Train Loss: 0.04935680129826338, Val Loss: 0.056858638424679225\n",
      "Epoch 53/100, Train Loss: 0.049356270311234546, Val Loss: 0.05673731841275433\n",
      "Epoch 54/100, Train Loss: 0.04936064942388794, Val Loss: 0.05668559300351857\n",
      "Epoch 55/100, Train Loss: 0.04936940298673067, Val Loss: 0.05662927893329775\n",
      "Epoch 56/100, Train Loss: 0.04935520282894099, Val Loss: 0.056820387002981\n",
      "Epoch 57/100, Train Loss: 0.04935491952671169, Val Loss: 0.05680585922668922\n",
      "Epoch 58/100, Train Loss: 0.04936131023149947, Val Loss: 0.05691599075119849\n",
      "Epoch 59/100, Train Loss: 0.04938650582181026, Val Loss: 0.056562521296197835\n",
      "Epoch 60/100, Train Loss: 0.04936148874102748, Val Loss: 0.05667864811197448\n",
      "Epoch 61/100, Train Loss: 0.04935598160640151, Val Loss: 0.05684251416767363\n",
      "Epoch 62/100, Train Loss: 0.049357376880514475, Val Loss: 0.05686809084757645\n",
      "Epoch 63/100, Train Loss: 0.04937009725694006, Val Loss: 0.056625810180410026\n",
      "Epoch 64/100, Train Loss: 0.049358536292999675, Val Loss: 0.05670603334355867\n",
      "Epoch 65/100, Train Loss: 0.04935544806355903, Val Loss: 0.056828724779430954\n",
      "Epoch 66/100, Train Loss: 0.049356426420859946, Val Loss: 0.05685176107960555\n",
      "Epoch 67/100, Train Loss: 0.0493559005018299, Val Loss: 0.05684065383201266\n",
      "Epoch 68/100, Train Loss: 0.049354957588456566, Val Loss: 0.05680852564031585\n",
      "Epoch 69/100, Train Loss: 0.04936442368942217, Val Loss: 0.056944651643049585\n",
      "Epoch 70/100, Train Loss: 0.04935986468765324, Val Loss: 0.05669261000479947\n",
      "Epoch 71/100, Train Loss: 0.04935529948023915, Val Loss: 0.05676013080246059\n",
      "Epoch 72/100, Train Loss: 0.04939742469082022, Val Loss: 0.056531831582219326\n",
      "Epoch 73/100, Train Loss: 0.0493556686519552, Val Loss: 0.056749858065909126\n",
      "Epoch 74/100, Train Loss: 0.04935483850637454, Val Loss: 0.0567862535942662\n",
      "Epoch 75/100, Train Loss: 0.04935570901365379, Val Loss: 0.05674889221467141\n",
      "Epoch 76/100, Train Loss: 0.04936808361234238, Val Loss: 0.05663615064551669\n",
      "Epoch 77/100, Train Loss: 0.049358169915853824, Val Loss: 0.05687960360012287\n",
      "Epoch 78/100, Train Loss: 0.0493548740915099, Val Loss: 0.05680182278268376\n",
      "Epoch 79/100, Train Loss: 0.049355480236813284, Val Loss: 0.05675472091855048\n",
      "Epoch 80/100, Train Loss: 0.049355650756896546, Val Loss: 0.056834456412194506\n",
      "Epoch 81/100, Train Loss: 0.04935482695559486, Val Loss: 0.056793397490948284\n",
      "Epoch 82/100, Train Loss: 0.049355198622418266, Val Loss: 0.05676362386472108\n",
      "Epoch 83/100, Train Loss: 0.049357205575706796, Val Loss: 0.05686539048047548\n",
      "Epoch 84/100, Train Loss: 0.04936153753719676, Val Loss: 0.056678257820344316\n",
      "Epoch 85/100, Train Loss: 0.049362899410029894, Val Loss: 0.056668007341015667\n",
      "Epoch 86/100, Train Loss: 0.04935535020930175, Val Loss: 0.05682563023958307\n",
      "Epoch 87/100, Train Loss: 0.04935872981392341, Val Loss: 0.05688697868153258\n",
      "Epoch 88/100, Train Loss: 0.04936132248699621, Val Loss: 0.056679980476589904\n",
      "Epoch 89/100, Train Loss: 0.049366698016978273, Val Loss: 0.05664382019445803\n",
      "Epoch 90/100, Train Loss: 0.049354830731225895, Val Loss: 0.05679494660468962\n",
      "Epoch 91/100, Train Loss: 0.049362420046793115, Val Loss: 0.05667149433577397\n",
      "Epoch 92/100, Train Loss: 0.049355725150793395, Val Loss: 0.056836385183050384\n",
      "Epoch 93/100, Train Loss: 0.04936813424729534, Val Loss: 0.05697383604530035\n",
      "Epoch 94/100, Train Loss: 0.04936979384593207, Val Loss: 0.05698572181461792\n",
      "Epoch 95/100, Train Loss: 0.0493549099322753, Val Loss: 0.056805102379106784\n",
      "Epoch 96/100, Train Loss: 0.049361722585955524, Val Loss: 0.05667679893016657\n",
      "Epoch 97/100, Train Loss: 0.04936963522101851, Val Loss: 0.05662810463961392\n",
      "Epoch 98/100, Train Loss: 0.04935969906514722, Val Loss: 0.0568986779714872\n",
      "Epoch 99/100, Train Loss: 0.049355737694460694, Val Loss: 0.05674821775694074\n",
      "Epoch 100/100, Train Loss: 0.04935540158473579, Val Loss: 0.05682728430648514\n",
      "Returning from fit...\n",
      "Train Losses: [np.float64(0.06364850292505377), np.float64(0.05063164981172148), np.float64(0.049459272535282296), np.float64(0.0493705808302211), np.float64(0.04935507505056621), np.float64(0.04935971880947422), np.float64(0.04938403559281621), np.float64(0.04935892903969961), np.float64(0.049355725933458335), np.float64(0.049355052931720635), np.float64(0.04936498125919313), np.float64(0.04938764403893864), np.float64(0.04935712255602665), np.float64(0.04935850281739839), np.float64(0.04935489798978992), np.float64(0.04935571017220119), np.float64(0.04935775222262866), np.float64(0.04935497766614839), np.float64(0.049372413196444434), np.float64(0.04935514593019898), np.float64(0.049355121170102455), np.float64(0.049363130631001326), np.float64(0.04936466288374341), np.float64(0.049358067750823305), np.float64(0.04936016358555022), np.float64(0.04935813660256873), np.float64(0.04935493772519266), np.float64(0.04936928480481719), np.float64(0.049359454283153734), np.float64(0.049360266412533334), np.float64(0.04935496119842308), np.float64(0.04936357787582983), np.float64(0.049355552780332684), np.float64(0.049360376890412484), np.float64(0.04935498460517295), np.float64(0.04935560480739979), np.float64(0.04935527506498119), np.float64(0.04935647433323043), np.float64(0.049355159459600895), np.float64(0.049362550020476396), np.float64(0.0493605557174046), np.float64(0.04936164642990693), np.float64(0.049360409466982225), np.float64(0.04935938054271654), np.float64(0.049367596074848225), np.float64(0.049356570741767775), np.float64(0.04935879789834607), np.float64(0.04937452662316006), np.float64(0.04935718450734785), np.float64(0.049356270935420214), np.float64(0.049355702983108395), np.float64(0.04935680129826338), np.float64(0.049356270311234546), np.float64(0.04936064942388794), np.float64(0.04936940298673067), np.float64(0.04935520282894099), np.float64(0.04935491952671169), np.float64(0.04936131023149947), np.float64(0.04938650582181026), np.float64(0.04936148874102748), np.float64(0.04935598160640151), np.float64(0.049357376880514475), np.float64(0.04937009725694006), np.float64(0.049358536292999675), np.float64(0.04935544806355903), np.float64(0.049356426420859946), np.float64(0.0493559005018299), np.float64(0.049354957588456566), np.float64(0.04936442368942217), np.float64(0.04935986468765324), np.float64(0.04935529948023915), np.float64(0.04939742469082022), np.float64(0.0493556686519552), np.float64(0.04935483850637454), np.float64(0.04935570901365379), np.float64(0.04936808361234238), np.float64(0.049358169915853824), np.float64(0.0493548740915099), np.float64(0.049355480236813284), np.float64(0.049355650756896546), np.float64(0.04935482695559486), np.float64(0.049355198622418266), np.float64(0.049357205575706796), np.float64(0.04936153753719676), np.float64(0.049362899410029894), np.float64(0.04935535020930175), np.float64(0.04935872981392341), np.float64(0.04936132248699621), np.float64(0.049366698016978273), np.float64(0.049354830731225895), np.float64(0.049362420046793115), np.float64(0.049355725150793395), np.float64(0.04936813424729534), np.float64(0.04936979384593207), np.float64(0.0493549099322753), np.float64(0.049361722585955524), np.float64(0.04936963522101851), np.float64(0.04935969906514722), np.float64(0.049355737694460694), np.float64(0.04935540158473579)]\n",
      "Validation Losses: [np.float64(0.06554743158118707), np.float64(0.05641325560282457), np.float64(0.056422620435792464), np.float64(0.05662345561041446), np.float64(0.05681495217995145), np.float64(0.056693986442696985), np.float64(0.05657042590273206), np.float64(0.05670182859926105), np.float64(0.056836413974816376), np.float64(0.05676968828961293), np.float64(0.0569493254844409), np.float64(0.05708972930399199), np.float64(0.05686405791009585), np.float64(0.05688405946970109), np.float64(0.056779146528171225), np.float64(0.05683601102975275), np.float64(0.05687372671747235), np.float64(0.05680978458910298), np.float64(0.056614889182602685), np.float64(0.056765650940181225), np.float64(0.05676665923846572), np.float64(0.05666637297951754), np.float64(0.056656112348976426), np.float64(0.05671139173065221), np.float64(0.05668987390191825), np.float64(0.056710579470147085), np.float64(0.05677614108671445), np.float64(0.056629881477193), np.float64(0.056696527475764015), np.float64(0.05668895041799159), np.float64(0.05680876146308276), np.float64(0.05666327217502569), np.float64(0.05675277643246232), np.float64(0.05668796910877698), np.float64(0.05681019688196114), np.float64(0.0567514397634397), np.float64(0.05676094188828569), np.float64(0.05685268252375167), np.float64(0.056818660700291845), np.float64(0.056670541143371125), np.float64(0.056686403427333325), np.float64(0.05691934774496008), np.float64(0.056906593487742574), np.float64(0.05669724923159819), np.float64(0.05663879578455347), np.float64(0.05685449212259269), np.float64(0.05670320497800385), np.float64(0.05701684796888438), np.float64(0.05686505604667847), np.float64(0.0567373073032796), np.float64(0.056749037359826324), np.float64(0.056858638424679225), np.float64(0.05673731841275433), np.float64(0.05668559300351857), np.float64(0.05662927893329775), np.float64(0.056820387002981), np.float64(0.05680585922668922), np.float64(0.05691599075119849), np.float64(0.056562521296197835), np.float64(0.05667864811197448), np.float64(0.05684251416767363), np.float64(0.05686809084757645), np.float64(0.056625810180410026), np.float64(0.05670603334355867), np.float64(0.056828724779430954), np.float64(0.05685176107960555), np.float64(0.05684065383201266), np.float64(0.05680852564031585), np.float64(0.056944651643049585), np.float64(0.05669261000479947), np.float64(0.05676013080246059), np.float64(0.056531831582219326), np.float64(0.056749858065909126), np.float64(0.0567862535942662), np.float64(0.05674889221467141), np.float64(0.05663615064551669), np.float64(0.05687960360012287), np.float64(0.05680182278268376), np.float64(0.05675472091855048), np.float64(0.056834456412194506), np.float64(0.056793397490948284), np.float64(0.05676362386472108), np.float64(0.05686539048047548), np.float64(0.056678257820344316), np.float64(0.056668007341015667), np.float64(0.05682563023958307), np.float64(0.05688697868153258), np.float64(0.056679980476589904), np.float64(0.05664382019445803), np.float64(0.05679494660468962), np.float64(0.05667149433577397), np.float64(0.056836385183050384), np.float64(0.05697383604530035), np.float64(0.05698572181461792), np.float64(0.056805102379106784), np.float64(0.05667679893016657), np.float64(0.05662810463961392), np.float64(0.0568986779714872), np.float64(0.05674821775694074), np.float64(0.05682728430648514)]\n",
      "Epoch 1/100, Train Loss: 0.049970647488157584, Val Loss: 0.058556813051305515\n",
      "Epoch 2/100, Train Loss: 0.04935643873980883, Val Loss: 0.0567343097862911\n",
      "Epoch 3/100, Train Loss: 0.04941102310184636, Val Loss: 0.05719495284384093\n",
      "Epoch 4/100, Train Loss: 0.04938577292896114, Val Loss: 0.057080146502155454\n",
      "Epoch 5/100, Train Loss: 0.04986085958874464, Val Loss: 0.05625562020335937\n",
      "Epoch 6/100, Train Loss: 0.050459490474600986, Val Loss: 0.05635673263227404\n",
      "Epoch 7/100, Train Loss: 0.049443838912804725, Val Loss: 0.057317535761628055\n",
      "Epoch 8/100, Train Loss: 0.049614956434782254, Val Loss: 0.057798699385001824\n",
      "Epoch 9/100, Train Loss: 0.04936583163375149, Val Loss: 0.05695619061341794\n",
      "Epoch 10/100, Train Loss: 0.050018587509318355, Val Loss: 0.056261963125504584\n",
      "Epoch 11/100, Train Loss: 0.0493713211252393, Val Loss: 0.056996133626017444\n",
      "Epoch 12/100, Train Loss: 0.049548053739536586, Val Loss: 0.05762859359437593\n",
      "Epoch 13/100, Train Loss: 0.04949942336430238, Val Loss: 0.05749307849777017\n",
      "Epoch 14/100, Train Loss: 0.04969386990536402, Val Loss: 0.05627770098038245\n",
      "Epoch 15/100, Train Loss: 0.04938307641911412, Val Loss: 0.05706594642137761\n",
      "Epoch 16/100, Train Loss: 0.04935732004974894, Val Loss: 0.05686715778459929\n",
      "Epoch 17/100, Train Loss: 0.04949790357292006, Val Loss: 0.05638055584815768\n",
      "Epoch 18/100, Train Loss: 0.049356933344854435, Val Loss: 0.05686085625908076\n",
      "Epoch 19/100, Train Loss: 0.04995460134091405, Val Loss: 0.05852559506035943\n",
      "Epoch 20/100, Train Loss: 0.050615433789435754, Val Loss: 0.05969658901867346\n",
      "Epoch 21/100, Train Loss: 0.05052635466344622, Val Loss: 0.05637770658745212\n",
      "Epoch 22/100, Train Loss: 0.04935836081049469, Val Loss: 0.05670793519803058\n",
      "Epoch 23/100, Train Loss: 0.04954414765396699, Val Loss: 0.05634351671132085\n",
      "Epoch 24/100, Train Loss: 0.04950907194189062, Val Loss: 0.0563704955891207\n",
      "Epoch 25/100, Train Loss: 0.049474203191397725, Val Loss: 0.05741690152374319\n",
      "Epoch 26/100, Train Loss: 0.049533612633889314, Val Loss: 0.057589551701034906\n",
      "Epoch 27/100, Train Loss: 0.049391967708068654, Val Loss: 0.057110874245041646\n",
      "Epoch 28/100, Train Loss: 0.049537818455317746, Val Loss: 0.05760098249911891\n",
      "Epoch 29/100, Train Loss: 0.04936914232461813, Val Loss: 0.056981014839140254\n",
      "Epoch 30/100, Train Loss: 0.049357141471875164, Val Loss: 0.056723279591413406\n",
      "Epoch 31/100, Train Loss: 0.049693005182951486, Val Loss: 0.056277909936448\n",
      "Epoch 32/100, Train Loss: 0.04953497050473103, Val Loss: 0.0575931985112989\n",
      "Epoch 33/100, Train Loss: 0.049373336092839094, Val Loss: 0.056610674657490485\n",
      "Epoch 34/100, Train Loss: 0.04939235793404713, Val Loss: 0.056545214291915814\n",
      "Epoch 35/100, Train Loss: 0.04954897941887506, Val Loss: 0.05634023701211765\n",
      "Epoch 36/100, Train Loss: 0.04958949766837836, Val Loss: 0.056316603426467236\n",
      "Epoch 37/100, Train Loss: 0.04935503862794381, Val Loss: 0.056770232277957876\n",
      "Epoch 38/100, Train Loss: 0.04949866750588756, Val Loss: 0.057490645992567736\n",
      "Epoch 39/100, Train Loss: 0.04939434181534013, Val Loss: 0.05653975494670745\n",
      "Epoch 40/100, Train Loss: 0.049421213772300646, Val Loss: 0.056480399954956156\n",
      "Epoch 41/100, Train Loss: 0.04935554648280412, Val Loss: 0.05683134943152502\n",
      "Epoch 42/100, Train Loss: 0.04982672148570316, Val Loss: 0.05625722911517202\n",
      "Epoch 43/100, Train Loss: 0.04938136585563149, Val Loss: 0.057056391429136696\n",
      "Epoch 44/100, Train Loss: 0.049363990439508926, Val Loss: 0.056940611805141365\n",
      "Epoch 45/100, Train Loss: 0.049370184417342776, Val Loss: 0.056988069690660836\n",
      "Epoch 46/100, Train Loss: 0.04946307518280206, Val Loss: 0.057381234251537794\n",
      "Epoch 47/100, Train Loss: 0.04959848095342144, Val Loss: 0.057757615468880946\n",
      "Epoch 48/100, Train Loss: 0.04939939384110081, Val Loss: 0.057144824329268394\n",
      "Epoch 49/100, Train Loss: 0.04975906987076851, Val Loss: 0.05812626774210835\n",
      "Epoch 50/100, Train Loss: 0.049394640979067705, Val Loss: 0.05712301586345182\n",
      "Epoch 51/100, Train Loss: 0.049936461571434415, Val Loss: 0.05848918613949676\n",
      "Epoch 52/100, Train Loss: 0.04954529594700244, Val Loss: 0.05762033793590031\n",
      "Epoch 53/100, Train Loss: 0.04940172695019199, Val Loss: 0.05715480312404148\n",
      "Epoch 54/100, Train Loss: 0.04976886134337459, Val Loss: 0.05626301084575112\n",
      "Epoch 55/100, Train Loss: 0.049388280168423754, Val Loss: 0.05709185492803604\n",
      "Epoch 56/100, Train Loss: 0.04940077966768046, Val Loss: 0.05715026803616352\n",
      "Epoch 57/100, Train Loss: 0.0493676261120013, Val Loss: 0.056637898833757604\n",
      "Epoch 58/100, Train Loss: 0.049372302197469235, Val Loss: 0.05661458538659805\n",
      "Epoch 59/100, Train Loss: 0.04951066188050115, Val Loss: 0.05636861569010592\n",
      "Epoch 60/100, Train Loss: 0.049664813453701495, Val Loss: 0.05791426234795858\n",
      "Epoch 61/100, Train Loss: 0.049512900728451055, Val Loss: 0.05752907748830915\n",
      "Epoch 62/100, Train Loss: 0.0496610169987603, Val Loss: 0.05790435789805467\n",
      "Epoch 63/100, Train Loss: 0.0493897128950723, Val Loss: 0.05709634914448066\n",
      "Epoch 64/100, Train Loss: 0.049367329413246674, Val Loss: 0.05663903206091681\n",
      "Epoch 65/100, Train Loss: 0.04961643926783179, Val Loss: 0.05779571557763916\n",
      "Epoch 66/100, Train Loss: 0.049433402065765464, Val Loss: 0.05727332978787552\n",
      "Epoch 67/100, Train Loss: 0.04936548561906664, Val Loss: 0.056651293651210057\n",
      "Epoch 68/100, Train Loss: 0.04963209842322373, Val Loss: 0.057826386223752094\n",
      "Epoch 69/100, Train Loss: 0.04938966179135254, Val Loss: 0.05708056118337975\n",
      "Epoch 70/100, Train Loss: 0.04961202637916252, Val Loss: 0.0577657520723445\n",
      "Epoch 71/100, Train Loss: 0.04962010943847171, Val Loss: 0.05630733038064028\n",
      "Epoch 72/100, Train Loss: 0.04952463301783003, Val Loss: 0.05637232630735127\n",
      "Epoch 73/100, Train Loss: 0.049484223814024265, Val Loss: 0.056441044182767956\n",
      "Epoch 74/100, Train Loss: 0.04954968485863657, Val Loss: 0.056451981612192934\n",
      "Epoch 75/100, Train Loss: 0.04961527173590701, Val Loss: 0.057299378192772775\n",
      "Epoch 76/100, Train Loss: 0.05004720203749923, Val Loss: 0.05765038616758688\n",
      "Epoch 77/100, Train Loss: 0.05162212091700792, Val Loss: 0.058735767321111236\n",
      "Epoch 78/100, Train Loss: 0.05699221508137371, Val Loss: 0.06448474635174102\n",
      "Epoch 79/100, Train Loss: 0.07008159488252833, Val Loss: 0.07828296653903824\n",
      "Epoch 80/100, Train Loss: 0.0816271130295834, Val Loss: 0.09056093293198918\n",
      "Epoch 81/100, Train Loss: 0.0898370416939329, Val Loss: 0.09914927699204228\n",
      "Epoch 82/100, Train Loss: 0.0919196976004294, Val Loss: 0.10155493542137652\n",
      "Epoch 83/100, Train Loss: 0.09296473024225295, Val Loss: 0.1027533999813302\n",
      "Epoch 84/100, Train Loss: 0.09411401565510694, Val Loss: 0.10403919457356386\n",
      "Epoch 85/100, Train Loss: 0.09588488075230331, Val Loss: 0.10582577325843193\n",
      "Epoch 86/100, Train Loss: 0.0948833606211118, Val Loss: 0.10496937763744561\n",
      "Epoch 87/100, Train Loss: 0.09510867255245442, Val Loss: 0.10523834730093502\n",
      "Epoch 88/100, Train Loss: 0.09507158253244312, Val Loss: 0.10530055781950656\n",
      "Epoch 89/100, Train Loss: 0.09506949106551703, Val Loss: 0.10538328289912606\n",
      "Epoch 90/100, Train Loss: 0.09552088641759368, Val Loss: 0.10592259433907036\n",
      "Epoch 91/100, Train Loss: 0.0957326235807664, Val Loss: 0.10624738018476666\n",
      "Epoch 92/100, Train Loss: 0.09538828783805016, Val Loss: 0.1060102470740902\n",
      "Epoch 93/100, Train Loss: 0.09568270413871115, Val Loss: 0.10636353866565612\n",
      "Epoch 94/100, Train Loss: 0.09612491304302838, Val Loss: 0.10695935933323858\n",
      "Epoch 95/100, Train Loss: 0.09701425978916695, Val Loss: 0.10790692547641763\n",
      "Epoch 96/100, Train Loss: 0.09618290506493887, Val Loss: 0.1071777326271705\n",
      "Epoch 97/100, Train Loss: 0.09556950042547742, Val Loss: 0.10668241518776736\n",
      "Epoch 98/100, Train Loss: 0.0961464928200899, Val Loss: 0.10736079282114439\n",
      "Epoch 99/100, Train Loss: 0.09560412773363143, Val Loss: 0.10693141846233434\n",
      "Epoch 100/100, Train Loss: 0.09675498466520384, Val Loss: 0.10814065806988622\n",
      "Returning from fit...\n",
      "Train Losses: [np.float64(0.049970647488157584), np.float64(0.04935643873980883), np.float64(0.04941102310184636), np.float64(0.04938577292896114), np.float64(0.04986085958874464), np.float64(0.050459490474600986), np.float64(0.049443838912804725), np.float64(0.049614956434782254), np.float64(0.04936583163375149), np.float64(0.050018587509318355), np.float64(0.0493713211252393), np.float64(0.049548053739536586), np.float64(0.04949942336430238), np.float64(0.04969386990536402), np.float64(0.04938307641911412), np.float64(0.04935732004974894), np.float64(0.04949790357292006), np.float64(0.049356933344854435), np.float64(0.04995460134091405), np.float64(0.050615433789435754), np.float64(0.05052635466344622), np.float64(0.04935836081049469), np.float64(0.04954414765396699), np.float64(0.04950907194189062), np.float64(0.049474203191397725), np.float64(0.049533612633889314), np.float64(0.049391967708068654), np.float64(0.049537818455317746), np.float64(0.04936914232461813), np.float64(0.049357141471875164), np.float64(0.049693005182951486), np.float64(0.04953497050473103), np.float64(0.049373336092839094), np.float64(0.04939235793404713), np.float64(0.04954897941887506), np.float64(0.04958949766837836), np.float64(0.04935503862794381), np.float64(0.04949866750588756), np.float64(0.04939434181534013), np.float64(0.049421213772300646), np.float64(0.04935554648280412), np.float64(0.04982672148570316), np.float64(0.04938136585563149), np.float64(0.049363990439508926), np.float64(0.049370184417342776), np.float64(0.04946307518280206), np.float64(0.04959848095342144), np.float64(0.04939939384110081), np.float64(0.04975906987076851), np.float64(0.049394640979067705), np.float64(0.049936461571434415), np.float64(0.04954529594700244), np.float64(0.04940172695019199), np.float64(0.04976886134337459), np.float64(0.049388280168423754), np.float64(0.04940077966768046), np.float64(0.0493676261120013), np.float64(0.049372302197469235), np.float64(0.04951066188050115), np.float64(0.049664813453701495), np.float64(0.049512900728451055), np.float64(0.0496610169987603), np.float64(0.0493897128950723), np.float64(0.049367329413246674), np.float64(0.04961643926783179), np.float64(0.049433402065765464), np.float64(0.04936548561906664), np.float64(0.04963209842322373), np.float64(0.04938966179135254), np.float64(0.04961202637916252), np.float64(0.04962010943847171), np.float64(0.04952463301783003), np.float64(0.049484223814024265), np.float64(0.04954968485863657), np.float64(0.04961527173590701), np.float64(0.05004720203749923), np.float64(0.05162212091700792), np.float64(0.05699221508137371), np.float64(0.07008159488252833), np.float64(0.0816271130295834), np.float64(0.0898370416939329), np.float64(0.0919196976004294), np.float64(0.09296473024225295), np.float64(0.09411401565510694), np.float64(0.09588488075230331), np.float64(0.0948833606211118), np.float64(0.09510867255245442), np.float64(0.09507158253244312), np.float64(0.09506949106551703), np.float64(0.09552088641759368), np.float64(0.0957326235807664), np.float64(0.09538828783805016), np.float64(0.09568270413871115), np.float64(0.09612491304302838), np.float64(0.09701425978916695), np.float64(0.09618290506493887), np.float64(0.09556950042547742), np.float64(0.0961464928200899), np.float64(0.09560412773363143), np.float64(0.09675498466520384)]\n",
      "Validation Losses: [np.float64(0.058556813051305515), np.float64(0.0567343097862911), np.float64(0.05719495284384093), np.float64(0.057080146502155454), np.float64(0.05625562020335937), np.float64(0.05635673263227404), np.float64(0.057317535761628055), np.float64(0.057798699385001824), np.float64(0.05695619061341794), np.float64(0.056261963125504584), np.float64(0.056996133626017444), np.float64(0.05762859359437593), np.float64(0.05749307849777017), np.float64(0.05627770098038245), np.float64(0.05706594642137761), np.float64(0.05686715778459929), np.float64(0.05638055584815768), np.float64(0.05686085625908076), np.float64(0.05852559506035943), np.float64(0.05969658901867346), np.float64(0.05637770658745212), np.float64(0.05670793519803058), np.float64(0.05634351671132085), np.float64(0.0563704955891207), np.float64(0.05741690152374319), np.float64(0.057589551701034906), np.float64(0.057110874245041646), np.float64(0.05760098249911891), np.float64(0.056981014839140254), np.float64(0.056723279591413406), np.float64(0.056277909936448), np.float64(0.0575931985112989), np.float64(0.056610674657490485), np.float64(0.056545214291915814), np.float64(0.05634023701211765), np.float64(0.056316603426467236), np.float64(0.056770232277957876), np.float64(0.057490645992567736), np.float64(0.05653975494670745), np.float64(0.056480399954956156), np.float64(0.05683134943152502), np.float64(0.05625722911517202), np.float64(0.057056391429136696), np.float64(0.056940611805141365), np.float64(0.056988069690660836), np.float64(0.057381234251537794), np.float64(0.057757615468880946), np.float64(0.057144824329268394), np.float64(0.05812626774210835), np.float64(0.05712301586345182), np.float64(0.05848918613949676), np.float64(0.05762033793590031), np.float64(0.05715480312404148), np.float64(0.05626301084575112), np.float64(0.05709185492803604), np.float64(0.05715026803616352), np.float64(0.056637898833757604), np.float64(0.05661458538659805), np.float64(0.05636861569010592), np.float64(0.05791426234795858), np.float64(0.05752907748830915), np.float64(0.05790435789805467), np.float64(0.05709634914448066), np.float64(0.05663903206091681), np.float64(0.05779571557763916), np.float64(0.05727332978787552), np.float64(0.056651293651210057), np.float64(0.057826386223752094), np.float64(0.05708056118337975), np.float64(0.0577657520723445), np.float64(0.05630733038064028), np.float64(0.05637232630735127), np.float64(0.056441044182767956), np.float64(0.056451981612192934), np.float64(0.057299378192772775), np.float64(0.05765038616758688), np.float64(0.058735767321111236), np.float64(0.06448474635174102), np.float64(0.07828296653903824), np.float64(0.09056093293198918), np.float64(0.09914927699204228), np.float64(0.10155493542137652), np.float64(0.1027533999813302), np.float64(0.10403919457356386), np.float64(0.10582577325843193), np.float64(0.10496937763744561), np.float64(0.10523834730093502), np.float64(0.10530055781950656), np.float64(0.10538328289912606), np.float64(0.10592259433907036), np.float64(0.10624738018476666), np.float64(0.1060102470740902), np.float64(0.10636353866565612), np.float64(0.10695935933323858), np.float64(0.10790692547641763), np.float64(0.1071777326271705), np.float64(0.10668241518776736), np.float64(0.10736079282114439), np.float64(0.10693141846233434), np.float64(0.10814065806988622)]\n",
      "Epoch 1/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 2/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 3/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 4/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 5/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 6/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 7/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 8/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 9/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 10/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 11/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 12/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 13/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 14/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 15/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 16/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 17/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 18/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 19/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 20/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 21/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 22/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 23/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 24/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 25/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 26/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 27/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 28/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 29/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 30/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 31/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 32/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 33/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 34/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 35/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 36/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 37/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 38/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 39/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 40/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 41/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 42/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 43/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 44/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 45/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 46/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 47/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 48/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 49/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 50/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 51/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 52/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 53/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 54/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 55/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 56/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 57/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 58/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 59/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 60/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 61/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 62/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 63/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 64/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 65/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 66/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 67/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 68/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 69/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 70/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 71/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 72/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 73/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 74/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 75/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 76/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 77/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 78/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 79/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 80/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 81/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 82/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 83/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 84/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 85/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 86/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 87/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 88/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 89/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 90/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 91/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 92/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 93/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 94/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 95/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 96/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 97/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 98/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 99/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 100/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 101/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 102/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 103/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 104/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 105/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 106/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 107/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 108/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 109/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 110/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 111/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 112/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 113/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 114/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 115/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 116/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 117/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 118/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 119/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 120/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 121/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 122/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 123/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 124/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 125/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 126/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 127/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 128/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 129/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 130/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 131/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 132/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 133/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 134/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 135/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 136/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 137/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 138/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 139/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 140/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 141/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 142/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 143/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 144/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 145/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 146/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 147/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 148/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 149/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 150/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 151/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 152/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 153/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 154/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 155/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 156/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 157/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 158/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 159/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 160/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 161/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 162/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 163/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 164/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 165/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 166/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 167/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 168/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 169/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 170/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 171/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 172/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 173/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 174/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 175/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 176/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 177/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 178/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 179/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 180/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 181/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 182/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 183/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 184/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 185/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 186/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 187/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 188/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 189/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 190/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 191/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 192/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 193/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 194/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 195/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 196/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 197/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 198/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 199/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 200/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 201/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 202/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 203/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 204/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 205/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 206/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 207/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 208/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 209/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 210/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 211/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 212/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 213/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 214/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 215/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 216/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 217/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 218/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 219/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 220/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 221/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 222/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 223/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 224/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 225/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 226/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 227/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 228/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 229/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 230/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 231/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 232/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 233/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 234/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 235/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 236/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 237/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 238/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 239/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 240/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 241/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 242/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 243/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 244/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 245/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 246/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 247/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 248/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 249/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 250/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 251/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 252/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 253/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 254/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 255/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 256/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 257/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 258/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 259/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 260/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 261/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 262/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 263/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 264/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 265/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 266/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 267/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 268/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 269/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 270/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 271/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 272/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 273/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 274/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 275/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 276/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 277/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 278/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 279/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 280/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 281/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 282/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 283/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 284/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 285/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 286/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 287/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 288/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 289/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 290/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 291/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 292/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 293/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 294/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 295/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 296/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 297/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 298/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 299/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 300/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 301/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 302/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 303/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 304/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 305/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 306/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 307/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 308/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 309/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 310/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 311/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 312/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 313/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 314/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 315/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 316/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 317/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 318/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 319/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 320/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 321/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 322/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 323/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 324/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 325/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 326/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 327/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 328/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 329/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 330/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 331/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 332/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 333/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 334/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 335/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 336/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 337/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 338/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 339/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 340/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 341/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 342/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 343/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 344/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 345/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 346/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 347/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 348/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 349/500, Train Loss: 0.22830748157703568, Val Loss: 0.2161498589965763\n",
      "Epoch 350/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 351/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 352/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 353/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 354/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 355/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 356/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 357/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 358/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 359/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 360/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 361/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 362/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 363/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 364/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 365/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 366/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 367/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 368/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 369/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 370/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 371/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 372/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 373/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 374/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 375/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 376/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 377/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 378/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 379/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 380/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 381/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 382/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 383/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 384/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 385/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 386/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 387/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 388/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 389/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 390/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 391/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 392/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 393/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 394/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 395/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 396/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 397/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 398/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 399/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 400/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 401/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 402/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 403/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 404/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 405/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 406/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 407/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 408/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 409/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 410/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 411/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 412/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 413/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 414/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 415/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 416/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 417/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 418/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 419/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 420/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 421/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 422/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 423/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 424/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 425/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 426/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 427/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 428/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 429/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 430/500, Train Loss: 0.22830748157703604, Val Loss: 0.2161498589965763\n",
      "Epoch 431/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 432/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 433/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 434/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 435/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 436/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 437/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 438/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 439/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 440/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 441/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 442/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 443/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 444/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 445/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 446/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 447/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 448/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 449/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 450/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 451/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 452/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 453/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 454/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 455/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 456/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 457/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 458/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 459/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 460/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 461/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 462/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 463/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 464/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 465/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 466/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 467/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 468/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 469/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 470/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 471/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 472/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 473/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 474/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 475/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 476/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 477/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 478/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 479/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 480/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 481/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 482/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 483/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 484/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 485/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 486/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 487/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 488/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 489/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 490/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 491/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 492/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 493/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 494/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 495/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 496/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 497/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 498/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 499/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 500/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Returning from fit...\n",
      "Train Losses: [np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703573), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.22830748157703598), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770357), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.22830748157703598), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703598), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.22830748157703595), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.2283074815770357), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703595), np.float64(0.22830748157703581), np.float64(0.22830748157703593), np.float64(0.22830748157703598), np.float64(0.22830748157703573), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.22830748157703573), np.float64(0.22830748157703598), np.float64(0.22830748157703581), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.22830748157703573), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703598), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.2283074815770357), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703598), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703593), np.float64(0.22830748157703593), np.float64(0.22830748157703598), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703573), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.22830748157703595), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703595), np.float64(0.2283074815770358), np.float64(0.22830748157703573), np.float64(0.22830748157703593), np.float64(0.22830748157703593), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703595), np.float64(0.22830748157703595), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.22830748157703598), np.float64(0.2283074815770357), np.float64(0.2283074815770359), np.float64(0.22830748157703573), np.float64(0.22830748157703595), np.float64(0.22830748157703595), np.float64(0.22830748157703593), np.float64(0.2283074815770357), np.float64(0.22830748157703598), np.float64(0.22830748157703573), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703573), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703598), np.float64(0.22830748157703573), np.float64(0.2283074815770357), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.22830748157703573), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703573), np.float64(0.22830748157703581), np.float64(0.22830748157703598), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703598), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703598), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.2283074815770357), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.22830748157703595), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770357), np.float64(0.22830748157703573), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703573), np.float64(0.22830748157703573), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703573), np.float64(0.22830748157703573), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.2283074815770357), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.22830748157703573), np.float64(0.2283074815770358), np.float64(0.22830748157703573), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703598), np.float64(0.22830748157703584), np.float64(0.22830748157703598), np.float64(0.22830748157703581), np.float64(0.22830748157703573), np.float64(0.22830748157703595), np.float64(0.2283074815770358), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.22830748157703573), np.float64(0.22830748157703581), np.float64(0.22830748157703593), np.float64(0.22830748157703593), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703568), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.22830748157703573), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703573), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703573), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.2283074815770357), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.22830748157703573), np.float64(0.22830748157703581), np.float64(0.2283074815770357), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703595), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.22830748157703573), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703598), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.22830748157703593), np.float64(0.22830748157703595), np.float64(0.22830748157703604), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.22830748157703598), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703593), np.float64(0.22830748157703584), np.float64(0.22830748157703573), np.float64(0.2283074815770358), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.22830748157703598), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.22830748157703595), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703598), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.2283074815770359)]\n",
      "Validation Losses: [np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763)]\n",
      "Epoch 1/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 2/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 3/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 4/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 5/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 6/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 7/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 8/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 9/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 10/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 11/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 12/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 13/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 14/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 15/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 16/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 17/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 18/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 19/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 20/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 21/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 22/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 23/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 24/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 25/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 26/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 27/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 28/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 29/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 30/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 31/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 32/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 33/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 34/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 35/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 36/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 37/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 38/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 39/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 40/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 41/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 42/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 43/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 44/500, Train Loss: 0.22830748157703604, Val Loss: 0.2161498589965763\n",
      "Epoch 45/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 46/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 47/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 48/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 49/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 50/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 51/500, Train Loss: 0.22830748157703604, Val Loss: 0.2161498589965763\n",
      "Epoch 52/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 53/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 54/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 55/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 56/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 57/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 58/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 59/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 60/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 61/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 62/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 63/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 64/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 65/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 66/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 67/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 68/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 69/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 70/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 71/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 72/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 73/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 74/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 75/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 76/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 77/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 78/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 79/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 80/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 81/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 82/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 83/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 84/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 85/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 86/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 87/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 88/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 89/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 90/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 91/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 92/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 93/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 94/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 95/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 96/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 97/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 98/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 99/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 100/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 101/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 102/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 103/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 104/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 105/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 106/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 107/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 108/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 109/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 110/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 111/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 112/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 113/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 114/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 115/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 116/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 117/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 118/500, Train Loss: 0.22830748157703606, Val Loss: 0.2161498589965763\n",
      "Epoch 119/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 120/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 121/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 122/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 123/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 124/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 125/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 126/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 127/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 128/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 129/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 130/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 131/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 132/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 133/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 134/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 135/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 136/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 137/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 138/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 139/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 140/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 141/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 142/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 143/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 144/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 145/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 146/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 147/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 148/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 149/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 150/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 151/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 152/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 153/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 154/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 155/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 156/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 157/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 158/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 159/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 160/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 161/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 162/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 163/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 164/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 165/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 166/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 167/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 168/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 169/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 170/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 171/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 172/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 173/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 174/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 175/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 176/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 177/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 178/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 179/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 180/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 181/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 182/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 183/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 184/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 185/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 186/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 187/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 188/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 189/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 190/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 191/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 192/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 193/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 194/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 195/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 196/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 197/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 198/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 199/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 200/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 201/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 202/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 203/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 204/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 205/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 206/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 207/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 208/500, Train Loss: 0.22830748157703604, Val Loss: 0.2161498589965763\n",
      "Epoch 209/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 210/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 211/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 212/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 213/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 214/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 215/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 216/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 217/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 218/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 219/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 220/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 221/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 222/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 223/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 224/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 225/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 226/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 227/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 228/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 229/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 230/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 231/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 232/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 233/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 234/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 235/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 236/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 237/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 238/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 239/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 240/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 241/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 242/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 243/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 244/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 245/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 246/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 247/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 248/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 249/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 250/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 251/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 252/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 253/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 254/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 255/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 256/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 257/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 258/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 259/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 260/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 261/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 262/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 263/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 264/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 265/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 266/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 267/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 268/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 269/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 270/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 271/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 272/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 273/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 274/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 275/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 276/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 277/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 278/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 279/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 280/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 281/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 282/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 283/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 284/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 285/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 286/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 287/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 288/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 289/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 290/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 291/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 292/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 293/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 294/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 295/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 296/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 297/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 298/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 299/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 300/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 301/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 302/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 303/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 304/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 305/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 306/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 307/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 308/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 309/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 310/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 311/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 312/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 313/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 314/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 315/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 316/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 317/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 318/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 319/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 320/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 321/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 322/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 323/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 324/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 325/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 326/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 327/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 328/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 329/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 330/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 331/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 332/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 333/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 334/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 335/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 336/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 337/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 338/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 339/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 340/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 341/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 342/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 343/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 344/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 345/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 346/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 347/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 348/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 349/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 350/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 351/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 352/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 353/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 354/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 355/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 356/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 357/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 358/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 359/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 360/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 361/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 362/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 363/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 364/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 365/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 366/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 367/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 368/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 369/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 370/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 371/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 372/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 373/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 374/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 375/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 376/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 377/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 378/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 379/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 380/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 381/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 382/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 383/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 384/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 385/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 386/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 387/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 388/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 389/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 390/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 391/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 392/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 393/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 394/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 395/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 396/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 397/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 398/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 399/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 400/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 401/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 402/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 403/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 404/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 405/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 406/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 407/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 408/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 409/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 410/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 411/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 412/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 413/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 414/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 415/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 416/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 417/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 418/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 419/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 420/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 421/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 422/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 423/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 424/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 425/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 426/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 427/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 428/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 429/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 430/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 431/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 432/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 433/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 434/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 435/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 436/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 437/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 438/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 439/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 440/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 441/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 442/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 443/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 444/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 445/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 446/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 447/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 448/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 449/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 450/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 451/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 452/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 453/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 454/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 455/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 456/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 457/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 458/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 459/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 460/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 461/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 462/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 463/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 464/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 465/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 466/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 467/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 468/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 469/500, Train Loss: 0.22830748157703604, Val Loss: 0.2161498589965763\n",
      "Epoch 470/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 471/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 472/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 473/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 474/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 475/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 476/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 477/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 478/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 479/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 480/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 481/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 482/500, Train Loss: 0.22830748157703598, Val Loss: 0.2161498589965763\n",
      "Epoch 483/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 484/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 485/500, Train Loss: 0.22830748157703573, Val Loss: 0.2161498589965763\n",
      "Epoch 486/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 487/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 488/500, Train Loss: 0.22830748157703595, Val Loss: 0.2161498589965763\n",
      "Epoch 489/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 490/500, Train Loss: 0.2283074815770358, Val Loss: 0.2161498589965763\n",
      "Epoch 491/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 492/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 493/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 494/500, Train Loss: 0.22830748157703581, Val Loss: 0.2161498589965763\n",
      "Epoch 495/500, Train Loss: 0.2283074815770357, Val Loss: 0.2161498589965763\n",
      "Epoch 496/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 497/500, Train Loss: 0.22830748157703584, Val Loss: 0.2161498589965763\n",
      "Epoch 498/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Epoch 499/500, Train Loss: 0.2283074815770359, Val Loss: 0.2161498589965763\n",
      "Epoch 500/500, Train Loss: 0.22830748157703593, Val Loss: 0.2161498589965763\n",
      "Returning from fit...\n",
      "Train Losses: [np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703595), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770357), np.float64(0.22830748157703593), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.2283074815770357), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703573), np.float64(0.22830748157703581), np.float64(0.22830748157703598), np.float64(0.2283074815770357), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703573), np.float64(0.22830748157703595), np.float64(0.2283074815770357), np.float64(0.22830748157703598), np.float64(0.22830748157703595), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703593), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.22830748157703604), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.22830748157703598), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.22830748157703604), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703573), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703598), np.float64(0.22830748157703573), np.float64(0.2283074815770357), np.float64(0.22830748157703593), np.float64(0.22830748157703573), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.22830748157703598), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.2283074815770358), np.float64(0.2283074815770357), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.22830748157703573), np.float64(0.22830748157703573), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703606), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703595), np.float64(0.22830748157703573), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703595), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703573), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703598), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.22830748157703595), np.float64(0.22830748157703595), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.22830748157703598), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.22830748157703584), np.float64(0.22830748157703573), np.float64(0.2283074815770358), np.float64(0.22830748157703595), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770357), np.float64(0.2283074815770359), np.float64(0.2283074815770357), np.float64(0.22830748157703593), np.float64(0.2283074815770357), np.float64(0.2283074815770357), np.float64(0.2283074815770359), np.float64(0.2283074815770357), np.float64(0.22830748157703593), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.22830748157703595), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703595), np.float64(0.2283074815770358), np.float64(0.22830748157703604), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.2283074815770357), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703573), np.float64(0.22830748157703573), np.float64(0.22830748157703581), np.float64(0.22830748157703598), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703573), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703598), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703598), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.22830748157703584), np.float64(0.22830748157703573), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.22830748157703595), np.float64(0.2283074815770357), np.float64(0.22830748157703598), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703573), np.float64(0.22830748157703598), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703598), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.22830748157703595), np.float64(0.22830748157703595), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703573), np.float64(0.22830748157703595), np.float64(0.22830748157703593), np.float64(0.22830748157703598), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703598), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703573), np.float64(0.2283074815770359), np.float64(0.22830748157703573), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.22830748157703598), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.2283074815770357), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703581), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.22830748157703593), np.float64(0.22830748157703573), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.22830748157703573), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703593), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.22830748157703573), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703598), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770357), np.float64(0.22830748157703573), np.float64(0.2283074815770358), np.float64(0.2283074815770357), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703598), np.float64(0.22830748157703581), np.float64(0.22830748157703593), np.float64(0.2283074815770357), np.float64(0.2283074815770359), np.float64(0.22830748157703598), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.22830748157703584), np.float64(0.2283074815770358), np.float64(0.2283074815770357), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703598), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.22830748157703581), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.22830748157703595), np.float64(0.22830748157703593), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.22830748157703584), np.float64(0.2283074815770357), np.float64(0.22830748157703573), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.22830748157703598), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.22830748157703598), np.float64(0.2283074815770359), np.float64(0.2283074815770358), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.22830748157703573), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.22830748157703573), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.22830748157703595), np.float64(0.2283074815770359), np.float64(0.22830748157703593), np.float64(0.22830748157703573), np.float64(0.22830748157703604), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.2283074815770359), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703598), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.22830748157703593), np.float64(0.2283074815770358), np.float64(0.2283074815770358), np.float64(0.2283074815770359), np.float64(0.22830748157703598), np.float64(0.22830748157703584), np.float64(0.22830748157703584), np.float64(0.22830748157703573), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703595), np.float64(0.22830748157703581), np.float64(0.2283074815770358), np.float64(0.22830748157703581), np.float64(0.2283074815770359), np.float64(0.22830748157703581), np.float64(0.22830748157703581), np.float64(0.2283074815770357), np.float64(0.2283074815770359), np.float64(0.22830748157703584), np.float64(0.22830748157703593), np.float64(0.2283074815770359), np.float64(0.22830748157703593)]\n",
      "Validation Losses: [np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763), np.float64(0.2161498589965763)]\n",
      "Epoch 1/500, Train Loss: 0.06320291364261621, Val Loss: 0.06518888642217772\n",
      "Epoch 2/500, Train Loss: 0.05020025010534154, Val Loss: 0.05629018532091398\n",
      "Epoch 3/500, Train Loss: 0.04942633118610035, Val Loss: 0.0564713719758158\n",
      "Epoch 4/500, Train Loss: 0.04935746570122979, Val Loss: 0.056869450461367016\n",
      "Epoch 5/500, Train Loss: 0.049362026430470475, Val Loss: 0.05692304207217695\n",
      "Epoch 6/500, Train Loss: 0.04935626619653176, Val Loss: 0.05684858229818921\n",
      "Epoch 7/500, Train Loss: 0.04936385456643296, Val Loss: 0.05693975130296706\n",
      "Epoch 8/500, Train Loss: 0.04935606561750327, Val Loss: 0.056844362935108694\n",
      "Epoch 9/500, Train Loss: 0.04935494374113121, Val Loss: 0.05680759148495548\n",
      "Epoch 10/500, Train Loss: 0.04935484999011613, Val Loss: 0.05679882721910478\n",
      "Epoch 11/500, Train Loss: 0.0493556107367544, Val Loss: 0.05683336999184911\n",
      "Epoch 12/500, Train Loss: 0.049360787159948405, Val Loss: 0.05691059469797179\n",
      "Epoch 13/500, Train Loss: 0.04936356281906032, Val Loss: 0.056937190087592245\n",
      "Epoch 14/500, Train Loss: 0.049354847115538406, Val Loss: 0.05678473142717097\n",
      "Epoch 15/500, Train Loss: 0.0493550125465847, Val Loss: 0.05677168637897442\n",
      "Epoch 16/500, Train Loss: 0.04936097460070241, Val Loss: 0.056912546733782\n",
      "Epoch 17/500, Train Loss: 0.04935668005213692, Val Loss: 0.056856472150273535\n",
      "Epoch 18/500, Train Loss: 0.049355361382770975, Val Loss: 0.056825984351398275\n",
      "Epoch 19/500, Train Loss: 0.049357527349146266, Val Loss: 0.05671810169448068\n",
      "Epoch 20/500, Train Loss: 0.04935485390959912, Val Loss: 0.056799388231799884\n",
      "Epoch 21/500, Train Loss: 0.04936464441025726, Val Loss: 0.056946498824888184\n",
      "Epoch 22/500, Train Loss: 0.04935545780681791, Val Loss: 0.056755333693362886\n",
      "Epoch 23/500, Train Loss: 0.0493551824442078, Val Loss: 0.05676421678712507\n",
      "Epoch 24/500, Train Loss: 0.04935484572504523, Val Loss: 0.05678495104705858\n",
      "Epoch 25/500, Train Loss: 0.04935482603344417, Val Loss: 0.05679271689535212\n",
      "Epoch 26/500, Train Loss: 0.0493551980211819, Val Loss: 0.05682018409605729\n",
      "Epoch 27/500, Train Loss: 0.04935483305864312, Val Loss: 0.05679559933559431\n",
      "Epoch 28/500, Train Loss: 0.04935483946877747, Val Loss: 0.056797037284127834\n",
      "Epoch 29/500, Train Loss: 0.04935494818460559, Val Loss: 0.056775417737977146\n",
      "Epoch 30/500, Train Loss: 0.049363180489300544, Val Loss: 0.05693376416668745\n",
      "Epoch 31/500, Train Loss: 0.04935611557121937, Val Loss: 0.05684542648684393\n",
      "Epoch 32/500, Train Loss: 0.049363541153608255, Val Loss: 0.056663498076668005\n",
      "Epoch 33/500, Train Loss: 0.04936978239482825, Val Loss: 0.056627349674865456\n",
      "Epoch 34/500, Train Loss: 0.04935896433871765, Val Loss: 0.05688989598341068\n",
      "Epoch 35/500, Train Loss: 0.0493594840589094, Val Loss: 0.056696210930032416\n",
      "Epoch 36/500, Train Loss: 0.049354863738640065, Val Loss: 0.0568006332712663\n",
      "Epoch 37/500, Train Loss: 0.049367202202430065, Val Loss: 0.05696685307938601\n",
      "Epoch 38/500, Train Loss: 0.049367227149237476, Val Loss: 0.056967042172762036\n",
      "Epoch 39/500, Train Loss: 0.04936212502970777, Val Loss: 0.05692396699209456\n",
      "Epoch 40/500, Train Loss: 0.049355814056549284, Val Loss: 0.056838568965666456\n",
      "Epoch 41/500, Train Loss: 0.04935491508155736, Val Loss: 0.056777743893165235\n",
      "Epoch 42/500, Train Loss: 0.0493602421564515, Val Loss: 0.056904743014706397\n",
      "Epoch 43/500, Train Loss: 0.049365579882807945, Val Loss: 0.05665038349616716\n",
      "Epoch 44/500, Train Loss: 0.04935573216502094, Val Loss: 0.056748325792995435\n",
      "Epoch 45/500, Train Loss: 0.04936126331495307, Val Loss: 0.056915486914058906\n",
      "Epoch 46/500, Train Loss: 0.04937281230307039, Val Loss: 0.05700595262271677\n",
      "Epoch 47/500, Train Loss: 0.04936613890440664, Val Loss: 0.05695863301064808\n",
      "Epoch 48/500, Train Loss: 0.049364777870898956, Val Loss: 0.05694760065383473\n",
      "Epoch 49/500, Train Loss: 0.04936734996637918, Val Loss: 0.05696797067559079\n",
      "Epoch 50/500, Train Loss: 0.04936171469278202, Val Loss: 0.05667684084604916\n",
      "Epoch 51/500, Train Loss: 0.04935497393492959, Val Loss: 0.056773822374201546\n",
      "Epoch 52/500, Train Loss: 0.049354886938201975, Val Loss: 0.05680307755215466\n",
      "Epoch 53/500, Train Loss: 0.04936857634225048, Val Loss: 0.05697703501720744\n",
      "Epoch 54/500, Train Loss: 0.049355698765741945, Val Loss: 0.056835685168193345\n",
      "Epoch 55/500, Train Loss: 0.049363124654477106, Val Loss: 0.056666388835242706\n",
      "Epoch 56/500, Train Loss: 0.04935938933281761, Val Loss: 0.056697137726619135\n",
      "Epoch 57/500, Train Loss: 0.04935562339343392, Val Loss: 0.05675094674048622\n",
      "Epoch 58/500, Train Loss: 0.049376440051574794, Val Loss: 0.05702848081236092\n",
      "Epoch 59/500, Train Loss: 0.049360914283847104, Val Loss: 0.0569119075450835\n",
      "Epoch 60/500, Train Loss: 0.04935974794790333, Val Loss: 0.05689921325592935\n",
      "Epoch 61/500, Train Loss: 0.04935912761845625, Val Loss: 0.05689189977840964\n",
      "Epoch 62/500, Train Loss: 0.04935500750148755, Val Loss: 0.05681147309739786\n",
      "Epoch 63/500, Train Loss: 0.04936698496158901, Val Loss: 0.05696519903655093\n",
      "Epoch 64/500, Train Loss: 0.049354904849464226, Val Loss: 0.05677854817354049\n",
      "Epoch 65/500, Train Loss: 0.04935533262297364, Val Loss: 0.05682502007606624\n",
      "Epoch 66/500, Train Loss: 0.04936721999896844, Val Loss: 0.05696698745614123\n",
      "Epoch 67/500, Train Loss: 0.049374191897520125, Val Loss: 0.05701472594657366\n",
      "Epoch 68/500, Train Loss: 0.049355479797680894, Val Loss: 0.056829648521569326\n",
      "Epoch 69/500, Train Loss: 0.04935584110045922, Val Loss: 0.05683922111678801\n",
      "Epoch 70/500, Train Loss: 0.04936769707593174, Val Loss: 0.05697057304447851\n",
      "Epoch 71/500, Train Loss: 0.049354965242029245, Val Loss: 0.056808985998040865\n",
      "Epoch 72/500, Train Loss: 0.04936537348528605, Val Loss: 0.056651641127007116\n",
      "Epoch 73/500, Train Loss: 0.04936126274244144, Val Loss: 0.056680443624798134\n",
      "Epoch 74/500, Train Loss: 0.04936624844908813, Val Loss: 0.05664640118039433\n",
      "Epoch 75/500, Train Loss: 0.04937010786234715, Val Loss: 0.05662573604298302\n",
      "Epoch 76/500, Train Loss: 0.04937051579484776, Val Loss: 0.056623743224685885\n",
      "Epoch 77/500, Train Loss: 0.04935661450497876, Val Loss: 0.05673135941597747\n",
      "Epoch 78/500, Train Loss: 0.049355033209535756, Val Loss: 0.05677061719677406\n",
      "Epoch 79/500, Train Loss: 0.0493549279283719, Val Loss: 0.0567767952633833\n",
      "Epoch 80/500, Train Loss: 0.04938331240252114, Val Loss: 0.05657279605909271\n",
      "Epoch 81/500, Train Loss: 0.04935875397332067, Val Loss: 0.05670364725216334\n",
      "Epoch 82/500, Train Loss: 0.04935487297002866, Val Loss: 0.05678146874853479\n",
      "Epoch 83/500, Train Loss: 0.04936146525209922, Val Loss: 0.0566788117322032\n",
      "Epoch 84/500, Train Loss: 0.049359509304735406, Val Loss: 0.056896451864352285\n",
      "Epoch 85/500, Train Loss: 0.04935485555487384, Val Loss: 0.05678350999174684\n",
      "Epoch 86/500, Train Loss: 0.04935585920369955, Val Loss: 0.05674546331412692\n",
      "Epoch 87/500, Train Loss: 0.04935972436578078, Val Loss: 0.05669390419691757\n",
      "Epoch 88/500, Train Loss: 0.049357911094014176, Val Loss: 0.056713246571877624\n",
      "Epoch 89/500, Train Loss: 0.04935482905530228, Val Loss: 0.05679433207554649\n",
      "Epoch 90/500, Train Loss: 0.0493560692770624, Val Loss: 0.056741109554797504\n",
      "Epoch 91/500, Train Loss: 0.049362027881281155, Val Loss: 0.05692303310930915\n",
      "Epoch 92/500, Train Loss: 0.04935661205199913, Val Loss: 0.05685522265531412\n",
      "Epoch 93/500, Train Loss: 0.04935727493370415, Val Loss: 0.05672148098583912\n",
      "Epoch 94/500, Train Loss: 0.04936614217058522, Val Loss: 0.056958657471721005\n",
      "Epoch 95/500, Train Loss: 0.04935640290870046, Val Loss: 0.05685127706206237\n",
      "Epoch 96/500, Train Loss: 0.049398833039267134, Val Loss: 0.057142798925569144\n",
      "Epoch 97/500, Train Loss: 0.04938492503308838, Val Loss: 0.05707574014262984\n",
      "Epoch 98/500, Train Loss: 0.0493730958308773, Val Loss: 0.057007776873839414\n",
      "Epoch 99/500, Train Loss: 0.04935808082846151, Val Loss: 0.056878350710600635\n",
      "Epoch 100/500, Train Loss: 0.04935709795073835, Val Loss: 0.056723971782010905\n",
      "Epoch 101/500, Train Loss: 0.04936516345811035, Val Loss: 0.056652935685903835\n",
      "Epoch 102/500, Train Loss: 0.04936075098359424, Val Loss: 0.05691019992542902\n",
      "Epoch 103/500, Train Loss: 0.049354837426163096, Val Loss: 0.056786454323509504\n",
      "Epoch 104/500, Train Loss: 0.04936399482375196, Val Loss: 0.05666043680477602\n",
      "Epoch 105/500, Train Loss: 0.04936073654838873, Val Loss: 0.05691004799667002\n",
      "Epoch 106/500, Train Loss: 0.04935750123687147, Val Loss: 0.056869967176507406\n",
      "Epoch 107/500, Train Loss: 0.04936800709843963, Val Loss: 0.05697287141585407\n",
      "Epoch 108/500, Train Loss: 0.04935523126582831, Val Loss: 0.05682143835289367\n",
      "Epoch 109/500, Train Loss: 0.049355943877356936, Val Loss: 0.0567436568246994\n",
      "Epoch 110/500, Train Loss: 0.04936937173486394, Val Loss: 0.056629413990038714\n",
      "Epoch 111/500, Train Loss: 0.04936269868379749, Val Loss: 0.05666943099061049\n",
      "Epoch 112/500, Train Loss: 0.04935567255282389, Val Loss: 0.0568350029387654\n",
      "Epoch 113/500, Train Loss: 0.04935601110742599, Val Loss: 0.056843145724420764\n",
      "Epoch 114/500, Train Loss: 0.04940850362918701, Val Loss: 0.05718455447971363\n",
      "Epoch 115/500, Train Loss: 0.04935755879913637, Val Loss: 0.0568708351959074\n",
      "Epoch 116/500, Train Loss: 0.04936640804654683, Val Loss: 0.05696074258925615\n",
      "Epoch 117/500, Train Loss: 0.049364430833340134, Val Loss: 0.05694468159847417\n",
      "Epoch 118/500, Train Loss: 0.049355650917973615, Val Loss: 0.05675026514201233\n",
      "Epoch 119/500, Train Loss: 0.04935618648751763, Val Loss: 0.05673884712236923\n",
      "Epoch 120/500, Train Loss: 0.04935482870433904, Val Loss: 0.056794193905935965\n",
      "Epoch 121/500, Train Loss: 0.04935495504571205, Val Loss: 0.056774975107303984\n",
      "Epoch 122/500, Train Loss: 0.04935485376394296, Val Loss: 0.056799354226538534\n",
      "Epoch 123/500, Train Loss: 0.049354848128775705, Val Loss: 0.05679853097764199\n",
      "Epoch 124/500, Train Loss: 0.04936028945721326, Val Loss: 0.056688717223697845\n",
      "Epoch 125/500, Train Loss: 0.04937629637590903, Val Loss: 0.057027618317425526\n",
      "Epoch 126/500, Train Loss: 0.04936581749984862, Val Loss: 0.05695608066329735\n",
      "Epoch 127/500, Train Loss: 0.04935735208134642, Val Loss: 0.05672042475071807\n",
      "Epoch 128/500, Train Loss: 0.04937185195934803, Val Loss: 0.0566174260003125\n",
      "Epoch 129/500, Train Loss: 0.049359083834655725, Val Loss: 0.05689136413172414\n",
      "Epoch 130/500, Train Loss: 0.04935482598435158, Val Loss: 0.05679039406275935\n",
      "Epoch 131/500, Train Loss: 0.049355109085409694, Val Loss: 0.05676713652254102\n",
      "Epoch 132/500, Train Loss: 0.04935493085526863, Val Loss: 0.0567765866987605\n",
      "Epoch 133/500, Train Loss: 0.04935566365280593, Val Loss: 0.05674995410621756\n",
      "Epoch 134/500, Train Loss: 0.04935482995168019, Val Loss: 0.05678839923038985\n",
      "Epoch 135/500, Train Loss: 0.049357328208235005, Val Loss: 0.05672074922218748\n",
      "Epoch 136/500, Train Loss: 0.049356649411910404, Val Loss: 0.056855902813604225\n",
      "Epoch 137/500, Train Loss: 0.049354960115554854, Val Loss: 0.056808658908157346\n",
      "Epoch 138/500, Train Loss: 0.04935691361259771, Val Loss: 0.05686054419125484\n",
      "Epoch 139/500, Train Loss: 0.04937041634015029, Val Loss: 0.0569900030121203\n",
      "Epoch 140/500, Train Loss: 0.04935894353313991, Val Loss: 0.05688963550933123\n",
      "Epoch 141/500, Train Loss: 0.04937377995117507, Val Loss: 0.05660882271522384\n",
      "Epoch 142/500, Train Loss: 0.04936561598076653, Val Loss: 0.056650162649887106\n",
      "Epoch 143/500, Train Loss: 0.04935635271090599, Val Loss: 0.05685029230775676\n",
      "Epoch 144/500, Train Loss: 0.04935503220982583, Val Loss: 0.056812793841497546\n",
      "Epoch 145/500, Train Loss: 0.0493578165025479, Val Loss: 0.056874620252761555\n",
      "Epoch 146/500, Train Loss: 0.0493579731126855, Val Loss: 0.05687684717352921\n",
      "Epoch 147/500, Train Loss: 0.04935514366799445, Val Loss: 0.056765709885873906\n",
      "Epoch 148/500, Train Loss: 0.049364990310285205, Val Loss: 0.05665401363174296\n",
      "Epoch 149/500, Train Loss: 0.04935482773586241, Val Loss: 0.0567892814890423\n",
      "Epoch 150/500, Train Loss: 0.04937056024094277, Val Loss: 0.05662352613830166\n",
      "Epoch 151/500, Train Loss: 0.04936522470803566, Val Loss: 0.05665255495147229\n",
      "Epoch 152/500, Train Loss: 0.04935491103061258, Val Loss: 0.05680516258034726\n",
      "Epoch 153/500, Train Loss: 0.04935560067711979, Val Loss: 0.05675151416909741\n",
      "Epoch 154/500, Train Loss: 0.049364687531499626, Val Loss: 0.056655926534512895\n",
      "Epoch 155/500, Train Loss: 0.04935489022490706, Val Loss: 0.0568033806662553\n",
      "Epoch 156/500, Train Loss: 0.04935488150120011, Val Loss: 0.056780606420611945\n",
      "Epoch 157/500, Train Loss: 0.049374987256703175, Val Loss: 0.05701966134162574\n",
      "Epoch 158/500, Train Loss: 0.049362448609203045, Val Loss: 0.05692703022560118\n",
      "Epoch 159/500, Train Loss: 0.04935918596529395, Val Loss: 0.056892603785555135\n",
      "Epoch 160/500, Train Loss: 0.04935514061040478, Val Loss: 0.056817841911661296\n",
      "Epoch 161/500, Train Loss: 0.0493550478429058, Val Loss: 0.056769898205109096\n",
      "Epoch 162/500, Train Loss: 0.04935589903632633, Val Loss: 0.056840588514560135\n",
      "Epoch 163/500, Train Loss: 0.049356623776106695, Val Loss: 0.056731205417805255\n",
      "Epoch 164/500, Train Loss: 0.0493581422741454, Val Loss: 0.056710482224312256\n",
      "Epoch 165/500, Train Loss: 0.049358022710135924, Val Loss: 0.056711896927472374\n",
      "Epoch 166/500, Train Loss: 0.049375507732839885, Val Loss: 0.05660155874015394\n",
      "Epoch 167/500, Train Loss: 0.04935482539262778, Val Loss: 0.05679155219504389\n",
      "Epoch 168/500, Train Loss: 0.049355430626215606, Val Loss: 0.05682816017814027\n",
      "Epoch 169/500, Train Loss: 0.04935641293961589, Val Loss: 0.05685146823347614\n",
      "Epoch 170/500, Train Loss: 0.049379752766126245, Val Loss: 0.05658519433169744\n",
      "Epoch 171/500, Train Loss: 0.04937471299721572, Val Loss: 0.05701796619331481\n",
      "Epoch 172/500, Train Loss: 0.04935736779960511, Val Loss: 0.056867916816424946\n",
      "Epoch 173/500, Train Loss: 0.049360402197014486, Val Loss: 0.0566877159517561\n",
      "Epoch 174/500, Train Loss: 0.049354885808843646, Val Loss: 0.05678019600638117\n",
      "Epoch 175/500, Train Loss: 0.04935824945652209, Val Loss: 0.05670923635339898\n",
      "Epoch 176/500, Train Loss: 0.04935810805649556, Val Loss: 0.05671088321966859\n",
      "Epoch 177/500, Train Loss: 0.04936708188785727, Val Loss: 0.056965932745233164\n",
      "Epoch 178/500, Train Loss: 0.049358465337268884, Val Loss: 0.05688352844642184\n",
      "Epoch 179/500, Train Loss: 0.04935592926645348, Val Loss: 0.056841287946271704\n",
      "Epoch 180/500, Train Loss: 0.04935950987332206, Val Loss: 0.05689645341683432\n",
      "Epoch 181/500, Train Loss: 0.04935700491236944, Val Loss: 0.05686207935877743\n",
      "Epoch 182/500, Train Loss: 0.04935819324870841, Val Loss: 0.05670988584706363\n",
      "Epoch 183/500, Train Loss: 0.04935684496457328, Val Loss: 0.056727715704735136\n",
      "Epoch 184/500, Train Loss: 0.04935497186282052, Val Loss: 0.056809392173836085\n",
      "Epoch 185/500, Train Loss: 0.04935607382275882, Val Loss: 0.056741015071040735\n",
      "Epoch 186/500, Train Loss: 0.04935624939676895, Val Loss: 0.05684821504638329\n",
      "Epoch 187/500, Train Loss: 0.0493566811715517, Val Loss: 0.056856472276808796\n",
      "Epoch 188/500, Train Loss: 0.04936363412459633, Val Loss: 0.0569377970920967\n",
      "Epoch 189/500, Train Loss: 0.049361694238220837, Val Loss: 0.0569197799434214\n",
      "Epoch 190/500, Train Loss: 0.049358257213101234, Val Loss: 0.056880755213292326\n",
      "Epoch 191/500, Train Loss: 0.0493816768532647, Val Loss: 0.05705838231592716\n",
      "Epoch 192/500, Train Loss: 0.04935483139920215, Val Loss: 0.05679511268952168\n",
      "Epoch 193/500, Train Loss: 0.049366694237966205, Val Loss: 0.05664381611148145\n",
      "Epoch 194/500, Train Loss: 0.049379288411355915, Val Loss: 0.05658689192110075\n",
      "Epoch 195/500, Train Loss: 0.049365630514137615, Val Loss: 0.05695457544640512\n",
      "Epoch 196/500, Train Loss: 0.04936459391405162, Val Loss: 0.05694605134124935\n",
      "Epoch 197/500, Train Loss: 0.04935893569967747, Val Loss: 0.056701723495116436\n",
      "Epoch 198/500, Train Loss: 0.04936584120746262, Val Loss: 0.056956262912229355\n",
      "Epoch 199/500, Train Loss: 0.049358110354476584, Val Loss: 0.05671085362109789\n",
      "Epoch 200/500, Train Loss: 0.049354979620815344, Val Loss: 0.056809860963727477\n",
      "Epoch 201/500, Train Loss: 0.049361977948129764, Val Loss: 0.05692254344115727\n",
      "Epoch 202/500, Train Loss: 0.04936730155910002, Val Loss: 0.05664039074522581\n",
      "Epoch 203/500, Train Loss: 0.049355114932183544, Val Loss: 0.05676688350513393\n",
      "Epoch 204/500, Train Loss: 0.049355072202589334, Val Loss: 0.0567687530956369\n",
      "Epoch 205/500, Train Loss: 0.049355828565015754, Val Loss: 0.056746128527519785\n",
      "Epoch 206/500, Train Loss: 0.049366098552447356, Val Loss: 0.05695830418253767\n",
      "Epoch 207/500, Train Loss: 0.04936104300938903, Val Loss: 0.05691322803032002\n",
      "Epoch 208/500, Train Loss: 0.04935500683526248, Val Loss: 0.05681142650661077\n",
      "Epoch 209/500, Train Loss: 0.04936252290769232, Val Loss: 0.056927719409437964\n",
      "Epoch 210/500, Train Loss: 0.04936429314684268, Val Loss: 0.05694350210780835\n",
      "Epoch 211/500, Train Loss: 0.049355994554158754, Val Loss: 0.05684276690349051\n",
      "Epoch 212/500, Train Loss: 0.04935525764018685, Val Loss: 0.056761496069687264\n",
      "Epoch 213/500, Train Loss: 0.04935601366742, Val Loss: 0.056843193361808646\n",
      "Epoch 214/500, Train Loss: 0.0493571977704535, Val Loss: 0.05686522836337308\n",
      "Epoch 215/500, Train Loss: 0.04935515193753684, Val Loss: 0.05681830876427166\n",
      "Epoch 216/500, Train Loss: 0.04935551431451933, Val Loss: 0.05683064760202096\n",
      "Epoch 217/500, Train Loss: 0.049358029543632956, Val Loss: 0.056711809238661016\n",
      "Epoch 218/500, Train Loss: 0.049361395685238056, Val Loss: 0.056916808942914676\n",
      "Epoch 219/500, Train Loss: 0.049354825895029035, Val Loss: 0.056792537585316556\n",
      "Epoch 220/500, Train Loss: 0.049354825641050294, Val Loss: 0.056792221683316546\n",
      "Epoch 221/500, Train Loss: 0.04938021235655306, Val Loss: 0.0565835263804366\n",
      "Epoch 222/500, Train Loss: 0.04936890025304672, Val Loss: 0.05663182050350438\n",
      "Epoch 223/500, Train Loss: 0.049357496449416303, Val Loss: 0.05671848578416825\n",
      "Epoch 224/500, Train Loss: 0.04935496507206081, Val Loss: 0.056808962403628815\n",
      "Epoch 225/500, Train Loss: 0.04935641702283207, Val Loss: 0.056851538619400815\n",
      "Epoch 226/500, Train Loss: 0.04937942445703433, Val Loss: 0.05704583584606264\n",
      "Epoch 227/500, Train Loss: 0.049378209021109475, Val Loss: 0.057038872945553216\n",
      "Epoch 228/500, Train Loss: 0.04936523212086243, Val Loss: 0.05695133736254359\n",
      "Epoch 229/500, Train Loss: 0.04937585326459515, Val Loss: 0.05702493508641299\n",
      "Epoch 230/500, Train Loss: 0.04935587037836967, Val Loss: 0.05683990445049366\n",
      "Epoch 231/500, Train Loss: 0.0493599511945371, Val Loss: 0.056691773323791855\n",
      "Epoch 232/500, Train Loss: 0.04935890912072356, Val Loss: 0.056701995539601986\n",
      "Epoch 233/500, Train Loss: 0.04935532968541807, Val Loss: 0.05675912439979128\n",
      "Epoch 234/500, Train Loss: 0.049362221082993346, Val Loss: 0.05667294589014014\n",
      "Epoch 235/500, Train Loss: 0.049360969554881, Val Loss: 0.05668284560951463\n",
      "Epoch 236/500, Train Loss: 0.04937107312808352, Val Loss: 0.05662105899835967\n",
      "Epoch 237/500, Train Loss: 0.04936317050191276, Val Loss: 0.056666053648198995\n",
      "Epoch 238/500, Train Loss: 0.04936152571737807, Val Loss: 0.056678317478571986\n",
      "Epoch 239/500, Train Loss: 0.049356419306400584, Val Loss: 0.05685157932760112\n",
      "Epoch 240/500, Train Loss: 0.04935743716858873, Val Loss: 0.05671926786536689\n",
      "Epoch 241/500, Train Loss: 0.0493553937394993, Val Loss: 0.05682699502441686\n",
      "Epoch 242/500, Train Loss: 0.04935844462559099, Val Loss: 0.05670701273635638\n",
      "Epoch 243/500, Train Loss: 0.04936133967900605, Val Loss: 0.056679806518110706\n",
      "Epoch 244/500, Train Loss: 0.04935483641077092, Val Loss: 0.05679637459278981\n",
      "Epoch 245/500, Train Loss: 0.04936024602605813, Val Loss: 0.05690476623157803\n",
      "Epoch 246/500, Train Loss: 0.0493645063952934, Val Loss: 0.056945302528209736\n",
      "Epoch 247/500, Train Loss: 0.04936460321295817, Val Loss: 0.05694611786957303\n",
      "Epoch 248/500, Train Loss: 0.049358808796357845, Val Loss: 0.05688793304798406\n",
      "Epoch 249/500, Train Loss: 0.049355336733450314, Val Loss: 0.05682513808327735\n",
      "Epoch 250/500, Train Loss: 0.04936259201414234, Val Loss: 0.05692835376338156\n",
      "Epoch 251/500, Train Loss: 0.049373278665379286, Val Loss: 0.057008926867042536\n",
      "Epoch 252/500, Train Loss: 0.049356551402798446, Val Loss: 0.056854082388335225\n",
      "Epoch 253/500, Train Loss: 0.04936614795602378, Val Loss: 0.05664697510821295\n",
      "Epoch 254/500, Train Loss: 0.049354905460669916, Val Loss: 0.05680468855534713\n",
      "Epoch 255/500, Train Loss: 0.04936047296728732, Val Loss: 0.05690722411299962\n",
      "Epoch 256/500, Train Loss: 0.04935527331911928, Val Loss: 0.05682295047547405\n",
      "Epoch 257/500, Train Loss: 0.04936008197447788, Val Loss: 0.0566905687180458\n",
      "Epoch 258/500, Train Loss: 0.04935767157888466, Val Loss: 0.056872490342266595\n",
      "Epoch 259/500, Train Loss: 0.04938274315751643, Val Loss: 0.057064149923138595\n",
      "Epoch 260/500, Train Loss: 0.04935518861251058, Val Loss: 0.056763954292826824\n",
      "Epoch 261/500, Train Loss: 0.04936224837088641, Val Loss: 0.05667273450108211\n",
      "Epoch 262/500, Train Loss: 0.04935499199535817, Val Loss: 0.05677276705572708\n",
      "Epoch 263/500, Train Loss: 0.04935779956483491, Val Loss: 0.056874354010935\n",
      "Epoch 264/500, Train Loss: 0.049355544297253806, Val Loss: 0.056752951008678124\n",
      "Epoch 265/500, Train Loss: 0.04935519677459471, Val Loss: 0.05676364907889582\n",
      "Epoch 266/500, Train Loss: 0.04940096016477976, Val Loss: 0.05652303776280117\n",
      "Epoch 267/500, Train Loss: 0.04937522979360927, Val Loss: 0.05660268521920029\n",
      "Epoch 268/500, Train Loss: 0.04935490036159879, Val Loss: 0.05677889875113145\n",
      "Epoch 269/500, Train Loss: 0.04936085333187683, Val Loss: 0.056683811563374056\n",
      "Epoch 270/500, Train Loss: 0.04935844058608465, Val Loss: 0.056707050027123625\n",
      "Epoch 271/500, Train Loss: 0.049357255381349635, Val Loss: 0.056721729382390895\n",
      "Epoch 272/500, Train Loss: 0.049354841800397675, Val Loss: 0.056785594123904465\n",
      "Epoch 273/500, Train Loss: 0.049358750639172576, Val Loss: 0.05688718791716256\n",
      "Epoch 274/500, Train Loss: 0.049354993717917475, Val Loss: 0.05681066574435511\n",
      "Epoch 275/500, Train Loss: 0.04936192885581553, Val Loss: 0.05667515620121387\n",
      "Epoch 276/500, Train Loss: 0.04935524266348086, Val Loss: 0.05682183156525841\n",
      "Epoch 277/500, Train Loss: 0.04935502574244652, Val Loss: 0.056812425530777456\n",
      "Epoch 278/500, Train Loss: 0.049357011509945675, Val Loss: 0.05672520176905098\n",
      "Epoch 279/500, Train Loss: 0.0493548893268166, Val Loss: 0.05677985567225367\n",
      "Epoch 280/500, Train Loss: 0.0493601116672064, Val Loss: 0.05690327289875023\n",
      "Epoch 281/500, Train Loss: 0.04935776776402254, Val Loss: 0.056714989655408415\n",
      "Epoch 282/500, Train Loss: 0.04937089737989799, Val Loss: 0.05662188313019295\n",
      "Epoch 283/500, Train Loss: 0.0493554782268789, Val Loss: 0.056754726341100986\n",
      "Epoch 284/500, Train Loss: 0.04936142225092218, Val Loss: 0.05667912950221696\n",
      "Epoch 285/500, Train Loss: 0.04935510708305539, Val Loss: 0.056767196400688044\n",
      "Epoch 286/500, Train Loss: 0.04935892698244507, Val Loss: 0.05688939620711478\n",
      "Epoch 287/500, Train Loss: 0.04935593804855456, Val Loss: 0.05674375086202724\n",
      "Epoch 288/500, Train Loss: 0.04935712890445574, Val Loss: 0.056864090531064046\n",
      "Epoch 289/500, Train Loss: 0.049365780846658415, Val Loss: 0.056955750167168466\n",
      "Epoch 290/500, Train Loss: 0.04935683445818703, Val Loss: 0.05685914840564931\n",
      "Epoch 291/500, Train Loss: 0.049364173614873524, Val Loss: 0.056659226381851696\n",
      "Epoch 292/500, Train Loss: 0.049359693676141306, Val Loss: 0.05689855107366643\n",
      "Epoch 293/500, Train Loss: 0.04936990280511094, Val Loss: 0.056986412136640664\n",
      "Epoch 294/500, Train Loss: 0.049401703785128835, Val Loss: 0.05715548627754808\n",
      "Epoch 295/500, Train Loss: 0.04935649038190951, Val Loss: 0.056733390539911804\n",
      "Epoch 296/500, Train Loss: 0.04935625481002643, Val Loss: 0.056737543688456356\n",
      "Epoch 297/500, Train Loss: 0.049367911376729204, Val Loss: 0.05697212039280612\n",
      "Epoch 298/500, Train Loss: 0.04935568234613099, Val Loss: 0.0568352162963351\n",
      "Epoch 299/500, Train Loss: 0.049357789171134245, Val Loss: 0.05687418462574628\n",
      "Epoch 300/500, Train Loss: 0.04935495924854041, Val Loss: 0.056808556414365226\n",
      "Epoch 301/500, Train Loss: 0.04935496511407065, Val Loss: 0.056774319234783946\n",
      "Epoch 302/500, Train Loss: 0.049360512896303936, Val Loss: 0.056686714670202504\n",
      "Epoch 303/500, Train Loss: 0.049355950861780185, Val Loss: 0.056841741818758604\n",
      "Epoch 304/500, Train Loss: 0.049354971645267275, Val Loss: 0.056773924236822024\n",
      "Epoch 305/500, Train Loss: 0.04935539457290752, Val Loss: 0.0567571122785178\n",
      "Epoch 306/500, Train Loss: 0.04936638323141323, Val Loss: 0.05696049842410887\n",
      "Epoch 307/500, Train Loss: 0.04936722570928669, Val Loss: 0.056966977710943424\n",
      "Epoch 308/500, Train Loss: 0.04938386412872371, Val Loss: 0.05707010382969866\n",
      "Epoch 309/500, Train Loss: 0.049356021153360886, Val Loss: 0.05684331855981666\n",
      "Epoch 310/500, Train Loss: 0.049373053536747216, Val Loss: 0.057007449622665254\n",
      "Epoch 311/500, Train Loss: 0.04937957738483425, Val Loss: 0.057046657636073694\n",
      "Epoch 312/500, Train Loss: 0.049362263798791925, Val Loss: 0.0569252337544816\n",
      "Epoch 313/500, Train Loss: 0.04936548299601079, Val Loss: 0.05695333583460657\n",
      "Epoch 314/500, Train Loss: 0.049360269701098615, Val Loss: 0.05668885155707585\n",
      "Epoch 315/500, Train Loss: 0.04937175558710015, Val Loss: 0.05661783187440094\n",
      "Epoch 316/500, Train Loss: 0.04935794826235179, Val Loss: 0.056712750697854704\n",
      "Epoch 317/500, Train Loss: 0.04935513381580762, Val Loss: 0.05676606703295581\n",
      "Epoch 318/500, Train Loss: 0.04935833553882376, Val Loss: 0.05670820957557961\n",
      "Epoch 319/500, Train Loss: 0.049362750442174565, Val Loss: 0.056669011446062185\n",
      "Epoch 320/500, Train Loss: 0.04935668755111187, Val Loss: 0.05673013255366102\n",
      "Epoch 321/500, Train Loss: 0.0493636192459038, Val Loss: 0.05693760815191153\n",
      "Epoch 322/500, Train Loss: 0.04935503489959794, Val Loss: 0.05681286624626353\n",
      "Epoch 323/500, Train Loss: 0.04937424948434931, Val Loss: 0.05701501593301676\n",
      "Epoch 324/500, Train Loss: 0.04935546380531888, Val Loss: 0.056755104730134266\n",
      "Epoch 325/500, Train Loss: 0.04935798833714399, Val Loss: 0.05687699608756587\n",
      "Epoch 326/500, Train Loss: 0.049354878124826244, Val Loss: 0.05680212831285929\n",
      "Epoch 327/500, Train Loss: 0.04936086169034179, Val Loss: 0.056911289513315866\n",
      "Epoch 328/500, Train Loss: 0.04936040861631474, Val Loss: 0.05690648127329019\n",
      "Epoch 329/500, Train Loss: 0.049355909306922977, Val Loss: 0.05684075900690446\n",
      "Epoch 330/500, Train Loss: 0.04935711015002349, Val Loss: 0.056863748593642266\n",
      "Epoch 331/500, Train Loss: 0.04935917425594847, Val Loss: 0.05689239076823363\n",
      "Epoch 332/500, Train Loss: 0.049355483242877994, Val Loss: 0.05682967322114523\n",
      "Epoch 333/500, Train Loss: 0.049355688552758126, Val Loss: 0.05683534267527886\n",
      "Epoch 334/500, Train Loss: 0.049361762603020456, Val Loss: 0.056676407678584076\n",
      "Epoch 335/500, Train Loss: 0.04936100922989847, Val Loss: 0.05668246767208738\n",
      "Epoch 336/500, Train Loss: 0.04935962000067067, Val Loss: 0.05669483683098872\n",
      "Epoch 337/500, Train Loss: 0.04935689914110302, Val Loss: 0.05686021656437367\n",
      "Epoch 338/500, Train Loss: 0.049369608560739256, Val Loss: 0.056984307706943085\n",
      "Epoch 339/500, Train Loss: 0.04935844847229651, Val Loss: 0.056883225937776644\n",
      "Epoch 340/500, Train Loss: 0.04935789430017369, Val Loss: 0.05687564836079361\n",
      "Epoch 341/500, Train Loss: 0.04937357635606283, Val Loss: 0.05701074999319161\n",
      "Epoch 342/500, Train Loss: 0.04935866358915753, Val Loss: 0.056886016252655276\n",
      "Epoch 343/500, Train Loss: 0.049355663131439714, Val Loss: 0.056749900599507554\n",
      "Epoch 344/500, Train Loss: 0.049366743831927004, Val Loss: 0.05664347119144154\n",
      "Epoch 345/500, Train Loss: 0.049362965377146566, Val Loss: 0.05666744592499437\n",
      "Epoch 346/500, Train Loss: 0.04935872713219653, Val Loss: 0.05670386218491337\n",
      "Epoch 347/500, Train Loss: 0.049355314713387985, Val Loss: 0.05675954421188077\n",
      "Epoch 348/500, Train Loss: 0.04935590222587214, Val Loss: 0.05674446279850502\n",
      "Epoch 349/500, Train Loss: 0.04935578301968101, Val Loss: 0.05683770497043527\n",
      "Epoch 350/500, Train Loss: 0.049360851451016395, Val Loss: 0.056683771737209815\n",
      "Epoch 351/500, Train Loss: 0.04935513786701479, Val Loss: 0.0567658750655756\n",
      "Epoch 352/500, Train Loss: 0.04935484757084486, Val Loss: 0.056798273493084445\n",
      "Epoch 353/500, Train Loss: 0.04936502238571407, Val Loss: 0.056949515350068765\n",
      "Epoch 354/500, Train Loss: 0.04935667700515663, Val Loss: 0.05685629129520227\n",
      "Epoch 355/500, Train Loss: 0.049367761516684955, Val Loss: 0.05697093428212951\n",
      "Epoch 356/500, Train Loss: 0.049356551173345205, Val Loss: 0.05685398171591101\n",
      "Epoch 357/500, Train Loss: 0.049361838685296554, Val Loss: 0.056921080737409174\n",
      "Epoch 358/500, Train Loss: 0.049354909757739256, Val Loss: 0.05680491006519915\n",
      "Epoch 359/500, Train Loss: 0.049381850111938824, Val Loss: 0.0565776826174174\n",
      "Epoch 360/500, Train Loss: 0.04935876260637169, Val Loss: 0.05670346333198482\n",
      "Epoch 361/500, Train Loss: 0.04935511899932952, Val Loss: 0.056766639817838103\n",
      "Epoch 362/500, Train Loss: 0.04935887839169415, Val Loss: 0.056888696089123766\n",
      "Epoch 363/500, Train Loss: 0.049368576151081804, Val Loss: 0.056633426061026684\n",
      "Epoch 364/500, Train Loss: 0.04935937574006273, Val Loss: 0.056697172705262026\n",
      "Epoch 365/500, Train Loss: 0.04935549337124489, Val Loss: 0.056754242467998574\n",
      "Epoch 366/500, Train Loss: 0.04935643772754717, Val Loss: 0.05673422226465453\n",
      "Epoch 367/500, Train Loss: 0.049356905996906245, Val Loss: 0.05672669114288485\n",
      "Epoch 368/500, Train Loss: 0.04938566966919126, Val Loss: 0.05656503628946531\n",
      "Epoch 369/500, Train Loss: 0.04935532607770403, Val Loss: 0.056759153550404874\n",
      "Epoch 370/500, Train Loss: 0.04935486542928373, Val Loss: 0.056800604339098164\n",
      "Epoch 371/500, Train Loss: 0.04935526020419584, Val Loss: 0.05682233489322253\n",
      "Epoch 372/500, Train Loss: 0.04936389737891942, Val Loss: 0.05666097652427579\n",
      "Epoch 373/500, Train Loss: 0.04935739747258814, Val Loss: 0.05671969788655217\n",
      "Epoch 374/500, Train Loss: 0.049355607061087874, Val Loss: 0.05675124511127439\n",
      "Epoch 375/500, Train Loss: 0.049362360723997946, Val Loss: 0.056926037172209176\n",
      "Epoch 376/500, Train Loss: 0.04935521350012548, Val Loss: 0.05682058101065588\n",
      "Epoch 377/500, Train Loss: 0.049367313789565846, Val Loss: 0.056967517915540423\n",
      "Epoch 378/500, Train Loss: 0.04936661854677638, Val Loss: 0.05664413362954842\n",
      "Epoch 379/500, Train Loss: 0.04935485219347505, Val Loss: 0.05678397335326634\n",
      "Epoch 380/500, Train Loss: 0.04940076474439414, Val Loss: 0.057151192063775086\n",
      "Epoch 381/500, Train Loss: 0.049365933202532755, Val Loss: 0.0569568109777021\n",
      "Epoch 382/500, Train Loss: 0.04935606187426049, Val Loss: 0.05684406828734225\n",
      "Epoch 383/500, Train Loss: 0.04935853192494563, Val Loss: 0.05688420823421124\n",
      "Epoch 384/500, Train Loss: 0.0493560171262001, Val Loss: 0.0568430738983511\n",
      "Epoch 385/500, Train Loss: 0.04935646985506291, Val Loss: 0.056733631849134804\n",
      "Epoch 386/500, Train Loss: 0.04935971390533623, Val Loss: 0.056693857335552655\n",
      "Epoch 387/500, Train Loss: 0.049357202819176625, Val Loss: 0.05672233664933275\n",
      "Epoch 388/500, Train Loss: 0.04935485259532214, Val Loss: 0.05679879249259126\n",
      "Epoch 389/500, Train Loss: 0.04935732060175955, Val Loss: 0.056720700969701464\n",
      "Epoch 390/500, Train Loss: 0.04935580995096012, Val Loss: 0.05674640263134636\n",
      "Epoch 391/500, Train Loss: 0.049364608750136, Val Loss: 0.05694594714756642\n",
      "Epoch 392/500, Train Loss: 0.04935810243757233, Val Loss: 0.05687841103945131\n",
      "Epoch 393/500, Train Loss: 0.04935737708565642, Val Loss: 0.05686782005016342\n",
      "Epoch 394/500, Train Loss: 0.04936112663367287, Val Loss: 0.056913845684044055\n",
      "Epoch 395/500, Train Loss: 0.04935514374467538, Val Loss: 0.05681768000298847\n",
      "Epoch 396/500, Train Loss: 0.04936144618684474, Val Loss: 0.05667878812468444\n",
      "Epoch 397/500, Train Loss: 0.04935716737239179, Val Loss: 0.056722806095315\n",
      "Epoch 398/500, Train Loss: 0.04935634632250793, Val Loss: 0.05673574736668735\n",
      "Epoch 399/500, Train Loss: 0.04935502404231606, Val Loss: 0.056812015865506126\n",
      "Epoch 400/500, Train Loss: 0.0493565083750582, Val Loss: 0.0568530042061228\n",
      "Epoch 401/500, Train Loss: 0.04935550977626184, Val Loss: 0.05675372351593017\n",
      "Epoch 402/500, Train Loss: 0.049356297177841076, Val Loss: 0.05673661660227042\n",
      "Epoch 403/500, Train Loss: 0.04935537571930742, Val Loss: 0.05682609454561151\n",
      "Epoch 404/500, Train Loss: 0.04935517386483878, Val Loss: 0.05681884676952147\n",
      "Epoch 405/500, Train Loss: 0.049357730443341484, Val Loss: 0.05687305484827594\n",
      "Epoch 406/500, Train Loss: 0.0493613103275815, Val Loss: 0.05691563583171012\n",
      "Epoch 407/500, Train Loss: 0.04936193771645226, Val Loss: 0.05692182901873281\n",
      "Epoch 408/500, Train Loss: 0.04935811281144967, Val Loss: 0.056710611194883985\n",
      "Epoch 409/500, Train Loss: 0.04935854349456242, Val Loss: 0.05670570484388248\n",
      "Epoch 410/500, Train Loss: 0.049374538879074975, Val Loss: 0.0566053654255943\n",
      "Epoch 411/500, Train Loss: 0.04936269291379269, Val Loss: 0.056669237960537314\n",
      "Epoch 412/500, Train Loss: 0.04937917134395388, Val Loss: 0.057044018502341434\n",
      "Epoch 413/500, Train Loss: 0.049361996775320965, Val Loss: 0.056674412853274445\n",
      "Epoch 414/500, Train Loss: 0.04935845839308954, Val Loss: 0.0567066254702101\n",
      "Epoch 415/500, Train Loss: 0.049370001460567636, Val Loss: 0.05662601186727408\n",
      "Epoch 416/500, Train Loss: 0.04937053628565742, Val Loss: 0.05662338994367318\n",
      "Epoch 417/500, Train Loss: 0.04936029340463855, Val Loss: 0.05668841718612687\n",
      "Epoch 418/500, Train Loss: 0.04936790164475077, Val Loss: 0.0566368410111324\n",
      "Epoch 419/500, Train Loss: 0.04935504402915126, Val Loss: 0.0567699708713215\n",
      "Epoch 420/500, Train Loss: 0.04935716401585422, Val Loss: 0.056722761339712886\n",
      "Epoch 421/500, Train Loss: 0.04935564113515075, Val Loss: 0.05683364668518233\n",
      "Epoch 422/500, Train Loss: 0.04935619509754221, Val Loss: 0.056738425540145986\n",
      "Epoch 423/500, Train Loss: 0.04938151732966492, Val Loss: 0.05705699991395569\n",
      "Epoch 424/500, Train Loss: 0.04935488181684521, Val Loss: 0.05680157634227279\n",
      "Epoch 425/500, Train Loss: 0.049387522036955865, Val Loss: 0.0565590795848647\n",
      "Epoch 426/500, Train Loss: 0.04935673107450694, Val Loss: 0.05672919527406475\n",
      "Epoch 427/500, Train Loss: 0.049355017047364766, Val Loss: 0.05681118339938793\n",
      "Epoch 428/500, Train Loss: 0.04935499104654257, Val Loss: 0.056809674280947194\n",
      "Epoch 429/500, Train Loss: 0.04935671117413817, Val Loss: 0.056856399749176535\n",
      "Epoch 430/500, Train Loss: 0.049354958136781486, Val Loss: 0.05677481457405819\n",
      "Epoch 431/500, Train Loss: 0.049358531178768636, Val Loss: 0.05670571553680474\n",
      "Epoch 432/500, Train Loss: 0.049354897095794305, Val Loss: 0.05677945825113229\n",
      "Epoch 433/500, Train Loss: 0.04935503757649804, Val Loss: 0.05681209290357581\n",
      "Epoch 434/500, Train Loss: 0.049355778135759774, Val Loss: 0.05674698262048031\n",
      "Epoch 435/500, Train Loss: 0.04935830267749194, Val Loss: 0.056708252032026056\n",
      "Epoch 436/500, Train Loss: 0.04935573410170274, Val Loss: 0.05683575364642249\n",
      "Epoch 437/500, Train Loss: 0.04935490840452321, Val Loss: 0.056778595492303\n",
      "Epoch 438/500, Train Loss: 0.04936335068755132, Val Loss: 0.05666438399788586\n",
      "Epoch 439/500, Train Loss: 0.049377335786514924, Val Loss: 0.056593853978028005\n",
      "Epoch 440/500, Train Loss: 0.04936813187243291, Val Loss: 0.056635426064036765\n",
      "Epoch 441/500, Train Loss: 0.04935544881201809, Val Loss: 0.056755346520947735\n",
      "Epoch 442/500, Train Loss: 0.04936106683602587, Val Loss: 0.05691262289405172\n",
      "Epoch 443/500, Train Loss: 0.04935617378406759, Val Loss: 0.05684565649173957\n",
      "Epoch 444/500, Train Loss: 0.04935497638874708, Val Loss: 0.05680802959489447\n",
      "Epoch 445/500, Train Loss: 0.04935492318667559, Val Loss: 0.05677768264749084\n",
      "Epoch 446/500, Train Loss: 0.04935539133831475, Val Loss: 0.05682565001856002\n",
      "Epoch 447/500, Train Loss: 0.049371269122284504, Val Loss: 0.056619624194026184\n",
      "Epoch 448/500, Train Loss: 0.049363619404903435, Val Loss: 0.056662434912329925\n",
      "Epoch 449/500, Train Loss: 0.0493679015855831, Val Loss: 0.05663656468026722\n",
      "Epoch 450/500, Train Loss: 0.04936990860248134, Val Loss: 0.05662616513758652\n",
      "Epoch 451/500, Train Loss: 0.04935574238274648, Val Loss: 0.056747820133129644\n",
      "Epoch 452/500, Train Loss: 0.04935768149771175, Val Loss: 0.05687140578989237\n",
      "Epoch 453/500, Train Loss: 0.04935747623151867, Val Loss: 0.0567182877395723\n",
      "Epoch 454/500, Train Loss: 0.04935936589204907, Val Loss: 0.05689347663661601\n",
      "Epoch 455/500, Train Loss: 0.0493566616540335, Val Loss: 0.0567301828980647\n",
      "Epoch 456/500, Train Loss: 0.04936146683342006, Val Loss: 0.05667820140205408\n",
      "Epoch 457/500, Train Loss: 0.049354884408227336, Val Loss: 0.05679833561876326\n",
      "Epoch 458/500, Train Loss: 0.04935536240181909, Val Loss: 0.05675817847400893\n",
      "Epoch 459/500, Train Loss: 0.04936392264135234, Val Loss: 0.056660267284416435\n",
      "Epoch 460/500, Train Loss: 0.0493555398163705, Val Loss: 0.05682923426193971\n",
      "Epoch 461/500, Train Loss: 0.04935604059970588, Val Loss: 0.05684179650335687\n",
      "Epoch 462/500, Train Loss: 0.04935576531250181, Val Loss: 0.056747455328506086\n",
      "Epoch 463/500, Train Loss: 0.04935490224001472, Val Loss: 0.05678202711575188\n",
      "Epoch 464/500, Train Loss: 0.04936425320777748, Val Loss: 0.056658024333422985\n",
      "Epoch 465/500, Train Loss: 0.04939206972933163, Val Loss: 0.05654535721199906\n",
      "Epoch 466/500, Train Loss: 0.04935892348402177, Val Loss: 0.056887363072969536\n",
      "Epoch 467/500, Train Loss: 0.04935694506882367, Val Loss: 0.0568587526506686\n",
      "Epoch 468/500, Train Loss: 0.04935800186828313, Val Loss: 0.05671165077387396\n",
      "Epoch 469/500, Train Loss: 0.04935512168566762, Val Loss: 0.056812694740532715\n",
      "Epoch 470/500, Train Loss: 0.0493678050248824, Val Loss: 0.05663682168442168\n",
      "Epoch 471/500, Train Loss: 0.04935573403651571, Val Loss: 0.05674861245103159\n",
      "Epoch 472/500, Train Loss: 0.049354983222043645, Val Loss: 0.056803222617281456\n",
      "Epoch 473/500, Train Loss: 0.04936008877841486, Val Loss: 0.05668989174776935\n",
      "Epoch 474/500, Train Loss: 0.04936218073633317, Val Loss: 0.05667252883558116\n",
      "Epoch 475/500, Train Loss: 0.04935546999211296, Val Loss: 0.056824721611703294\n",
      "Epoch 476/500, Train Loss: 0.04935735494418202, Val Loss: 0.056720191205408395\n",
      "Epoch 477/500, Train Loss: 0.049376938325079285, Val Loss: 0.05659487412762201\n",
      "Epoch 478/500, Train Loss: 0.04935517598461013, Val Loss: 0.05676754768407073\n",
      "Epoch 479/500, Train Loss: 0.04935910810543843, Val Loss: 0.05669952868553481\n",
      "Epoch 480/500, Train Loss: 0.04935509995769708, Val Loss: 0.056772368083231974\n",
      "Epoch 481/500, Train Loss: 0.04935726295328898, Val Loss: 0.05686180173643638\n",
      "Epoch 482/500, Train Loss: 0.04936184015876251, Val Loss: 0.05691734668277375\n",
      "Epoch 483/500, Train Loss: 0.049355171478141946, Val Loss: 0.05680913682918919\n",
      "Epoch 484/500, Train Loss: 0.04935509560577828, Val Loss: 0.056803329018712975\n",
      "Epoch 485/500, Train Loss: 0.04936247090473721, Val Loss: 0.056670523216166745\n",
      "Epoch 486/500, Train Loss: 0.04935907035772255, Val Loss: 0.05670033953221591\n",
      "Epoch 487/500, Train Loss: 0.0493565358670999, Val Loss: 0.056846817747515085\n",
      "Epoch 488/500, Train Loss: 0.049369038315797455, Val Loss: 0.05697554383584521\n",
      "Epoch 489/500, Train Loss: 0.04935576814880784, Val Loss: 0.05682760382842994\n",
      "Epoch 490/500, Train Loss: 0.04939521334209435, Val Loss: 0.05712125885759444\n",
      "Epoch 491/500, Train Loss: 0.04936624769146018, Val Loss: 0.05695369373369624\n",
      "Epoch 492/500, Train Loss: 0.04935722832876148, Val Loss: 0.05672423818258292\n",
      "Epoch 493/500, Train Loss: 0.0493554409023611, Val Loss: 0.05676558311846496\n",
      "Epoch 494/500, Train Loss: 0.04935690646847228, Val Loss: 0.056730106745521446\n",
      "Epoch 495/500, Train Loss: 0.04936036244712211, Val Loss: 0.056689030494419625\n",
      "Epoch 496/500, Train Loss: 0.04936607822100992, Val Loss: 0.056647337648315504\n",
      "Epoch 497/500, Train Loss: 0.04936230911034455, Val Loss: 0.056673110347961825\n",
      "Epoch 498/500, Train Loss: 0.04936562153455253, Val Loss: 0.05694554990734274\n",
      "Epoch 499/500, Train Loss: 0.04937110719693345, Val Loss: 0.05662077627787567\n",
      "Epoch 500/500, Train Loss: 0.04935793130770282, Val Loss: 0.05686180363886293\n",
      "Returning from fit...\n",
      "Train Losses: [np.float64(0.06320291364261621), np.float64(0.05020025010534154), np.float64(0.04942633118610035), np.float64(0.04935746570122979), np.float64(0.049362026430470475), np.float64(0.04935626619653176), np.float64(0.04936385456643296), np.float64(0.04935606561750327), np.float64(0.04935494374113121), np.float64(0.04935484999011613), np.float64(0.0493556107367544), np.float64(0.049360787159948405), np.float64(0.04936356281906032), np.float64(0.049354847115538406), np.float64(0.0493550125465847), np.float64(0.04936097460070241), np.float64(0.04935668005213692), np.float64(0.049355361382770975), np.float64(0.049357527349146266), np.float64(0.04935485390959912), np.float64(0.04936464441025726), np.float64(0.04935545780681791), np.float64(0.0493551824442078), np.float64(0.04935484572504523), np.float64(0.04935482603344417), np.float64(0.0493551980211819), np.float64(0.04935483305864312), np.float64(0.04935483946877747), np.float64(0.04935494818460559), np.float64(0.049363180489300544), np.float64(0.04935611557121937), np.float64(0.049363541153608255), np.float64(0.04936978239482825), np.float64(0.04935896433871765), np.float64(0.0493594840589094), np.float64(0.049354863738640065), np.float64(0.049367202202430065), np.float64(0.049367227149237476), np.float64(0.04936212502970777), np.float64(0.049355814056549284), np.float64(0.04935491508155736), np.float64(0.0493602421564515), np.float64(0.049365579882807945), np.float64(0.04935573216502094), np.float64(0.04936126331495307), np.float64(0.04937281230307039), np.float64(0.04936613890440664), np.float64(0.049364777870898956), np.float64(0.04936734996637918), np.float64(0.04936171469278202), np.float64(0.04935497393492959), np.float64(0.049354886938201975), np.float64(0.04936857634225048), np.float64(0.049355698765741945), np.float64(0.049363124654477106), np.float64(0.04935938933281761), np.float64(0.04935562339343392), np.float64(0.049376440051574794), np.float64(0.049360914283847104), np.float64(0.04935974794790333), np.float64(0.04935912761845625), np.float64(0.04935500750148755), np.float64(0.04936698496158901), np.float64(0.049354904849464226), np.float64(0.04935533262297364), np.float64(0.04936721999896844), np.float64(0.049374191897520125), np.float64(0.049355479797680894), np.float64(0.04935584110045922), np.float64(0.04936769707593174), np.float64(0.049354965242029245), np.float64(0.04936537348528605), np.float64(0.04936126274244144), np.float64(0.04936624844908813), np.float64(0.04937010786234715), np.float64(0.04937051579484776), np.float64(0.04935661450497876), np.float64(0.049355033209535756), np.float64(0.0493549279283719), np.float64(0.04938331240252114), np.float64(0.04935875397332067), np.float64(0.04935487297002866), np.float64(0.04936146525209922), np.float64(0.049359509304735406), np.float64(0.04935485555487384), np.float64(0.04935585920369955), np.float64(0.04935972436578078), np.float64(0.049357911094014176), np.float64(0.04935482905530228), np.float64(0.0493560692770624), np.float64(0.049362027881281155), np.float64(0.04935661205199913), np.float64(0.04935727493370415), np.float64(0.04936614217058522), np.float64(0.04935640290870046), np.float64(0.049398833039267134), np.float64(0.04938492503308838), np.float64(0.0493730958308773), np.float64(0.04935808082846151), np.float64(0.04935709795073835), np.float64(0.04936516345811035), np.float64(0.04936075098359424), np.float64(0.049354837426163096), np.float64(0.04936399482375196), np.float64(0.04936073654838873), np.float64(0.04935750123687147), np.float64(0.04936800709843963), np.float64(0.04935523126582831), np.float64(0.049355943877356936), np.float64(0.04936937173486394), np.float64(0.04936269868379749), np.float64(0.04935567255282389), np.float64(0.04935601110742599), np.float64(0.04940850362918701), np.float64(0.04935755879913637), np.float64(0.04936640804654683), np.float64(0.049364430833340134), np.float64(0.049355650917973615), np.float64(0.04935618648751763), np.float64(0.04935482870433904), np.float64(0.04935495504571205), np.float64(0.04935485376394296), np.float64(0.049354848128775705), np.float64(0.04936028945721326), np.float64(0.04937629637590903), np.float64(0.04936581749984862), np.float64(0.04935735208134642), np.float64(0.04937185195934803), np.float64(0.049359083834655725), np.float64(0.04935482598435158), np.float64(0.049355109085409694), np.float64(0.04935493085526863), np.float64(0.04935566365280593), np.float64(0.04935482995168019), np.float64(0.049357328208235005), np.float64(0.049356649411910404), np.float64(0.049354960115554854), np.float64(0.04935691361259771), np.float64(0.04937041634015029), np.float64(0.04935894353313991), np.float64(0.04937377995117507), np.float64(0.04936561598076653), np.float64(0.04935635271090599), np.float64(0.04935503220982583), np.float64(0.0493578165025479), np.float64(0.0493579731126855), np.float64(0.04935514366799445), np.float64(0.049364990310285205), np.float64(0.04935482773586241), np.float64(0.04937056024094277), np.float64(0.04936522470803566), np.float64(0.04935491103061258), np.float64(0.04935560067711979), np.float64(0.049364687531499626), np.float64(0.04935489022490706), np.float64(0.04935488150120011), np.float64(0.049374987256703175), np.float64(0.049362448609203045), np.float64(0.04935918596529395), np.float64(0.04935514061040478), np.float64(0.0493550478429058), np.float64(0.04935589903632633), np.float64(0.049356623776106695), np.float64(0.0493581422741454), np.float64(0.049358022710135924), np.float64(0.049375507732839885), np.float64(0.04935482539262778), np.float64(0.049355430626215606), np.float64(0.04935641293961589), np.float64(0.049379752766126245), np.float64(0.04937471299721572), np.float64(0.04935736779960511), np.float64(0.049360402197014486), np.float64(0.049354885808843646), np.float64(0.04935824945652209), np.float64(0.04935810805649556), np.float64(0.04936708188785727), np.float64(0.049358465337268884), np.float64(0.04935592926645348), np.float64(0.04935950987332206), np.float64(0.04935700491236944), np.float64(0.04935819324870841), np.float64(0.04935684496457328), np.float64(0.04935497186282052), np.float64(0.04935607382275882), np.float64(0.04935624939676895), np.float64(0.0493566811715517), np.float64(0.04936363412459633), np.float64(0.049361694238220837), np.float64(0.049358257213101234), np.float64(0.0493816768532647), np.float64(0.04935483139920215), np.float64(0.049366694237966205), np.float64(0.049379288411355915), np.float64(0.049365630514137615), np.float64(0.04936459391405162), np.float64(0.04935893569967747), np.float64(0.04936584120746262), np.float64(0.049358110354476584), np.float64(0.049354979620815344), np.float64(0.049361977948129764), np.float64(0.04936730155910002), np.float64(0.049355114932183544), np.float64(0.049355072202589334), np.float64(0.049355828565015754), np.float64(0.049366098552447356), np.float64(0.04936104300938903), np.float64(0.04935500683526248), np.float64(0.04936252290769232), np.float64(0.04936429314684268), np.float64(0.049355994554158754), np.float64(0.04935525764018685), np.float64(0.04935601366742), np.float64(0.0493571977704535), np.float64(0.04935515193753684), np.float64(0.04935551431451933), np.float64(0.049358029543632956), np.float64(0.049361395685238056), np.float64(0.049354825895029035), np.float64(0.049354825641050294), np.float64(0.04938021235655306), np.float64(0.04936890025304672), np.float64(0.049357496449416303), np.float64(0.04935496507206081), np.float64(0.04935641702283207), np.float64(0.04937942445703433), np.float64(0.049378209021109475), np.float64(0.04936523212086243), np.float64(0.04937585326459515), np.float64(0.04935587037836967), np.float64(0.0493599511945371), np.float64(0.04935890912072356), np.float64(0.04935532968541807), np.float64(0.049362221082993346), np.float64(0.049360969554881), np.float64(0.04937107312808352), np.float64(0.04936317050191276), np.float64(0.04936152571737807), np.float64(0.049356419306400584), np.float64(0.04935743716858873), np.float64(0.0493553937394993), np.float64(0.04935844462559099), np.float64(0.04936133967900605), np.float64(0.04935483641077092), np.float64(0.04936024602605813), np.float64(0.0493645063952934), np.float64(0.04936460321295817), np.float64(0.049358808796357845), np.float64(0.049355336733450314), np.float64(0.04936259201414234), np.float64(0.049373278665379286), np.float64(0.049356551402798446), np.float64(0.04936614795602378), np.float64(0.049354905460669916), np.float64(0.04936047296728732), np.float64(0.04935527331911928), np.float64(0.04936008197447788), np.float64(0.04935767157888466), np.float64(0.04938274315751643), np.float64(0.04935518861251058), np.float64(0.04936224837088641), np.float64(0.04935499199535817), np.float64(0.04935779956483491), np.float64(0.049355544297253806), np.float64(0.04935519677459471), np.float64(0.04940096016477976), np.float64(0.04937522979360927), np.float64(0.04935490036159879), np.float64(0.04936085333187683), np.float64(0.04935844058608465), np.float64(0.049357255381349635), np.float64(0.049354841800397675), np.float64(0.049358750639172576), np.float64(0.049354993717917475), np.float64(0.04936192885581553), np.float64(0.04935524266348086), np.float64(0.04935502574244652), np.float64(0.049357011509945675), np.float64(0.0493548893268166), np.float64(0.0493601116672064), np.float64(0.04935776776402254), np.float64(0.04937089737989799), np.float64(0.0493554782268789), np.float64(0.04936142225092218), np.float64(0.04935510708305539), np.float64(0.04935892698244507), np.float64(0.04935593804855456), np.float64(0.04935712890445574), np.float64(0.049365780846658415), np.float64(0.04935683445818703), np.float64(0.049364173614873524), np.float64(0.049359693676141306), np.float64(0.04936990280511094), np.float64(0.049401703785128835), np.float64(0.04935649038190951), np.float64(0.04935625481002643), np.float64(0.049367911376729204), np.float64(0.04935568234613099), np.float64(0.049357789171134245), np.float64(0.04935495924854041), np.float64(0.04935496511407065), np.float64(0.049360512896303936), np.float64(0.049355950861780185), np.float64(0.049354971645267275), np.float64(0.04935539457290752), np.float64(0.04936638323141323), np.float64(0.04936722570928669), np.float64(0.04938386412872371), np.float64(0.049356021153360886), np.float64(0.049373053536747216), np.float64(0.04937957738483425), np.float64(0.049362263798791925), np.float64(0.04936548299601079), np.float64(0.049360269701098615), np.float64(0.04937175558710015), np.float64(0.04935794826235179), np.float64(0.04935513381580762), np.float64(0.04935833553882376), np.float64(0.049362750442174565), np.float64(0.04935668755111187), np.float64(0.0493636192459038), np.float64(0.04935503489959794), np.float64(0.04937424948434931), np.float64(0.04935546380531888), np.float64(0.04935798833714399), np.float64(0.049354878124826244), np.float64(0.04936086169034179), np.float64(0.04936040861631474), np.float64(0.049355909306922977), np.float64(0.04935711015002349), np.float64(0.04935917425594847), np.float64(0.049355483242877994), np.float64(0.049355688552758126), np.float64(0.049361762603020456), np.float64(0.04936100922989847), np.float64(0.04935962000067067), np.float64(0.04935689914110302), np.float64(0.049369608560739256), np.float64(0.04935844847229651), np.float64(0.04935789430017369), np.float64(0.04937357635606283), np.float64(0.04935866358915753), np.float64(0.049355663131439714), np.float64(0.049366743831927004), np.float64(0.049362965377146566), np.float64(0.04935872713219653), np.float64(0.049355314713387985), np.float64(0.04935590222587214), np.float64(0.04935578301968101), np.float64(0.049360851451016395), np.float64(0.04935513786701479), np.float64(0.04935484757084486), np.float64(0.04936502238571407), np.float64(0.04935667700515663), np.float64(0.049367761516684955), np.float64(0.049356551173345205), np.float64(0.049361838685296554), np.float64(0.049354909757739256), np.float64(0.049381850111938824), np.float64(0.04935876260637169), np.float64(0.04935511899932952), np.float64(0.04935887839169415), np.float64(0.049368576151081804), np.float64(0.04935937574006273), np.float64(0.04935549337124489), np.float64(0.04935643772754717), np.float64(0.049356905996906245), np.float64(0.04938566966919126), np.float64(0.04935532607770403), np.float64(0.04935486542928373), np.float64(0.04935526020419584), np.float64(0.04936389737891942), np.float64(0.04935739747258814), np.float64(0.049355607061087874), np.float64(0.049362360723997946), np.float64(0.04935521350012548), np.float64(0.049367313789565846), np.float64(0.04936661854677638), np.float64(0.04935485219347505), np.float64(0.04940076474439414), np.float64(0.049365933202532755), np.float64(0.04935606187426049), np.float64(0.04935853192494563), np.float64(0.0493560171262001), np.float64(0.04935646985506291), np.float64(0.04935971390533623), np.float64(0.049357202819176625), np.float64(0.04935485259532214), np.float64(0.04935732060175955), np.float64(0.04935580995096012), np.float64(0.049364608750136), np.float64(0.04935810243757233), np.float64(0.04935737708565642), np.float64(0.04936112663367287), np.float64(0.04935514374467538), np.float64(0.04936144618684474), np.float64(0.04935716737239179), np.float64(0.04935634632250793), np.float64(0.04935502404231606), np.float64(0.0493565083750582), np.float64(0.04935550977626184), np.float64(0.049356297177841076), np.float64(0.04935537571930742), np.float64(0.04935517386483878), np.float64(0.049357730443341484), np.float64(0.0493613103275815), np.float64(0.04936193771645226), np.float64(0.04935811281144967), np.float64(0.04935854349456242), np.float64(0.049374538879074975), np.float64(0.04936269291379269), np.float64(0.04937917134395388), np.float64(0.049361996775320965), np.float64(0.04935845839308954), np.float64(0.049370001460567636), np.float64(0.04937053628565742), np.float64(0.04936029340463855), np.float64(0.04936790164475077), np.float64(0.04935504402915126), np.float64(0.04935716401585422), np.float64(0.04935564113515075), np.float64(0.04935619509754221), np.float64(0.04938151732966492), np.float64(0.04935488181684521), np.float64(0.049387522036955865), np.float64(0.04935673107450694), np.float64(0.049355017047364766), np.float64(0.04935499104654257), np.float64(0.04935671117413817), np.float64(0.049354958136781486), np.float64(0.049358531178768636), np.float64(0.049354897095794305), np.float64(0.04935503757649804), np.float64(0.049355778135759774), np.float64(0.04935830267749194), np.float64(0.04935573410170274), np.float64(0.04935490840452321), np.float64(0.04936335068755132), np.float64(0.049377335786514924), np.float64(0.04936813187243291), np.float64(0.04935544881201809), np.float64(0.04936106683602587), np.float64(0.04935617378406759), np.float64(0.04935497638874708), np.float64(0.04935492318667559), np.float64(0.04935539133831475), np.float64(0.049371269122284504), np.float64(0.049363619404903435), np.float64(0.0493679015855831), np.float64(0.04936990860248134), np.float64(0.04935574238274648), np.float64(0.04935768149771175), np.float64(0.04935747623151867), np.float64(0.04935936589204907), np.float64(0.0493566616540335), np.float64(0.04936146683342006), np.float64(0.049354884408227336), np.float64(0.04935536240181909), np.float64(0.04936392264135234), np.float64(0.0493555398163705), np.float64(0.04935604059970588), np.float64(0.04935576531250181), np.float64(0.04935490224001472), np.float64(0.04936425320777748), np.float64(0.04939206972933163), np.float64(0.04935892348402177), np.float64(0.04935694506882367), np.float64(0.04935800186828313), np.float64(0.04935512168566762), np.float64(0.0493678050248824), np.float64(0.04935573403651571), np.float64(0.049354983222043645), np.float64(0.04936008877841486), np.float64(0.04936218073633317), np.float64(0.04935546999211296), np.float64(0.04935735494418202), np.float64(0.049376938325079285), np.float64(0.04935517598461013), np.float64(0.04935910810543843), np.float64(0.04935509995769708), np.float64(0.04935726295328898), np.float64(0.04936184015876251), np.float64(0.049355171478141946), np.float64(0.04935509560577828), np.float64(0.04936247090473721), np.float64(0.04935907035772255), np.float64(0.0493565358670999), np.float64(0.049369038315797455), np.float64(0.04935576814880784), np.float64(0.04939521334209435), np.float64(0.04936624769146018), np.float64(0.04935722832876148), np.float64(0.0493554409023611), np.float64(0.04935690646847228), np.float64(0.04936036244712211), np.float64(0.04936607822100992), np.float64(0.04936230911034455), np.float64(0.04936562153455253), np.float64(0.04937110719693345), np.float64(0.04935793130770282)]\n",
      "Validation Losses: [np.float64(0.06518888642217772), np.float64(0.05629018532091398), np.float64(0.0564713719758158), np.float64(0.056869450461367016), np.float64(0.05692304207217695), np.float64(0.05684858229818921), np.float64(0.05693975130296706), np.float64(0.056844362935108694), np.float64(0.05680759148495548), np.float64(0.05679882721910478), np.float64(0.05683336999184911), np.float64(0.05691059469797179), np.float64(0.056937190087592245), np.float64(0.05678473142717097), np.float64(0.05677168637897442), np.float64(0.056912546733782), np.float64(0.056856472150273535), np.float64(0.056825984351398275), np.float64(0.05671810169448068), np.float64(0.056799388231799884), np.float64(0.056946498824888184), np.float64(0.056755333693362886), np.float64(0.05676421678712507), np.float64(0.05678495104705858), np.float64(0.05679271689535212), np.float64(0.05682018409605729), np.float64(0.05679559933559431), np.float64(0.056797037284127834), np.float64(0.056775417737977146), np.float64(0.05693376416668745), np.float64(0.05684542648684393), np.float64(0.056663498076668005), np.float64(0.056627349674865456), np.float64(0.05688989598341068), np.float64(0.056696210930032416), np.float64(0.0568006332712663), np.float64(0.05696685307938601), np.float64(0.056967042172762036), np.float64(0.05692396699209456), np.float64(0.056838568965666456), np.float64(0.056777743893165235), np.float64(0.056904743014706397), np.float64(0.05665038349616716), np.float64(0.056748325792995435), np.float64(0.056915486914058906), np.float64(0.05700595262271677), np.float64(0.05695863301064808), np.float64(0.05694760065383473), np.float64(0.05696797067559079), np.float64(0.05667684084604916), np.float64(0.056773822374201546), np.float64(0.05680307755215466), np.float64(0.05697703501720744), np.float64(0.056835685168193345), np.float64(0.056666388835242706), np.float64(0.056697137726619135), np.float64(0.05675094674048622), np.float64(0.05702848081236092), np.float64(0.0569119075450835), np.float64(0.05689921325592935), np.float64(0.05689189977840964), np.float64(0.05681147309739786), np.float64(0.05696519903655093), np.float64(0.05677854817354049), np.float64(0.05682502007606624), np.float64(0.05696698745614123), np.float64(0.05701472594657366), np.float64(0.056829648521569326), np.float64(0.05683922111678801), np.float64(0.05697057304447851), np.float64(0.056808985998040865), np.float64(0.056651641127007116), np.float64(0.056680443624798134), np.float64(0.05664640118039433), np.float64(0.05662573604298302), np.float64(0.056623743224685885), np.float64(0.05673135941597747), np.float64(0.05677061719677406), np.float64(0.0567767952633833), np.float64(0.05657279605909271), np.float64(0.05670364725216334), np.float64(0.05678146874853479), np.float64(0.0566788117322032), np.float64(0.056896451864352285), np.float64(0.05678350999174684), np.float64(0.05674546331412692), np.float64(0.05669390419691757), np.float64(0.056713246571877624), np.float64(0.05679433207554649), np.float64(0.056741109554797504), np.float64(0.05692303310930915), np.float64(0.05685522265531412), np.float64(0.05672148098583912), np.float64(0.056958657471721005), np.float64(0.05685127706206237), np.float64(0.057142798925569144), np.float64(0.05707574014262984), np.float64(0.057007776873839414), np.float64(0.056878350710600635), np.float64(0.056723971782010905), np.float64(0.056652935685903835), np.float64(0.05691019992542902), np.float64(0.056786454323509504), np.float64(0.05666043680477602), np.float64(0.05691004799667002), np.float64(0.056869967176507406), np.float64(0.05697287141585407), np.float64(0.05682143835289367), np.float64(0.0567436568246994), np.float64(0.056629413990038714), np.float64(0.05666943099061049), np.float64(0.0568350029387654), np.float64(0.056843145724420764), np.float64(0.05718455447971363), np.float64(0.0568708351959074), np.float64(0.05696074258925615), np.float64(0.05694468159847417), np.float64(0.05675026514201233), np.float64(0.05673884712236923), np.float64(0.056794193905935965), np.float64(0.056774975107303984), np.float64(0.056799354226538534), np.float64(0.05679853097764199), np.float64(0.056688717223697845), np.float64(0.057027618317425526), np.float64(0.05695608066329735), np.float64(0.05672042475071807), np.float64(0.0566174260003125), np.float64(0.05689136413172414), np.float64(0.05679039406275935), np.float64(0.05676713652254102), np.float64(0.0567765866987605), np.float64(0.05674995410621756), np.float64(0.05678839923038985), np.float64(0.05672074922218748), np.float64(0.056855902813604225), np.float64(0.056808658908157346), np.float64(0.05686054419125484), np.float64(0.0569900030121203), np.float64(0.05688963550933123), np.float64(0.05660882271522384), np.float64(0.056650162649887106), np.float64(0.05685029230775676), np.float64(0.056812793841497546), np.float64(0.056874620252761555), np.float64(0.05687684717352921), np.float64(0.056765709885873906), np.float64(0.05665401363174296), np.float64(0.0567892814890423), np.float64(0.05662352613830166), np.float64(0.05665255495147229), np.float64(0.05680516258034726), np.float64(0.05675151416909741), np.float64(0.056655926534512895), np.float64(0.0568033806662553), np.float64(0.056780606420611945), np.float64(0.05701966134162574), np.float64(0.05692703022560118), np.float64(0.056892603785555135), np.float64(0.056817841911661296), np.float64(0.056769898205109096), np.float64(0.056840588514560135), np.float64(0.056731205417805255), np.float64(0.056710482224312256), np.float64(0.056711896927472374), np.float64(0.05660155874015394), np.float64(0.05679155219504389), np.float64(0.05682816017814027), np.float64(0.05685146823347614), np.float64(0.05658519433169744), np.float64(0.05701796619331481), np.float64(0.056867916816424946), np.float64(0.0566877159517561), np.float64(0.05678019600638117), np.float64(0.05670923635339898), np.float64(0.05671088321966859), np.float64(0.056965932745233164), np.float64(0.05688352844642184), np.float64(0.056841287946271704), np.float64(0.05689645341683432), np.float64(0.05686207935877743), np.float64(0.05670988584706363), np.float64(0.056727715704735136), np.float64(0.056809392173836085), np.float64(0.056741015071040735), np.float64(0.05684821504638329), np.float64(0.056856472276808796), np.float64(0.0569377970920967), np.float64(0.0569197799434214), np.float64(0.056880755213292326), np.float64(0.05705838231592716), np.float64(0.05679511268952168), np.float64(0.05664381611148145), np.float64(0.05658689192110075), np.float64(0.05695457544640512), np.float64(0.05694605134124935), np.float64(0.056701723495116436), np.float64(0.056956262912229355), np.float64(0.05671085362109789), np.float64(0.056809860963727477), np.float64(0.05692254344115727), np.float64(0.05664039074522581), np.float64(0.05676688350513393), np.float64(0.0567687530956369), np.float64(0.056746128527519785), np.float64(0.05695830418253767), np.float64(0.05691322803032002), np.float64(0.05681142650661077), np.float64(0.056927719409437964), np.float64(0.05694350210780835), np.float64(0.05684276690349051), np.float64(0.056761496069687264), np.float64(0.056843193361808646), np.float64(0.05686522836337308), np.float64(0.05681830876427166), np.float64(0.05683064760202096), np.float64(0.056711809238661016), np.float64(0.056916808942914676), np.float64(0.056792537585316556), np.float64(0.056792221683316546), np.float64(0.0565835263804366), np.float64(0.05663182050350438), np.float64(0.05671848578416825), np.float64(0.056808962403628815), np.float64(0.056851538619400815), np.float64(0.05704583584606264), np.float64(0.057038872945553216), np.float64(0.05695133736254359), np.float64(0.05702493508641299), np.float64(0.05683990445049366), np.float64(0.056691773323791855), np.float64(0.056701995539601986), np.float64(0.05675912439979128), np.float64(0.05667294589014014), np.float64(0.05668284560951463), np.float64(0.05662105899835967), np.float64(0.056666053648198995), np.float64(0.056678317478571986), np.float64(0.05685157932760112), np.float64(0.05671926786536689), np.float64(0.05682699502441686), np.float64(0.05670701273635638), np.float64(0.056679806518110706), np.float64(0.05679637459278981), np.float64(0.05690476623157803), np.float64(0.056945302528209736), np.float64(0.05694611786957303), np.float64(0.05688793304798406), np.float64(0.05682513808327735), np.float64(0.05692835376338156), np.float64(0.057008926867042536), np.float64(0.056854082388335225), np.float64(0.05664697510821295), np.float64(0.05680468855534713), np.float64(0.05690722411299962), np.float64(0.05682295047547405), np.float64(0.0566905687180458), np.float64(0.056872490342266595), np.float64(0.057064149923138595), np.float64(0.056763954292826824), np.float64(0.05667273450108211), np.float64(0.05677276705572708), np.float64(0.056874354010935), np.float64(0.056752951008678124), np.float64(0.05676364907889582), np.float64(0.05652303776280117), np.float64(0.05660268521920029), np.float64(0.05677889875113145), np.float64(0.056683811563374056), np.float64(0.056707050027123625), np.float64(0.056721729382390895), np.float64(0.056785594123904465), np.float64(0.05688718791716256), np.float64(0.05681066574435511), np.float64(0.05667515620121387), np.float64(0.05682183156525841), np.float64(0.056812425530777456), np.float64(0.05672520176905098), np.float64(0.05677985567225367), np.float64(0.05690327289875023), np.float64(0.056714989655408415), np.float64(0.05662188313019295), np.float64(0.056754726341100986), np.float64(0.05667912950221696), np.float64(0.056767196400688044), np.float64(0.05688939620711478), np.float64(0.05674375086202724), np.float64(0.056864090531064046), np.float64(0.056955750167168466), np.float64(0.05685914840564931), np.float64(0.056659226381851696), np.float64(0.05689855107366643), np.float64(0.056986412136640664), np.float64(0.05715548627754808), np.float64(0.056733390539911804), np.float64(0.056737543688456356), np.float64(0.05697212039280612), np.float64(0.0568352162963351), np.float64(0.05687418462574628), np.float64(0.056808556414365226), np.float64(0.056774319234783946), np.float64(0.056686714670202504), np.float64(0.056841741818758604), np.float64(0.056773924236822024), np.float64(0.0567571122785178), np.float64(0.05696049842410887), np.float64(0.056966977710943424), np.float64(0.05707010382969866), np.float64(0.05684331855981666), np.float64(0.057007449622665254), np.float64(0.057046657636073694), np.float64(0.0569252337544816), np.float64(0.05695333583460657), np.float64(0.05668885155707585), np.float64(0.05661783187440094), np.float64(0.056712750697854704), np.float64(0.05676606703295581), np.float64(0.05670820957557961), np.float64(0.056669011446062185), np.float64(0.05673013255366102), np.float64(0.05693760815191153), np.float64(0.05681286624626353), np.float64(0.05701501593301676), np.float64(0.056755104730134266), np.float64(0.05687699608756587), np.float64(0.05680212831285929), np.float64(0.056911289513315866), np.float64(0.05690648127329019), np.float64(0.05684075900690446), np.float64(0.056863748593642266), np.float64(0.05689239076823363), np.float64(0.05682967322114523), np.float64(0.05683534267527886), np.float64(0.056676407678584076), np.float64(0.05668246767208738), np.float64(0.05669483683098872), np.float64(0.05686021656437367), np.float64(0.056984307706943085), np.float64(0.056883225937776644), np.float64(0.05687564836079361), np.float64(0.05701074999319161), np.float64(0.056886016252655276), np.float64(0.056749900599507554), np.float64(0.05664347119144154), np.float64(0.05666744592499437), np.float64(0.05670386218491337), np.float64(0.05675954421188077), np.float64(0.05674446279850502), np.float64(0.05683770497043527), np.float64(0.056683771737209815), np.float64(0.0567658750655756), np.float64(0.056798273493084445), np.float64(0.056949515350068765), np.float64(0.05685629129520227), np.float64(0.05697093428212951), np.float64(0.05685398171591101), np.float64(0.056921080737409174), np.float64(0.05680491006519915), np.float64(0.0565776826174174), np.float64(0.05670346333198482), np.float64(0.056766639817838103), np.float64(0.056888696089123766), np.float64(0.056633426061026684), np.float64(0.056697172705262026), np.float64(0.056754242467998574), np.float64(0.05673422226465453), np.float64(0.05672669114288485), np.float64(0.05656503628946531), np.float64(0.056759153550404874), np.float64(0.056800604339098164), np.float64(0.05682233489322253), np.float64(0.05666097652427579), np.float64(0.05671969788655217), np.float64(0.05675124511127439), np.float64(0.056926037172209176), np.float64(0.05682058101065588), np.float64(0.056967517915540423), np.float64(0.05664413362954842), np.float64(0.05678397335326634), np.float64(0.057151192063775086), np.float64(0.0569568109777021), np.float64(0.05684406828734225), np.float64(0.05688420823421124), np.float64(0.0568430738983511), np.float64(0.056733631849134804), np.float64(0.056693857335552655), np.float64(0.05672233664933275), np.float64(0.05679879249259126), np.float64(0.056720700969701464), np.float64(0.05674640263134636), np.float64(0.05694594714756642), np.float64(0.05687841103945131), np.float64(0.05686782005016342), np.float64(0.056913845684044055), np.float64(0.05681768000298847), np.float64(0.05667878812468444), np.float64(0.056722806095315), np.float64(0.05673574736668735), np.float64(0.056812015865506126), np.float64(0.0568530042061228), np.float64(0.05675372351593017), np.float64(0.05673661660227042), np.float64(0.05682609454561151), np.float64(0.05681884676952147), np.float64(0.05687305484827594), np.float64(0.05691563583171012), np.float64(0.05692182901873281), np.float64(0.056710611194883985), np.float64(0.05670570484388248), np.float64(0.0566053654255943), np.float64(0.056669237960537314), np.float64(0.057044018502341434), np.float64(0.056674412853274445), np.float64(0.0567066254702101), np.float64(0.05662601186727408), np.float64(0.05662338994367318), np.float64(0.05668841718612687), np.float64(0.0566368410111324), np.float64(0.0567699708713215), np.float64(0.056722761339712886), np.float64(0.05683364668518233), np.float64(0.056738425540145986), np.float64(0.05705699991395569), np.float64(0.05680157634227279), np.float64(0.0565590795848647), np.float64(0.05672919527406475), np.float64(0.05681118339938793), np.float64(0.056809674280947194), np.float64(0.056856399749176535), np.float64(0.05677481457405819), np.float64(0.05670571553680474), np.float64(0.05677945825113229), np.float64(0.05681209290357581), np.float64(0.05674698262048031), np.float64(0.056708252032026056), np.float64(0.05683575364642249), np.float64(0.056778595492303), np.float64(0.05666438399788586), np.float64(0.056593853978028005), np.float64(0.056635426064036765), np.float64(0.056755346520947735), np.float64(0.05691262289405172), np.float64(0.05684565649173957), np.float64(0.05680802959489447), np.float64(0.05677768264749084), np.float64(0.05682565001856002), np.float64(0.056619624194026184), np.float64(0.056662434912329925), np.float64(0.05663656468026722), np.float64(0.05662616513758652), np.float64(0.056747820133129644), np.float64(0.05687140578989237), np.float64(0.0567182877395723), np.float64(0.05689347663661601), np.float64(0.0567301828980647), np.float64(0.05667820140205408), np.float64(0.05679833561876326), np.float64(0.05675817847400893), np.float64(0.056660267284416435), np.float64(0.05682923426193971), np.float64(0.05684179650335687), np.float64(0.056747455328506086), np.float64(0.05678202711575188), np.float64(0.056658024333422985), np.float64(0.05654535721199906), np.float64(0.056887363072969536), np.float64(0.0568587526506686), np.float64(0.05671165077387396), np.float64(0.056812694740532715), np.float64(0.05663682168442168), np.float64(0.05674861245103159), np.float64(0.056803222617281456), np.float64(0.05668989174776935), np.float64(0.05667252883558116), np.float64(0.056824721611703294), np.float64(0.056720191205408395), np.float64(0.05659487412762201), np.float64(0.05676754768407073), np.float64(0.05669952868553481), np.float64(0.056772368083231974), np.float64(0.05686180173643638), np.float64(0.05691734668277375), np.float64(0.05680913682918919), np.float64(0.056803329018712975), np.float64(0.056670523216166745), np.float64(0.05670033953221591), np.float64(0.056846817747515085), np.float64(0.05697554383584521), np.float64(0.05682760382842994), np.float64(0.05712125885759444), np.float64(0.05695369373369624), np.float64(0.05672423818258292), np.float64(0.05676558311846496), np.float64(0.056730106745521446), np.float64(0.056689030494419625), np.float64(0.056647337648315504), np.float64(0.056673110347961825), np.float64(0.05694554990734274), np.float64(0.05662077627787567), np.float64(0.05686180363886293)]\n",
      "Epoch 1/500, Train Loss: 0.04939193985859111, Val Loss: 0.05654649462569563\n",
      "Epoch 2/500, Train Loss: 0.049410725508206174, Val Loss: 0.05719378710129309\n",
      "Epoch 3/500, Train Loss: 0.049433051168153545, Val Loss: 0.05646011189569566\n",
      "Epoch 4/500, Train Loss: 0.04978646919051701, Val Loss: 0.05626086227165081\n",
      "Epoch 5/500, Train Loss: 0.04942041298008662, Val Loss: 0.05723227182179832\n",
      "Epoch 6/500, Train Loss: 0.04936383338918035, Val Loss: 0.05693958458213941\n",
      "Epoch 7/500, Train Loss: 0.049387085990711704, Val Loss: 0.05656072667685992\n",
      "Epoch 8/500, Train Loss: 0.049556186650544606, Val Loss: 0.05633563172176607\n",
      "Epoch 9/500, Train Loss: 0.049547661219267104, Val Loss: 0.057627599639829385\n",
      "Epoch 10/500, Train Loss: 0.049517129767610794, Val Loss: 0.0575439524005731\n",
      "Epoch 11/500, Train Loss: 0.04936159694050902, Val Loss: 0.056918848701390135\n",
      "Epoch 12/500, Train Loss: 0.049393907054702854, Val Loss: 0.05654105918021174\n",
      "Epoch 13/500, Train Loss: 0.04942847344465054, Val Loss: 0.05646768638203279\n",
      "Epoch 14/500, Train Loss: 0.049702541997494326, Val Loss: 0.05800296887593099\n",
      "Epoch 15/500, Train Loss: 0.04938270183597842, Val Loss: 0.05706396592856512\n",
      "Epoch 16/500, Train Loss: 0.04939437142926159, Val Loss: 0.056539801458792095\n",
      "Epoch 17/500, Train Loss: 0.04935497089403027, Val Loss: 0.056774010550639825\n",
      "Epoch 18/500, Train Loss: 0.04941575440026974, Val Loss: 0.05649090888125247\n",
      "Epoch 19/500, Train Loss: 0.04942539905288476, Val Loss: 0.05647298728149217\n",
      "Epoch 20/500, Train Loss: 0.049684733401937915, Val Loss: 0.05628013642344472\n",
      "Epoch 21/500, Train Loss: 0.049364824043761836, Val Loss: 0.05665505712138019\n",
      "Epoch 22/500, Train Loss: 0.049393735215316835, Val Loss: 0.05654150484684624\n",
      "Epoch 23/500, Train Loss: 0.0493683386282092, Val Loss: 0.056634759712236485\n",
      "Epoch 24/500, Train Loss: 0.049357862574973384, Val Loss: 0.056875261658648715\n",
      "Epoch 25/500, Train Loss: 0.049895981794284554, Val Loss: 0.05841012606396241\n",
      "Epoch 26/500, Train Loss: 0.04943915815596945, Val Loss: 0.05730117257071395\n",
      "Epoch 27/500, Train Loss: 0.049366213964911566, Val Loss: 0.05695918435668786\n",
      "Epoch 28/500, Train Loss: 0.04942392433131224, Val Loss: 0.05647557598334606\n",
      "Epoch 29/500, Train Loss: 0.04956877011498978, Val Loss: 0.057682885687505535\n",
      "Epoch 30/500, Train Loss: 0.049368516887964634, Val Loss: 0.05697654072110623\n",
      "Epoch 31/500, Train Loss: 0.04968690279679418, Val Loss: 0.057967552038299584\n",
      "Epoch 32/500, Train Loss: 0.049445405744310784, Val Loss: 0.05644123870674566\n",
      "Epoch 33/500, Train Loss: 0.049355979928913184, Val Loss: 0.056742850946084264\n",
      "Epoch 34/500, Train Loss: 0.04938171771329966, Val Loss: 0.0565781561613573\n",
      "Epoch 35/500, Train Loss: 0.04948178914149806, Val Loss: 0.05744024387620311\n",
      "Epoch 36/500, Train Loss: 0.049460368973240076, Val Loss: 0.05642116033050037\n",
      "Epoch 37/500, Train Loss: 0.049354905154285485, Val Loss: 0.056778500525997\n",
      "Epoch 38/500, Train Loss: 0.0493574377104459, Val Loss: 0.056868824747232975\n",
      "Epoch 39/500, Train Loss: 0.0493567151498295, Val Loss: 0.056856885935882326\n",
      "Epoch 40/500, Train Loss: 0.049355502095486184, Val Loss: 0.05683005440159906\n",
      "Epoch 41/500, Train Loss: 0.04959253765998342, Val Loss: 0.0577430182296623\n",
      "Epoch 42/500, Train Loss: 0.04991215086373523, Val Loss: 0.056255388271141044\n",
      "Epoch 43/500, Train Loss: 0.049443026388148834, Val Loss: 0.056444578455423965\n",
      "Epoch 44/500, Train Loss: 0.04937538593678637, Val Loss: 0.05702172492477201\n",
      "Epoch 45/500, Train Loss: 0.0493626366451446, Val Loss: 0.05692835670601643\n",
      "Epoch 46/500, Train Loss: 0.049377095187968144, Val Loss: 0.05659493996608859\n",
      "Epoch 47/500, Train Loss: 0.04944298379465829, Val Loss: 0.057313926477966876\n",
      "Epoch 48/500, Train Loss: 0.049602819095522534, Val Loss: 0.05630996142223918\n",
      "Epoch 49/500, Train Loss: 0.049368096448702575, Val Loss: 0.05663565968907038\n",
      "Epoch 50/500, Train Loss: 0.049368056079672706, Val Loss: 0.05697232456266918\n",
      "Epoch 51/500, Train Loss: 0.05079806759823551, Val Loss: 0.059992272628371215\n",
      "Epoch 52/500, Train Loss: 0.04942859182749091, Val Loss: 0.057261749927634664\n",
      "Epoch 53/500, Train Loss: 0.049421513756769286, Val Loss: 0.056479391998322914\n",
      "Epoch 54/500, Train Loss: 0.04939639177972836, Val Loss: 0.05653376303289695\n",
      "Epoch 55/500, Train Loss: 0.049413084525927894, Val Loss: 0.05649548166246872\n",
      "Epoch 56/500, Train Loss: 0.0493597782895154, Val Loss: 0.05689629715706733\n",
      "Epoch 57/500, Train Loss: 0.04952581451664004, Val Loss: 0.057564361616579164\n",
      "Epoch 58/500, Train Loss: 0.04950740895045325, Val Loss: 0.05751154111043646\n",
      "Epoch 59/500, Train Loss: 0.04944048212641173, Val Loss: 0.05644743230030333\n",
      "Epoch 60/500, Train Loss: 0.049550908514509294, Val Loss: 0.056338339176685376\n",
      "Epoch 61/500, Train Loss: 0.049360265361631, Val Loss: 0.05688850629495481\n",
      "Epoch 62/500, Train Loss: 0.04962736740801974, Val Loss: 0.05629975179039081\n",
      "Epoch 63/500, Train Loss: 0.04992488202911656, Val Loss: 0.05625908098870898\n",
      "Epoch 64/500, Train Loss: 0.04937177618728575, Val Loss: 0.05694748712024586\n",
      "Epoch 65/500, Train Loss: 0.049373987229370926, Val Loss: 0.056668970711699726\n",
      "Epoch 66/500, Train Loss: 0.04942561467140407, Val Loss: 0.05713176932771544\n",
      "Epoch 67/500, Train Loss: 0.049422977212816764, Val Loss: 0.05678720853622593\n",
      "Epoch 68/500, Train Loss: 0.04964756490629176, Val Loss: 0.05658880707092109\n",
      "Epoch 69/500, Train Loss: 0.050019578641496566, Val Loss: 0.05728811198892405\n",
      "Epoch 70/500, Train Loss: 0.05187157094840203, Val Loss: 0.059231639274158594\n",
      "Epoch 71/500, Train Loss: 0.05844599621041374, Val Loss: 0.06615833890703925\n",
      "Epoch 72/500, Train Loss: 0.07110388812977812, Val Loss: 0.07941759571763939\n",
      "Epoch 73/500, Train Loss: 0.08410707653426058, Val Loss: 0.09327259595037135\n",
      "Epoch 74/500, Train Loss: 0.08952544701265257, Val Loss: 0.09923615275737621\n",
      "Epoch 75/500, Train Loss: 0.09348270387164793, Val Loss: 0.10332737870650424\n",
      "Epoch 76/500, Train Loss: 0.09359177718734961, Val Loss: 0.10368758445247356\n",
      "Epoch 77/500, Train Loss: 0.09458717110396782, Val Loss: 0.10473439283164711\n",
      "Epoch 78/500, Train Loss: 0.09466928859995585, Val Loss: 0.10496967663864697\n",
      "Epoch 79/500, Train Loss: 0.09524679874474457, Val Loss: 0.10558194059864563\n",
      "Epoch 80/500, Train Loss: 0.09563767583937084, Val Loss: 0.10604248047311873\n",
      "Epoch 81/500, Train Loss: 0.09606192032978302, Val Loss: 0.10659874429361695\n",
      "Epoch 82/500, Train Loss: 0.09528894501086535, Val Loss: 0.10594371211027546\n",
      "Epoch 83/500, Train Loss: 0.09599406651008895, Val Loss: 0.10672990752649424\n",
      "Epoch 84/500, Train Loss: 0.09601142693943396, Val Loss: 0.10684726694786689\n",
      "Epoch 85/500, Train Loss: 0.09719224745357417, Val Loss: 0.10813097917848434\n",
      "Epoch 86/500, Train Loss: 0.09584066141938, Val Loss: 0.10685714507581653\n",
      "Epoch 87/500, Train Loss: 0.09710710153547844, Val Loss: 0.10824532202433891\n",
      "Epoch 88/500, Train Loss: 0.09626466805747948, Val Loss: 0.10745149606040302\n",
      "Epoch 89/500, Train Loss: 0.0964279538514238, Val Loss: 0.10775017613329119\n",
      "Epoch 90/500, Train Loss: 0.0961688378009794, Val Loss: 0.10754076546135158\n",
      "Epoch 91/500, Train Loss: 0.09660120870281474, Val Loss: 0.10800354023503299\n",
      "Epoch 92/500, Train Loss: 0.09694583464554536, Val Loss: 0.10845494989127324\n",
      "Epoch 93/500, Train Loss: 0.09616007826219156, Val Loss: 0.10775212878769783\n",
      "Epoch 94/500, Train Loss: 0.09587488462457128, Val Loss: 0.10751205115010803\n",
      "Epoch 95/500, Train Loss: 0.09658282943978065, Val Loss: 0.10828436552119275\n",
      "Epoch 96/500, Train Loss: 0.09769049861184297, Val Loss: 0.10942318435761188\n",
      "Epoch 97/500, Train Loss: 0.0973776494320981, Val Loss: 0.10917711168563533\n",
      "Epoch 98/500, Train Loss: 0.09692407672833322, Val Loss: 0.108758030915401\n",
      "Epoch 99/500, Train Loss: 0.09609565368356264, Val Loss: 0.1079377571425292\n",
      "Epoch 100/500, Train Loss: 0.09749179903058199, Val Loss: 0.10937662362859796\n",
      "Epoch 101/500, Train Loss: 0.09604987482214007, Val Loss: 0.1079177923294147\n",
      "Epoch 102/500, Train Loss: 0.09722583051337223, Val Loss: 0.10914876239819808\n",
      "Epoch 103/500, Train Loss: 0.09796639228623441, Val Loss: 0.10994897626162092\n",
      "Epoch 104/500, Train Loss: 0.09689505131252872, Val Loss: 0.10888865291471662\n",
      "Epoch 105/500, Train Loss: 0.09693166029869418, Val Loss: 0.10892397640751401\n",
      "Epoch 106/500, Train Loss: 0.09586930500637848, Val Loss: 0.10789943773166641\n",
      "Epoch 107/500, Train Loss: 0.09735689932771972, Val Loss: 0.10941393839800764\n",
      "Epoch 108/500, Train Loss: 0.0967537003599974, Val Loss: 0.10881947910232015\n",
      "Epoch 109/500, Train Loss: 0.09644122451338841, Val Loss: 0.10851363667563828\n",
      "Epoch 110/500, Train Loss: 0.09751518041324111, Val Loss: 0.10957825195663394\n",
      "Epoch 111/500, Train Loss: 0.09700999307955314, Val Loss: 0.10909172172983155\n",
      "Epoch 112/500, Train Loss: 0.09747321365280054, Val Loss: 0.1095768773051348\n",
      "Epoch 113/500, Train Loss: 0.09672767397681092, Val Loss: 0.10888987981729141\n",
      "Epoch 114/500, Train Loss: 0.09728541141434965, Val Loss: 0.10944914300497102\n",
      "Epoch 115/500, Train Loss: 0.097047674336584, Val Loss: 0.10917712172868031\n",
      "Epoch 116/500, Train Loss: 0.09700476380067856, Val Loss: 0.1091497139280133\n",
      "Epoch 117/500, Train Loss: 0.09666830410708695, Val Loss: 0.10881926543195593\n",
      "Epoch 118/500, Train Loss: 0.09744735198130355, Val Loss: 0.10962954480376817\n",
      "Epoch 119/500, Train Loss: 0.09680131356050117, Val Loss: 0.1089875752302437\n",
      "Epoch 120/500, Train Loss: 0.09702906062337278, Val Loss: 0.10920360548981169\n",
      "Epoch 121/500, Train Loss: 0.09780106798999039, Val Loss: 0.10998395408615474\n",
      "Epoch 122/500, Train Loss: 0.09707873305498885, Val Loss: 0.10928535982243315\n",
      "Epoch 123/500, Train Loss: 0.09769966195613947, Val Loss: 0.10989994916906813\n",
      "Epoch 124/500, Train Loss: 0.09720759057124345, Val Loss: 0.10939103015532904\n",
      "Epoch 125/500, Train Loss: 0.09702258045069626, Val Loss: 0.10919710600841138\n",
      "Epoch 126/500, Train Loss: 0.09698497976716784, Val Loss: 0.1091473776202988\n",
      "Epoch 127/500, Train Loss: 0.09682023688721271, Val Loss: 0.10896564428219718\n",
      "Epoch 128/500, Train Loss: 0.09692231135368785, Val Loss: 0.10908930985335877\n",
      "Epoch 129/500, Train Loss: 0.09659016050211794, Val Loss: 0.10871690476366165\n",
      "Epoch 130/500, Train Loss: 0.09724568258698746, Val Loss: 0.10940967066002096\n",
      "Epoch 131/500, Train Loss: 0.09690078761238138, Val Loss: 0.10905548701132695\n",
      "Epoch 132/500, Train Loss: 0.09658462667985587, Val Loss: 0.10874807424273528\n",
      "Epoch 133/500, Train Loss: 0.09698854516936325, Val Loss: 0.10912084116429117\n",
      "Epoch 134/500, Train Loss: 0.09728516483056815, Val Loss: 0.10943930272645944\n",
      "Epoch 135/500, Train Loss: 0.09670488447629542, Val Loss: 0.10884963352971583\n",
      "Epoch 136/500, Train Loss: 0.09741111126362938, Val Loss: 0.10957216164580955\n",
      "Epoch 137/500, Train Loss: 0.09755550931063613, Val Loss: 0.10971304557518881\n",
      "Epoch 138/500, Train Loss: 0.09686093941290358, Val Loss: 0.10898853602340929\n",
      "Epoch 139/500, Train Loss: 0.09642743484051454, Val Loss: 0.1085541434914999\n",
      "Epoch 140/500, Train Loss: 0.09655421368927553, Val Loss: 0.1086660461077936\n",
      "Epoch 141/500, Train Loss: 0.09688092780657823, Val Loss: 0.10899026460014963\n",
      "Epoch 142/500, Train Loss: 0.09754747494632801, Val Loss: 0.10968723199011833\n",
      "Epoch 143/500, Train Loss: 0.09753171423330141, Val Loss: 0.10968614181801518\n",
      "Epoch 144/500, Train Loss: 0.09699306603661263, Val Loss: 0.10914132700362687\n",
      "Epoch 145/500, Train Loss: 0.09709981074993665, Val Loss: 0.10920945251431168\n",
      "Epoch 146/500, Train Loss: 0.09619809994353937, Val Loss: 0.10827268175960392\n",
      "Epoch 147/500, Train Loss: 0.09798074196021539, Val Loss: 0.11011085950212127\n",
      "Epoch 148/500, Train Loss: 0.0969159148959214, Val Loss: 0.10903050991685642\n",
      "Epoch 149/500, Train Loss: 0.09641606665866882, Val Loss: 0.10852269278173422\n",
      "Epoch 150/500, Train Loss: 0.09763312932213526, Val Loss: 0.10974564593052825\n",
      "Epoch 151/500, Train Loss: 0.09680266073983673, Val Loss: 0.10888689325115145\n",
      "Epoch 152/500, Train Loss: 0.09662727839272554, Val Loss: 0.10868983580214618\n",
      "Epoch 153/500, Train Loss: 0.09739453348866213, Val Loss: 0.10947201771892841\n",
      "Epoch 154/500, Train Loss: 0.09804398668700537, Val Loss: 0.11014413460422823\n",
      "Epoch 155/500, Train Loss: 0.09753274177723639, Val Loss: 0.10962211781490633\n",
      "Epoch 156/500, Train Loss: 0.09782232294302488, Val Loss: 0.10991985063236161\n",
      "Epoch 157/500, Train Loss: 0.09718063954526146, Val Loss: 0.10926267726173261\n",
      "Epoch 158/500, Train Loss: 0.09680148823112768, Val Loss: 0.1088537776426061\n",
      "Epoch 159/500, Train Loss: 0.09738642978332882, Val Loss: 0.10946144522207579\n",
      "Epoch 160/500, Train Loss: 0.09674158710173861, Val Loss: 0.10875025187500295\n",
      "Epoch 161/500, Train Loss: 0.0975882725807304, Val Loss: 0.10965369509375311\n",
      "Epoch 162/500, Train Loss: 0.0966739674271955, Val Loss: 0.1086959520253962\n",
      "Epoch 163/500, Train Loss: 0.09763146099974504, Val Loss: 0.10970034465567072\n",
      "Epoch 164/500, Train Loss: 0.0963487754728622, Val Loss: 0.10834972307106959\n",
      "Epoch 165/500, Train Loss: 0.09776575729696811, Val Loss: 0.10983162393460068\n",
      "Epoch 166/500, Train Loss: 0.09704605795733345, Val Loss: 0.10908107854718584\n",
      "Epoch 167/500, Train Loss: 0.09744901894240283, Val Loss: 0.1094951405228738\n",
      "Epoch 168/500, Train Loss: 0.09714819968627955, Val Loss: 0.10918046671670126\n",
      "Epoch 169/500, Train Loss: 0.09664190951084169, Val Loss: 0.10864373826387042\n",
      "Epoch 170/500, Train Loss: 0.09712558083179584, Val Loss: 0.10913151840840404\n",
      "Epoch 171/500, Train Loss: 0.09772452471309152, Val Loss: 0.10977952249055953\n",
      "Epoch 172/500, Train Loss: 0.09741834515876566, Val Loss: 0.10945741300754003\n",
      "Epoch 173/500, Train Loss: 0.09796216628358628, Val Loss: 0.10998990986871882\n",
      "Epoch 174/500, Train Loss: 0.09680054740280815, Val Loss: 0.10880957232346194\n",
      "Epoch 175/500, Train Loss: 0.09729044442701432, Val Loss: 0.10930798376177674\n",
      "Epoch 176/500, Train Loss: 0.097204989424296, Val Loss: 0.10921275023503427\n",
      "Epoch 177/500, Train Loss: 0.09728746742931901, Val Loss: 0.10930034005684922\n",
      "Epoch 178/500, Train Loss: 0.09669314862158741, Val Loss: 0.10867811400148111\n",
      "Epoch 179/500, Train Loss: 0.09681681349050204, Val Loss: 0.10879976852315687\n",
      "Epoch 180/500, Train Loss: 0.0968314111528787, Val Loss: 0.10880127951020058\n",
      "Epoch 181/500, Train Loss: 0.09722632948405295, Val Loss: 0.10920705862619508\n",
      "Epoch 182/500, Train Loss: 0.09724778945503935, Val Loss: 0.1092311651877106\n",
      "Epoch 183/500, Train Loss: 0.09651642922064627, Val Loss: 0.10845486589101087\n",
      "Epoch 184/500, Train Loss: 0.0969419727136456, Val Loss: 0.10889940879387414\n",
      "Epoch 185/500, Train Loss: 0.09696650976399454, Val Loss: 0.10894096449134487\n",
      "Epoch 186/500, Train Loss: 0.09696885897342274, Val Loss: 0.1089420208169578\n",
      "Epoch 187/500, Train Loss: 0.09769137871609461, Val Loss: 0.10968759030790448\n",
      "Epoch 188/500, Train Loss: 0.09744483948299468, Val Loss: 0.10941818296024336\n",
      "Epoch 189/500, Train Loss: 0.096583062970674, Val Loss: 0.10852265047096825\n",
      "Epoch 190/500, Train Loss: 0.0972592248466905, Val Loss: 0.10923286300226753\n",
      "Epoch 191/500, Train Loss: 0.09763242209747093, Val Loss: 0.10960798039930193\n",
      "Epoch 192/500, Train Loss: 0.0974120766948101, Val Loss: 0.1093468348690174\n",
      "Epoch 193/500, Train Loss: 0.09767125020030769, Val Loss: 0.10962036537221741\n",
      "Epoch 194/500, Train Loss: 0.09712693688226912, Val Loss: 0.10906610543977184\n",
      "Epoch 195/500, Train Loss: 0.09736497804967273, Val Loss: 0.10931130907234662\n",
      "Epoch 196/500, Train Loss: 0.09669412584847564, Val Loss: 0.10863167446860937\n",
      "Epoch 197/500, Train Loss: 0.0971346177135522, Val Loss: 0.10904471419239245\n",
      "Epoch 198/500, Train Loss: 0.09752442348615821, Val Loss: 0.10947934259464524\n",
      "Epoch 199/500, Train Loss: 0.09707513947119625, Val Loss: 0.1090048840527447\n",
      "Epoch 200/500, Train Loss: 0.09731500727677296, Val Loss: 0.10927140557831576\n",
      "Epoch 201/500, Train Loss: 0.09824463350601341, Val Loss: 0.1102091110414881\n",
      "Epoch 202/500, Train Loss: 0.09702956655788768, Val Loss: 0.10895388640359498\n",
      "Epoch 203/500, Train Loss: 0.09702544005985074, Val Loss: 0.10894349127665222\n",
      "Epoch 204/500, Train Loss: 0.09746992927996147, Val Loss: 0.10940381817080018\n",
      "Epoch 205/500, Train Loss: 0.09679863698866971, Val Loss: 0.10871714558104069\n",
      "Epoch 206/500, Train Loss: 0.097197609692073, Val Loss: 0.10912912859376704\n",
      "Epoch 207/500, Train Loss: 0.09725737669429348, Val Loss: 0.10917931593782938\n",
      "Epoch 208/500, Train Loss: 0.09718921675655567, Val Loss: 0.10907618522740999\n",
      "Epoch 209/500, Train Loss: 0.09792743567603424, Val Loss: 0.10983597553397415\n",
      "Epoch 210/500, Train Loss: 0.09743671247552067, Val Loss: 0.10930861069377971\n",
      "Epoch 211/500, Train Loss: 0.0980248245907133, Val Loss: 0.10993895255000519\n",
      "Epoch 212/500, Train Loss: 0.09782323248457508, Val Loss: 0.10972192062913676\n",
      "Epoch 213/500, Train Loss: 0.09697158312338554, Val Loss: 0.1088139414880413\n",
      "Epoch 214/500, Train Loss: 0.09729974809566137, Val Loss: 0.10914965245029187\n",
      "Epoch 215/500, Train Loss: 0.09654920070189074, Val Loss: 0.10836624425483754\n",
      "Epoch 216/500, Train Loss: 0.0970022429232431, Val Loss: 0.10878743443171236\n",
      "Epoch 217/500, Train Loss: 0.0972597054286583, Val Loss: 0.10910410677550733\n",
      "Epoch 218/500, Train Loss: 0.09668052381706245, Val Loss: 0.10848194794185341\n",
      "Epoch 219/500, Train Loss: 0.0972678774337782, Val Loss: 0.10910124435852742\n",
      "Epoch 220/500, Train Loss: 0.09704649427544831, Val Loss: 0.10886318530724029\n",
      "Epoch 221/500, Train Loss: 0.09688861573190045, Val Loss: 0.1087197069369411\n",
      "Epoch 222/500, Train Loss: 0.0967095878953065, Val Loss: 0.10851557156436935\n",
      "Epoch 223/500, Train Loss: 0.0969323874926253, Val Loss: 0.10873316772142216\n",
      "Epoch 224/500, Train Loss: 0.09763603473658977, Val Loss: 0.10946166668406399\n",
      "Epoch 225/500, Train Loss: 0.09729694282709568, Val Loss: 0.10911172126770442\n",
      "Epoch 226/500, Train Loss: 0.09793439951866093, Val Loss: 0.10977364431210367\n",
      "Epoch 227/500, Train Loss: 0.09672036300230161, Val Loss: 0.10851786191448605\n",
      "Epoch 228/500, Train Loss: 0.09676029873000333, Val Loss: 0.1085083438221858\n",
      "Epoch 229/500, Train Loss: 0.09692539004711026, Val Loss: 0.10870372936611027\n",
      "Epoch 230/500, Train Loss: 0.09690793654436723, Val Loss: 0.10867675496115714\n",
      "Epoch 231/500, Train Loss: 0.09764958403490905, Val Loss: 0.10945475885482786\n",
      "Epoch 232/500, Train Loss: 0.0972381737013531, Val Loss: 0.1090086360201499\n",
      "Epoch 233/500, Train Loss: 0.09593443454645463, Val Loss: 0.10763923440741849\n",
      "Epoch 234/500, Train Loss: 0.09666085243769768, Val Loss: 0.10837606672994113\n",
      "Epoch 235/500, Train Loss: 0.09687604624714778, Val Loss: 0.10860758188784603\n",
      "Epoch 236/500, Train Loss: 0.09798334917412223, Val Loss: 0.10977367650845661\n",
      "Epoch 237/500, Train Loss: 0.09689039352129201, Val Loss: 0.10860878924331863\n",
      "Epoch 238/500, Train Loss: 0.09678653968473094, Val Loss: 0.10850109818009149\n",
      "Epoch 239/500, Train Loss: 0.09712022256812376, Val Loss: 0.1088383763489436\n",
      "Epoch 240/500, Train Loss: 0.09678274160159708, Val Loss: 0.10847235232303946\n",
      "Epoch 241/500, Train Loss: 0.09744456547790559, Val Loss: 0.10915907146062402\n",
      "Epoch 242/500, Train Loss: 0.09747083935908765, Val Loss: 0.10918849681835605\n",
      "Epoch 243/500, Train Loss: 0.0976601494309933, Val Loss: 0.1093899059420775\n",
      "Epoch 244/500, Train Loss: 0.09692692641438555, Val Loss: 0.10862342095666953\n",
      "Epoch 245/500, Train Loss: 0.09828565652254903, Val Loss: 0.11002414459309097\n",
      "Epoch 246/500, Train Loss: 0.09738466153832376, Val Loss: 0.10906181644982776\n",
      "Epoch 247/500, Train Loss: 0.09697867520530716, Val Loss: 0.10866435250683823\n",
      "Epoch 248/500, Train Loss: 0.09728778187291563, Val Loss: 0.10897367133842352\n",
      "Epoch 249/500, Train Loss: 0.09765535787647489, Val Loss: 0.10936964943652336\n",
      "Epoch 250/500, Train Loss: 0.09778426409800713, Val Loss: 0.10953221261177035\n",
      "Epoch 251/500, Train Loss: 0.09758357313096186, Val Loss: 0.10931532375945009\n",
      "Epoch 252/500, Train Loss: 0.09723164765299393, Val Loss: 0.10893017133152488\n",
      "Epoch 253/500, Train Loss: 0.09696630158660141, Val Loss: 0.1086214570228516\n",
      "Epoch 254/500, Train Loss: 0.0971604861386858, Val Loss: 0.10883213303911228\n",
      "Epoch 255/500, Train Loss: 0.09717214198078505, Val Loss: 0.10883541344408013\n",
      "Epoch 256/500, Train Loss: 0.09737053646753083, Val Loss: 0.10905926129022409\n",
      "Epoch 257/500, Train Loss: 0.09724018110848531, Val Loss: 0.10892224941409547\n",
      "Epoch 258/500, Train Loss: 0.09749749915177003, Val Loss: 0.10916436879468046\n",
      "Epoch 259/500, Train Loss: 0.09745822301458473, Val Loss: 0.1091206267278724\n",
      "Epoch 260/500, Train Loss: 0.0972181751288079, Val Loss: 0.10889404698921981\n",
      "Epoch 261/500, Train Loss: 0.09709608712144548, Val Loss: 0.10876132738824873\n",
      "Epoch 262/500, Train Loss: 0.09740580135503586, Val Loss: 0.10907762727487548\n",
      "Epoch 263/500, Train Loss: 0.0974632077832476, Val Loss: 0.10913776142146647\n",
      "Epoch 264/500, Train Loss: 0.09642035374599388, Val Loss: 0.10804379056983127\n",
      "Epoch 265/500, Train Loss: 0.09723769940258706, Val Loss: 0.10891855008795115\n",
      "Epoch 266/500, Train Loss: 0.09711942597247893, Val Loss: 0.10877785963704488\n",
      "Epoch 267/500, Train Loss: 0.09724014062875598, Val Loss: 0.10890499522020064\n",
      "Epoch 268/500, Train Loss: 0.09799635746056959, Val Loss: 0.1096981911383517\n",
      "Epoch 269/500, Train Loss: 0.0969706450077314, Val Loss: 0.10862023346919289\n",
      "Epoch 270/500, Train Loss: 0.09757146280255896, Val Loss: 0.1092209854460939\n",
      "Epoch 271/500, Train Loss: 0.09713978104756935, Val Loss: 0.10875979278147335\n",
      "Epoch 272/500, Train Loss: 0.09757542548122994, Val Loss: 0.1092352973847858\n",
      "Epoch 273/500, Train Loss: 0.09698011656934097, Val Loss: 0.10862390176310913\n",
      "Epoch 274/500, Train Loss: 0.09706087546783587, Val Loss: 0.10870810924122674\n",
      "Epoch 275/500, Train Loss: 0.09730572860776084, Val Loss: 0.10897003551533935\n",
      "Epoch 276/500, Train Loss: 0.09699891065127444, Val Loss: 0.10864714677822446\n",
      "Epoch 277/500, Train Loss: 0.09733134293892513, Val Loss: 0.10896891179997689\n",
      "Epoch 278/500, Train Loss: 0.09687002455237913, Val Loss: 0.1085149625959245\n",
      "Epoch 279/500, Train Loss: 0.09693329214081471, Val Loss: 0.10856622440670961\n",
      "Epoch 280/500, Train Loss: 0.09765263358245066, Val Loss: 0.10930779312720645\n",
      "Epoch 281/500, Train Loss: 0.0979312069619721, Val Loss: 0.10957328675449576\n",
      "Epoch 282/500, Train Loss: 0.09775376942867453, Val Loss: 0.10940483253067045\n",
      "Epoch 283/500, Train Loss: 0.09794883945172256, Val Loss: 0.10959196875530154\n",
      "Epoch 284/500, Train Loss: 0.09750187337636501, Val Loss: 0.10914224042871132\n",
      "Epoch 285/500, Train Loss: 0.09735605389491674, Val Loss: 0.10898004230802562\n",
      "Epoch 286/500, Train Loss: 0.09701746969616386, Val Loss: 0.10863945199300284\n",
      "Epoch 287/500, Train Loss: 0.09677338334063107, Val Loss: 0.1083763451487292\n",
      "Epoch 288/500, Train Loss: 0.09751387289767488, Val Loss: 0.10914432610684033\n",
      "Epoch 289/500, Train Loss: 0.09706965999334898, Val Loss: 0.10869881846536625\n",
      "Epoch 290/500, Train Loss: 0.09727325140553632, Val Loss: 0.10889470422198225\n",
      "Epoch 291/500, Train Loss: 0.09743955935240604, Val Loss: 0.10906386666942475\n",
      "Epoch 292/500, Train Loss: 0.09730235313424801, Val Loss: 0.10892691052675511\n",
      "Epoch 293/500, Train Loss: 0.09673395730603541, Val Loss: 0.10832632692314938\n",
      "Epoch 294/500, Train Loss: 0.09780791886410072, Val Loss: 0.10946212368593686\n",
      "Epoch 295/500, Train Loss: 0.09700305744813514, Val Loss: 0.10861064900657738\n",
      "Epoch 296/500, Train Loss: 0.09702703761213596, Val Loss: 0.10862810417015234\n",
      "Epoch 297/500, Train Loss: 0.09622807710192129, Val Loss: 0.10775546697842295\n",
      "Epoch 298/500, Train Loss: 0.09691482822010818, Val Loss: 0.10849562660868461\n",
      "Epoch 299/500, Train Loss: 0.09739803926942406, Val Loss: 0.10901802703980236\n",
      "Epoch 300/500, Train Loss: 0.09827414870735371, Val Loss: 0.1099263897105825\n",
      "Epoch 301/500, Train Loss: 0.09655900870869333, Val Loss: 0.10811137179691435\n",
      "Epoch 302/500, Train Loss: 0.09743558533906647, Val Loss: 0.10903518488397988\n",
      "Epoch 303/500, Train Loss: 0.09797608876398628, Val Loss: 0.10958331985846095\n",
      "Epoch 304/500, Train Loss: 0.09749274135970872, Val Loss: 0.10909936659630906\n",
      "Epoch 305/500, Train Loss: 0.09785168949044501, Val Loss: 0.10946283065423326\n",
      "Epoch 306/500, Train Loss: 0.0974473490731445, Val Loss: 0.10903859486792611\n",
      "Epoch 307/500, Train Loss: 0.09668849146897429, Val Loss: 0.10823836410643278\n",
      "Epoch 308/500, Train Loss: 0.09743490183584695, Val Loss: 0.10901068379567479\n",
      "Epoch 309/500, Train Loss: 0.09816060272860272, Val Loss: 0.10978059846250247\n",
      "Epoch 310/500, Train Loss: 0.0970101094887689, Val Loss: 0.10858128993605892\n",
      "Epoch 311/500, Train Loss: 0.09638169051346121, Val Loss: 0.10790179353649254\n",
      "Epoch 312/500, Train Loss: 0.09706516524292788, Val Loss: 0.10865226776805761\n",
      "Epoch 313/500, Train Loss: 0.09698968248104645, Val Loss: 0.10853397881226703\n",
      "Epoch 314/500, Train Loss: 0.09731190133422013, Val Loss: 0.10889698968755354\n",
      "Epoch 315/500, Train Loss: 0.0968031997691575, Val Loss: 0.1083574527690967\n",
      "Epoch 316/500, Train Loss: 0.09737790637048233, Val Loss: 0.10895536163847573\n",
      "Epoch 317/500, Train Loss: 0.09748476830169583, Val Loss: 0.1090820513005184\n",
      "Epoch 318/500, Train Loss: 0.09754020999044707, Val Loss: 0.10912301864790236\n",
      "Epoch 319/500, Train Loss: 0.09720387233375982, Val Loss: 0.10875006774883104\n",
      "Epoch 320/500, Train Loss: 0.09814804346295354, Val Loss: 0.10972748040487884\n",
      "Epoch 321/500, Train Loss: 0.09717548503741114, Val Loss: 0.10873882050062612\n",
      "Epoch 322/500, Train Loss: 0.09715011373936175, Val Loss: 0.10866363218352365\n",
      "Epoch 323/500, Train Loss: 0.09740061523056708, Val Loss: 0.10896681114584361\n",
      "Epoch 324/500, Train Loss: 0.09840578750646431, Val Loss: 0.11004027284596665\n",
      "Epoch 325/500, Train Loss: 0.09785331339994519, Val Loss: 0.1094309736145903\n",
      "Epoch 326/500, Train Loss: 0.09705612678194642, Val Loss: 0.10856651467462752\n",
      "Epoch 327/500, Train Loss: 0.0975391784445414, Val Loss: 0.1090825369597359\n",
      "Epoch 328/500, Train Loss: 0.09755499941083859, Val Loss: 0.10908731095401601\n",
      "Epoch 329/500, Train Loss: 0.09739838848508961, Val Loss: 0.10892201898665797\n",
      "Epoch 330/500, Train Loss: 0.09729286980838774, Val Loss: 0.10882160726281623\n",
      "Epoch 331/500, Train Loss: 0.09718558923729828, Val Loss: 0.10871045451955397\n",
      "Epoch 332/500, Train Loss: 0.09733930434191233, Val Loss: 0.10887988447303171\n",
      "Epoch 333/500, Train Loss: 0.09792021432588026, Val Loss: 0.10951085098275605\n",
      "Epoch 334/500, Train Loss: 0.09841222578911328, Val Loss: 0.11003440886436146\n",
      "Epoch 335/500, Train Loss: 0.09793860597053257, Val Loss: 0.10954060691495104\n",
      "Epoch 336/500, Train Loss: 0.09756049643437761, Val Loss: 0.10911916150806028\n",
      "Epoch 337/500, Train Loss: 0.09746073979406035, Val Loss: 0.10901036161059695\n",
      "Epoch 338/500, Train Loss: 0.09694908204277634, Val Loss: 0.10846199044694367\n",
      "Epoch 339/500, Train Loss: 0.09770835653929803, Val Loss: 0.10926127247991226\n",
      "Epoch 340/500, Train Loss: 0.09804159771049072, Val Loss: 0.10961071700661058\n",
      "Epoch 341/500, Train Loss: 0.0975920755278002, Val Loss: 0.10914050084409073\n",
      "Epoch 342/500, Train Loss: 0.09774034231690648, Val Loss: 0.10928706202810246\n",
      "Epoch 343/500, Train Loss: 0.09845999626283193, Val Loss: 0.11005252767493029\n",
      "Epoch 344/500, Train Loss: 0.09786015891786815, Val Loss: 0.10942991327179664\n",
      "Epoch 345/500, Train Loss: 0.09783702312933769, Val Loss: 0.10938740093678524\n",
      "Epoch 346/500, Train Loss: 0.09743237001506767, Val Loss: 0.10895688485561222\n",
      "Epoch 347/500, Train Loss: 0.09731595845850832, Val Loss: 0.10882976211032952\n",
      "Epoch 348/500, Train Loss: 0.09689648509228413, Val Loss: 0.1083538397992818\n",
      "Epoch 349/500, Train Loss: 0.09733407327976103, Val Loss: 0.10882364306466565\n",
      "Epoch 350/500, Train Loss: 0.09756136529806128, Val Loss: 0.10905828422687165\n",
      "Epoch 351/500, Train Loss: 0.09760422263966859, Val Loss: 0.10909989157254012\n",
      "Epoch 352/500, Train Loss: 0.09744391577269425, Val Loss: 0.10893036513610996\n",
      "Epoch 353/500, Train Loss: 0.09728447727085035, Val Loss: 0.10875436189200809\n",
      "Epoch 354/500, Train Loss: 0.09644423130131832, Val Loss: 0.10782686663234708\n",
      "Epoch 355/500, Train Loss: 0.09674828350604375, Val Loss: 0.10815592457497615\n",
      "Epoch 356/500, Train Loss: 0.09730412796897815, Val Loss: 0.10875208405092077\n",
      "Epoch 357/500, Train Loss: 0.09758556454794162, Val Loss: 0.10906295423641406\n",
      "Epoch 358/500, Train Loss: 0.09730753520188416, Val Loss: 0.10874712544493943\n",
      "Epoch 359/500, Train Loss: 0.09712888144065004, Val Loss: 0.10855178231131739\n",
      "Epoch 360/500, Train Loss: 0.09715189440679838, Val Loss: 0.1085835835287855\n",
      "Epoch 361/500, Train Loss: 0.09702333424926256, Val Loss: 0.1084414297322342\n",
      "Epoch 362/500, Train Loss: 0.09739758654540116, Val Loss: 0.10885639728760285\n",
      "Epoch 363/500, Train Loss: 0.09725615670626774, Val Loss: 0.10869130872457618\n",
      "Epoch 364/500, Train Loss: 0.09765887960830902, Val Loss: 0.10913349792794676\n",
      "Epoch 365/500, Train Loss: 0.09750844839943217, Val Loss: 0.10897351467756737\n",
      "Epoch 366/500, Train Loss: 0.09719622336333082, Val Loss: 0.10861713756882864\n",
      "Epoch 367/500, Train Loss: 0.0971319578420615, Val Loss: 0.10854201967441339\n",
      "Epoch 368/500, Train Loss: 0.09717288811168526, Val Loss: 0.10858022817984997\n",
      "Epoch 369/500, Train Loss: 0.09726434848598585, Val Loss: 0.10867316864694068\n",
      "Epoch 370/500, Train Loss: 0.09761824151024673, Val Loss: 0.10905565139704208\n",
      "Epoch 371/500, Train Loss: 0.09738312594472495, Val Loss: 0.10879036243618109\n",
      "Epoch 372/500, Train Loss: 0.09763536500180119, Val Loss: 0.10907190202167369\n",
      "Epoch 373/500, Train Loss: 0.09736689851051956, Val Loss: 0.10876400041159659\n",
      "Epoch 374/500, Train Loss: 0.09734002509412741, Val Loss: 0.10872143221540558\n",
      "Epoch 375/500, Train Loss: 0.09721682353695087, Val Loss: 0.1085778214594654\n",
      "Epoch 376/500, Train Loss: 0.0972522876933173, Val Loss: 0.10862237739449078\n",
      "Epoch 377/500, Train Loss: 0.09720504703057145, Val Loss: 0.10856237922725777\n",
      "Epoch 378/500, Train Loss: 0.09775662044392117, Val Loss: 0.10917882430956638\n",
      "Epoch 379/500, Train Loss: 0.09747300555230534, Val Loss: 0.10887167192485814\n",
      "Epoch 380/500, Train Loss: 0.09730406492795275, Val Loss: 0.10867703029325754\n",
      "Epoch 381/500, Train Loss: 0.09745338278409994, Val Loss: 0.10883288095062431\n",
      "Epoch 382/500, Train Loss: 0.09732491257713285, Val Loss: 0.10869100539043912\n",
      "Epoch 383/500, Train Loss: 0.09725117158065646, Val Loss: 0.10861332566812194\n",
      "Epoch 384/500, Train Loss: 0.09714398890732942, Val Loss: 0.1084825065887098\n",
      "Epoch 385/500, Train Loss: 0.096720098563545, Val Loss: 0.10799661368284466\n",
      "Epoch 386/500, Train Loss: 0.0973004328415021, Val Loss: 0.10867368765884439\n",
      "Epoch 387/500, Train Loss: 0.09755111684502388, Val Loss: 0.1089428694994232\n",
      "Epoch 388/500, Train Loss: 0.09723220820591533, Val Loss: 0.10858191548352635\n",
      "Epoch 389/500, Train Loss: 0.09693483460889625, Val Loss: 0.10824724563902938\n",
      "Epoch 390/500, Train Loss: 0.09763883220470185, Val Loss: 0.10904265909002421\n",
      "Epoch 391/500, Train Loss: 0.09763982367177873, Val Loss: 0.10904465022275164\n",
      "Epoch 392/500, Train Loss: 0.09699544724861775, Val Loss: 0.10830702664051847\n",
      "Epoch 393/500, Train Loss: 0.09740798771227839, Val Loss: 0.10878275629280731\n",
      "Epoch 394/500, Train Loss: 0.09752003144113824, Val Loss: 0.10888179665213063\n",
      "Epoch 395/500, Train Loss: 0.09679555218172238, Val Loss: 0.10806865955390943\n",
      "Epoch 396/500, Train Loss: 0.09692940726134468, Val Loss: 0.10822930208580024\n",
      "Epoch 397/500, Train Loss: 0.09729154747250877, Val Loss: 0.1086354134176476\n",
      "Epoch 398/500, Train Loss: 0.09763644238586186, Val Loss: 0.10902829545797696\n",
      "Epoch 399/500, Train Loss: 0.0969985568295779, Val Loss: 0.10830434590796731\n",
      "Epoch 400/500, Train Loss: 0.09720750698902551, Val Loss: 0.1085561332676374\n",
      "Epoch 401/500, Train Loss: 0.09658585856255124, Val Loss: 0.10784564162917515\n",
      "Epoch 402/500, Train Loss: 0.09691901870505895, Val Loss: 0.108232575760952\n",
      "Epoch 403/500, Train Loss: 0.09718155738486484, Val Loss: 0.10851504665788385\n",
      "Epoch 404/500, Train Loss: 0.0968179135392284, Val Loss: 0.10810286392978502\n",
      "Epoch 405/500, Train Loss: 0.09752460947035217, Val Loss: 0.10890383635973758\n",
      "Epoch 406/500, Train Loss: 0.09706620782927257, Val Loss: 0.1083915782696939\n",
      "Epoch 407/500, Train Loss: 0.09881402440082904, Val Loss: 0.11032621567942767\n",
      "Epoch 408/500, Train Loss: 0.09676671828442647, Val Loss: 0.10805177556240185\n",
      "Epoch 409/500, Train Loss: 0.0973052747376347, Val Loss: 0.10866041277009256\n",
      "Epoch 410/500, Train Loss: 0.09757977008127881, Val Loss: 0.10895411649931322\n",
      "Epoch 411/500, Train Loss: 0.09772903713908493, Val Loss: 0.10913055351671912\n",
      "Epoch 412/500, Train Loss: 0.0976689818838621, Val Loss: 0.10906460362599037\n",
      "Epoch 413/500, Train Loss: 0.09699819033082697, Val Loss: 0.10830218456243564\n",
      "Epoch 414/500, Train Loss: 0.09711727857134292, Val Loss: 0.10841483185352692\n",
      "Epoch 415/500, Train Loss: 0.09715266782334284, Val Loss: 0.10847650795142695\n",
      "Epoch 416/500, Train Loss: 0.096963176881863, Val Loss: 0.1082728389405914\n",
      "Epoch 417/500, Train Loss: 0.09688805602923271, Val Loss: 0.10819519489052715\n",
      "Epoch 418/500, Train Loss: 0.09704455853179152, Val Loss: 0.10836680701141185\n",
      "Epoch 419/500, Train Loss: 0.09713941365061907, Val Loss: 0.10844988552202857\n",
      "Epoch 420/500, Train Loss: 0.09754852072940805, Val Loss: 0.10891260130317643\n",
      "Epoch 421/500, Train Loss: 0.09800449568307985, Val Loss: 0.10942289025896206\n",
      "Epoch 422/500, Train Loss: 0.09743269437952033, Val Loss: 0.10877759426889931\n",
      "Epoch 423/500, Train Loss: 0.09700143640627532, Val Loss: 0.1082879132445572\n",
      "Epoch 424/500, Train Loss: 0.09661481074326338, Val Loss: 0.10787623440038223\n",
      "Epoch 425/500, Train Loss: 0.09698633499771754, Val Loss: 0.10830505151172558\n",
      "Epoch 426/500, Train Loss: 0.09700933713883486, Val Loss: 0.10831692478027881\n",
      "Epoch 427/500, Train Loss: 0.09808406595089016, Val Loss: 0.10951025952061225\n",
      "Epoch 428/500, Train Loss: 0.09773078277757281, Val Loss: 0.10912171792542648\n",
      "Epoch 429/500, Train Loss: 0.09736335999745548, Val Loss: 0.10870835346880506\n",
      "Epoch 430/500, Train Loss: 0.09770985894191454, Val Loss: 0.1090833203631329\n",
      "Epoch 431/500, Train Loss: 0.09810043748010798, Val Loss: 0.10953036743918376\n",
      "Epoch 432/500, Train Loss: 0.09782036992742495, Val Loss: 0.10922082533572511\n",
      "Epoch 433/500, Train Loss: 0.09821802664330168, Val Loss: 0.10964870829175576\n",
      "Epoch 434/500, Train Loss: 0.09682203616506666, Val Loss: 0.10807752469067979\n",
      "Epoch 435/500, Train Loss: 0.09706898288427594, Val Loss: 0.10835966649005004\n",
      "Epoch 436/500, Train Loss: 0.09835422002762108, Val Loss: 0.10981140918254155\n",
      "Epoch 437/500, Train Loss: 0.09664375468858502, Val Loss: 0.10788422923426562\n",
      "Epoch 438/500, Train Loss: 0.09683374429218995, Val Loss: 0.10810857832579684\n",
      "Epoch 439/500, Train Loss: 0.09714469560940511, Val Loss: 0.1084570396353373\n",
      "Epoch 440/500, Train Loss: 0.09716603638851001, Val Loss: 0.10849393718017762\n",
      "Epoch 441/500, Train Loss: 0.09676501365488549, Val Loss: 0.10802436076327686\n",
      "Epoch 442/500, Train Loss: 0.09748461103602303, Val Loss: 0.10883538821016023\n",
      "Epoch 443/500, Train Loss: 0.09654234017925561, Val Loss: 0.10777582985026686\n",
      "Epoch 444/500, Train Loss: 0.0974066994468612, Val Loss: 0.10875101326330337\n",
      "Epoch 445/500, Train Loss: 0.0970291351407975, Val Loss: 0.10830368465505563\n",
      "Epoch 446/500, Train Loss: 0.09760334572974656, Val Loss: 0.10896645348775287\n",
      "Epoch 447/500, Train Loss: 0.09769478981774025, Val Loss: 0.10907312408384334\n",
      "Epoch 448/500, Train Loss: 0.09698205483968182, Val Loss: 0.10827421049715853\n",
      "Epoch 449/500, Train Loss: 0.09762236197816987, Val Loss: 0.10899849306136102\n",
      "Epoch 450/500, Train Loss: 0.0972619275199472, Val Loss: 0.10859390893080224\n",
      "Epoch 451/500, Train Loss: 0.09783884566178117, Val Loss: 0.109242985391645\n",
      "Epoch 452/500, Train Loss: 0.09722438139239684, Val Loss: 0.10855865789829973\n",
      "Epoch 453/500, Train Loss: 0.09679075021078075, Val Loss: 0.10804765518227905\n",
      "Epoch 454/500, Train Loss: 0.09705445016278262, Val Loss: 0.10834823472696624\n",
      "Epoch 455/500, Train Loss: 0.09769318644347567, Val Loss: 0.10905719704200395\n",
      "Epoch 456/500, Train Loss: 0.09705557830501255, Val Loss: 0.10832637326566623\n",
      "Epoch 457/500, Train Loss: 0.09771517525504463, Val Loss: 0.1090902693939866\n",
      "Epoch 458/500, Train Loss: 0.09746397227573828, Val Loss: 0.10880659067474532\n",
      "Epoch 459/500, Train Loss: 0.09771335676739663, Val Loss: 0.10909250767807453\n",
      "Epoch 460/500, Train Loss: 0.09671376876240265, Val Loss: 0.10795591587643479\n",
      "Epoch 461/500, Train Loss: 0.09711074268718248, Val Loss: 0.10840656289548065\n",
      "Epoch 462/500, Train Loss: 0.09659452037247929, Val Loss: 0.10779800971753058\n",
      "Epoch 463/500, Train Loss: 0.09760936250470133, Val Loss: 0.10896730652612191\n",
      "Epoch 464/500, Train Loss: 0.09725902185687207, Val Loss: 0.10855485465843623\n",
      "Epoch 465/500, Train Loss: 0.09744235788439295, Val Loss: 0.10877362587140245\n",
      "Epoch 466/500, Train Loss: 0.09739202099736638, Val Loss: 0.10874022695605198\n",
      "Epoch 467/500, Train Loss: 0.09750413670689265, Val Loss: 0.10884249008058428\n",
      "Epoch 468/500, Train Loss: 0.09730422306670093, Val Loss: 0.10862133800837397\n",
      "Epoch 469/500, Train Loss: 0.09763621386057576, Val Loss: 0.10900776291257841\n",
      "Epoch 470/500, Train Loss: 0.09741167846076854, Val Loss: 0.1087301023311523\n",
      "Epoch 471/500, Train Loss: 0.09671410718998677, Val Loss: 0.1079482020598015\n",
      "Epoch 472/500, Train Loss: 0.09742803797799614, Val Loss: 0.10874192612732818\n",
      "Epoch 473/500, Train Loss: 0.09747654234651565, Val Loss: 0.10881889068114797\n",
      "Epoch 474/500, Train Loss: 0.09662064629169792, Val Loss: 0.10782024325495364\n",
      "Epoch 475/500, Train Loss: 0.09697402454107987, Val Loss: 0.10824548547848567\n",
      "Epoch 476/500, Train Loss: 0.09741534201416296, Val Loss: 0.1087451859555371\n",
      "Epoch 477/500, Train Loss: 0.09659600768739178, Val Loss: 0.10779614784029871\n",
      "Epoch 478/500, Train Loss: 0.09729395868545594, Val Loss: 0.10859303670439241\n",
      "Epoch 479/500, Train Loss: 0.09774890813481818, Val Loss: 0.10911763664402983\n",
      "Epoch 480/500, Train Loss: 0.09701136865081375, Val Loss: 0.10828414108108456\n",
      "Epoch 481/500, Train Loss: 0.09792846833853457, Val Loss: 0.10931121496548432\n",
      "Epoch 482/500, Train Loss: 0.09720269443518922, Val Loss: 0.10846554572835608\n",
      "Epoch 483/500, Train Loss: 0.09685953451247946, Val Loss: 0.10809200500026087\n",
      "Epoch 484/500, Train Loss: 0.09680800280109446, Val Loss: 0.10803958605454278\n",
      "Epoch 485/500, Train Loss: 0.09725088450036655, Val Loss: 0.10856551990161259\n",
      "Epoch 486/500, Train Loss: 0.09754791986257805, Val Loss: 0.10891126711440469\n",
      "Epoch 487/500, Train Loss: 0.09746641914081292, Val Loss: 0.10882673646424369\n",
      "Epoch 488/500, Train Loss: 0.09722903662471116, Val Loss: 0.10856997359954271\n",
      "Epoch 489/500, Train Loss: 0.09725225431142968, Val Loss: 0.10856907751442377\n",
      "Epoch 490/500, Train Loss: 0.09680522426124143, Val Loss: 0.10804410254042027\n",
      "Epoch 491/500, Train Loss: 0.09688279119165567, Val Loss: 0.10815701641528162\n",
      "Epoch 492/500, Train Loss: 0.09673676787917816, Val Loss: 0.10793766639460381\n",
      "Epoch 493/500, Train Loss: 0.09793456988595528, Val Loss: 0.10933155198929492\n",
      "Epoch 494/500, Train Loss: 0.09709501527763463, Val Loss: 0.1083882933852127\n",
      "Epoch 495/500, Train Loss: 0.09689362380652883, Val Loss: 0.10815355871162799\n",
      "Epoch 496/500, Train Loss: 0.09712815650012181, Val Loss: 0.10843814681871343\n",
      "Epoch 497/500, Train Loss: 0.09729596866952099, Val Loss: 0.10860059548674593\n",
      "Epoch 498/500, Train Loss: 0.0974332961067929, Val Loss: 0.10876385306264177\n",
      "Epoch 499/500, Train Loss: 0.09684653024282755, Val Loss: 0.10809889186672125\n",
      "Epoch 500/500, Train Loss: 0.09743551214008088, Val Loss: 0.10875971720074555\n",
      "Returning from fit...\n",
      "Train Losses: [np.float64(0.04939193985859111), np.float64(0.049410725508206174), np.float64(0.049433051168153545), np.float64(0.04978646919051701), np.float64(0.04942041298008662), np.float64(0.04936383338918035), np.float64(0.049387085990711704), np.float64(0.049556186650544606), np.float64(0.049547661219267104), np.float64(0.049517129767610794), np.float64(0.04936159694050902), np.float64(0.049393907054702854), np.float64(0.04942847344465054), np.float64(0.049702541997494326), np.float64(0.04938270183597842), np.float64(0.04939437142926159), np.float64(0.04935497089403027), np.float64(0.04941575440026974), np.float64(0.04942539905288476), np.float64(0.049684733401937915), np.float64(0.049364824043761836), np.float64(0.049393735215316835), np.float64(0.0493683386282092), np.float64(0.049357862574973384), np.float64(0.049895981794284554), np.float64(0.04943915815596945), np.float64(0.049366213964911566), np.float64(0.04942392433131224), np.float64(0.04956877011498978), np.float64(0.049368516887964634), np.float64(0.04968690279679418), np.float64(0.049445405744310784), np.float64(0.049355979928913184), np.float64(0.04938171771329966), np.float64(0.04948178914149806), np.float64(0.049460368973240076), np.float64(0.049354905154285485), np.float64(0.0493574377104459), np.float64(0.0493567151498295), np.float64(0.049355502095486184), np.float64(0.04959253765998342), np.float64(0.04991215086373523), np.float64(0.049443026388148834), np.float64(0.04937538593678637), np.float64(0.0493626366451446), np.float64(0.049377095187968144), np.float64(0.04944298379465829), np.float64(0.049602819095522534), np.float64(0.049368096448702575), np.float64(0.049368056079672706), np.float64(0.05079806759823551), np.float64(0.04942859182749091), np.float64(0.049421513756769286), np.float64(0.04939639177972836), np.float64(0.049413084525927894), np.float64(0.0493597782895154), np.float64(0.04952581451664004), np.float64(0.04950740895045325), np.float64(0.04944048212641173), np.float64(0.049550908514509294), np.float64(0.049360265361631), np.float64(0.04962736740801974), np.float64(0.04992488202911656), np.float64(0.04937177618728575), np.float64(0.049373987229370926), np.float64(0.04942561467140407), np.float64(0.049422977212816764), np.float64(0.04964756490629176), np.float64(0.050019578641496566), np.float64(0.05187157094840203), np.float64(0.05844599621041374), np.float64(0.07110388812977812), np.float64(0.08410707653426058), np.float64(0.08952544701265257), np.float64(0.09348270387164793), np.float64(0.09359177718734961), np.float64(0.09458717110396782), np.float64(0.09466928859995585), np.float64(0.09524679874474457), np.float64(0.09563767583937084), np.float64(0.09606192032978302), np.float64(0.09528894501086535), np.float64(0.09599406651008895), np.float64(0.09601142693943396), np.float64(0.09719224745357417), np.float64(0.09584066141938), np.float64(0.09710710153547844), np.float64(0.09626466805747948), np.float64(0.0964279538514238), np.float64(0.0961688378009794), np.float64(0.09660120870281474), np.float64(0.09694583464554536), np.float64(0.09616007826219156), np.float64(0.09587488462457128), np.float64(0.09658282943978065), np.float64(0.09769049861184297), np.float64(0.0973776494320981), np.float64(0.09692407672833322), np.float64(0.09609565368356264), np.float64(0.09749179903058199), np.float64(0.09604987482214007), np.float64(0.09722583051337223), np.float64(0.09796639228623441), np.float64(0.09689505131252872), np.float64(0.09693166029869418), np.float64(0.09586930500637848), np.float64(0.09735689932771972), np.float64(0.0967537003599974), np.float64(0.09644122451338841), np.float64(0.09751518041324111), np.float64(0.09700999307955314), np.float64(0.09747321365280054), np.float64(0.09672767397681092), np.float64(0.09728541141434965), np.float64(0.097047674336584), np.float64(0.09700476380067856), np.float64(0.09666830410708695), np.float64(0.09744735198130355), np.float64(0.09680131356050117), np.float64(0.09702906062337278), np.float64(0.09780106798999039), np.float64(0.09707873305498885), np.float64(0.09769966195613947), np.float64(0.09720759057124345), np.float64(0.09702258045069626), np.float64(0.09698497976716784), np.float64(0.09682023688721271), np.float64(0.09692231135368785), np.float64(0.09659016050211794), np.float64(0.09724568258698746), np.float64(0.09690078761238138), np.float64(0.09658462667985587), np.float64(0.09698854516936325), np.float64(0.09728516483056815), np.float64(0.09670488447629542), np.float64(0.09741111126362938), np.float64(0.09755550931063613), np.float64(0.09686093941290358), np.float64(0.09642743484051454), np.float64(0.09655421368927553), np.float64(0.09688092780657823), np.float64(0.09754747494632801), np.float64(0.09753171423330141), np.float64(0.09699306603661263), np.float64(0.09709981074993665), np.float64(0.09619809994353937), np.float64(0.09798074196021539), np.float64(0.0969159148959214), np.float64(0.09641606665866882), np.float64(0.09763312932213526), np.float64(0.09680266073983673), np.float64(0.09662727839272554), np.float64(0.09739453348866213), np.float64(0.09804398668700537), np.float64(0.09753274177723639), np.float64(0.09782232294302488), np.float64(0.09718063954526146), np.float64(0.09680148823112768), np.float64(0.09738642978332882), np.float64(0.09674158710173861), np.float64(0.0975882725807304), np.float64(0.0966739674271955), np.float64(0.09763146099974504), np.float64(0.0963487754728622), np.float64(0.09776575729696811), np.float64(0.09704605795733345), np.float64(0.09744901894240283), np.float64(0.09714819968627955), np.float64(0.09664190951084169), np.float64(0.09712558083179584), np.float64(0.09772452471309152), np.float64(0.09741834515876566), np.float64(0.09796216628358628), np.float64(0.09680054740280815), np.float64(0.09729044442701432), np.float64(0.097204989424296), np.float64(0.09728746742931901), np.float64(0.09669314862158741), np.float64(0.09681681349050204), np.float64(0.0968314111528787), np.float64(0.09722632948405295), np.float64(0.09724778945503935), np.float64(0.09651642922064627), np.float64(0.0969419727136456), np.float64(0.09696650976399454), np.float64(0.09696885897342274), np.float64(0.09769137871609461), np.float64(0.09744483948299468), np.float64(0.096583062970674), np.float64(0.0972592248466905), np.float64(0.09763242209747093), np.float64(0.0974120766948101), np.float64(0.09767125020030769), np.float64(0.09712693688226912), np.float64(0.09736497804967273), np.float64(0.09669412584847564), np.float64(0.0971346177135522), np.float64(0.09752442348615821), np.float64(0.09707513947119625), np.float64(0.09731500727677296), np.float64(0.09824463350601341), np.float64(0.09702956655788768), np.float64(0.09702544005985074), np.float64(0.09746992927996147), np.float64(0.09679863698866971), np.float64(0.097197609692073), np.float64(0.09725737669429348), np.float64(0.09718921675655567), np.float64(0.09792743567603424), np.float64(0.09743671247552067), np.float64(0.0980248245907133), np.float64(0.09782323248457508), np.float64(0.09697158312338554), np.float64(0.09729974809566137), np.float64(0.09654920070189074), np.float64(0.0970022429232431), np.float64(0.0972597054286583), np.float64(0.09668052381706245), np.float64(0.0972678774337782), np.float64(0.09704649427544831), np.float64(0.09688861573190045), np.float64(0.0967095878953065), np.float64(0.0969323874926253), np.float64(0.09763603473658977), np.float64(0.09729694282709568), np.float64(0.09793439951866093), np.float64(0.09672036300230161), np.float64(0.09676029873000333), np.float64(0.09692539004711026), np.float64(0.09690793654436723), np.float64(0.09764958403490905), np.float64(0.0972381737013531), np.float64(0.09593443454645463), np.float64(0.09666085243769768), np.float64(0.09687604624714778), np.float64(0.09798334917412223), np.float64(0.09689039352129201), np.float64(0.09678653968473094), np.float64(0.09712022256812376), np.float64(0.09678274160159708), np.float64(0.09744456547790559), np.float64(0.09747083935908765), np.float64(0.0976601494309933), np.float64(0.09692692641438555), np.float64(0.09828565652254903), np.float64(0.09738466153832376), np.float64(0.09697867520530716), np.float64(0.09728778187291563), np.float64(0.09765535787647489), np.float64(0.09778426409800713), np.float64(0.09758357313096186), np.float64(0.09723164765299393), np.float64(0.09696630158660141), np.float64(0.0971604861386858), np.float64(0.09717214198078505), np.float64(0.09737053646753083), np.float64(0.09724018110848531), np.float64(0.09749749915177003), np.float64(0.09745822301458473), np.float64(0.0972181751288079), np.float64(0.09709608712144548), np.float64(0.09740580135503586), np.float64(0.0974632077832476), np.float64(0.09642035374599388), np.float64(0.09723769940258706), np.float64(0.09711942597247893), np.float64(0.09724014062875598), np.float64(0.09799635746056959), np.float64(0.0969706450077314), np.float64(0.09757146280255896), np.float64(0.09713978104756935), np.float64(0.09757542548122994), np.float64(0.09698011656934097), np.float64(0.09706087546783587), np.float64(0.09730572860776084), np.float64(0.09699891065127444), np.float64(0.09733134293892513), np.float64(0.09687002455237913), np.float64(0.09693329214081471), np.float64(0.09765263358245066), np.float64(0.0979312069619721), np.float64(0.09775376942867453), np.float64(0.09794883945172256), np.float64(0.09750187337636501), np.float64(0.09735605389491674), np.float64(0.09701746969616386), np.float64(0.09677338334063107), np.float64(0.09751387289767488), np.float64(0.09706965999334898), np.float64(0.09727325140553632), np.float64(0.09743955935240604), np.float64(0.09730235313424801), np.float64(0.09673395730603541), np.float64(0.09780791886410072), np.float64(0.09700305744813514), np.float64(0.09702703761213596), np.float64(0.09622807710192129), np.float64(0.09691482822010818), np.float64(0.09739803926942406), np.float64(0.09827414870735371), np.float64(0.09655900870869333), np.float64(0.09743558533906647), np.float64(0.09797608876398628), np.float64(0.09749274135970872), np.float64(0.09785168949044501), np.float64(0.0974473490731445), np.float64(0.09668849146897429), np.float64(0.09743490183584695), np.float64(0.09816060272860272), np.float64(0.0970101094887689), np.float64(0.09638169051346121), np.float64(0.09706516524292788), np.float64(0.09698968248104645), np.float64(0.09731190133422013), np.float64(0.0968031997691575), np.float64(0.09737790637048233), np.float64(0.09748476830169583), np.float64(0.09754020999044707), np.float64(0.09720387233375982), np.float64(0.09814804346295354), np.float64(0.09717548503741114), np.float64(0.09715011373936175), np.float64(0.09740061523056708), np.float64(0.09840578750646431), np.float64(0.09785331339994519), np.float64(0.09705612678194642), np.float64(0.0975391784445414), np.float64(0.09755499941083859), np.float64(0.09739838848508961), np.float64(0.09729286980838774), np.float64(0.09718558923729828), np.float64(0.09733930434191233), np.float64(0.09792021432588026), np.float64(0.09841222578911328), np.float64(0.09793860597053257), np.float64(0.09756049643437761), np.float64(0.09746073979406035), np.float64(0.09694908204277634), np.float64(0.09770835653929803), np.float64(0.09804159771049072), np.float64(0.0975920755278002), np.float64(0.09774034231690648), np.float64(0.09845999626283193), np.float64(0.09786015891786815), np.float64(0.09783702312933769), np.float64(0.09743237001506767), np.float64(0.09731595845850832), np.float64(0.09689648509228413), np.float64(0.09733407327976103), np.float64(0.09756136529806128), np.float64(0.09760422263966859), np.float64(0.09744391577269425), np.float64(0.09728447727085035), np.float64(0.09644423130131832), np.float64(0.09674828350604375), np.float64(0.09730412796897815), np.float64(0.09758556454794162), np.float64(0.09730753520188416), np.float64(0.09712888144065004), np.float64(0.09715189440679838), np.float64(0.09702333424926256), np.float64(0.09739758654540116), np.float64(0.09725615670626774), np.float64(0.09765887960830902), np.float64(0.09750844839943217), np.float64(0.09719622336333082), np.float64(0.0971319578420615), np.float64(0.09717288811168526), np.float64(0.09726434848598585), np.float64(0.09761824151024673), np.float64(0.09738312594472495), np.float64(0.09763536500180119), np.float64(0.09736689851051956), np.float64(0.09734002509412741), np.float64(0.09721682353695087), np.float64(0.0972522876933173), np.float64(0.09720504703057145), np.float64(0.09775662044392117), np.float64(0.09747300555230534), np.float64(0.09730406492795275), np.float64(0.09745338278409994), np.float64(0.09732491257713285), np.float64(0.09725117158065646), np.float64(0.09714398890732942), np.float64(0.096720098563545), np.float64(0.0973004328415021), np.float64(0.09755111684502388), np.float64(0.09723220820591533), np.float64(0.09693483460889625), np.float64(0.09763883220470185), np.float64(0.09763982367177873), np.float64(0.09699544724861775), np.float64(0.09740798771227839), np.float64(0.09752003144113824), np.float64(0.09679555218172238), np.float64(0.09692940726134468), np.float64(0.09729154747250877), np.float64(0.09763644238586186), np.float64(0.0969985568295779), np.float64(0.09720750698902551), np.float64(0.09658585856255124), np.float64(0.09691901870505895), np.float64(0.09718155738486484), np.float64(0.0968179135392284), np.float64(0.09752460947035217), np.float64(0.09706620782927257), np.float64(0.09881402440082904), np.float64(0.09676671828442647), np.float64(0.0973052747376347), np.float64(0.09757977008127881), np.float64(0.09772903713908493), np.float64(0.0976689818838621), np.float64(0.09699819033082697), np.float64(0.09711727857134292), np.float64(0.09715266782334284), np.float64(0.096963176881863), np.float64(0.09688805602923271), np.float64(0.09704455853179152), np.float64(0.09713941365061907), np.float64(0.09754852072940805), np.float64(0.09800449568307985), np.float64(0.09743269437952033), np.float64(0.09700143640627532), np.float64(0.09661481074326338), np.float64(0.09698633499771754), np.float64(0.09700933713883486), np.float64(0.09808406595089016), np.float64(0.09773078277757281), np.float64(0.09736335999745548), np.float64(0.09770985894191454), np.float64(0.09810043748010798), np.float64(0.09782036992742495), np.float64(0.09821802664330168), np.float64(0.09682203616506666), np.float64(0.09706898288427594), np.float64(0.09835422002762108), np.float64(0.09664375468858502), np.float64(0.09683374429218995), np.float64(0.09714469560940511), np.float64(0.09716603638851001), np.float64(0.09676501365488549), np.float64(0.09748461103602303), np.float64(0.09654234017925561), np.float64(0.0974066994468612), np.float64(0.0970291351407975), np.float64(0.09760334572974656), np.float64(0.09769478981774025), np.float64(0.09698205483968182), np.float64(0.09762236197816987), np.float64(0.0972619275199472), np.float64(0.09783884566178117), np.float64(0.09722438139239684), np.float64(0.09679075021078075), np.float64(0.09705445016278262), np.float64(0.09769318644347567), np.float64(0.09705557830501255), np.float64(0.09771517525504463), np.float64(0.09746397227573828), np.float64(0.09771335676739663), np.float64(0.09671376876240265), np.float64(0.09711074268718248), np.float64(0.09659452037247929), np.float64(0.09760936250470133), np.float64(0.09725902185687207), np.float64(0.09744235788439295), np.float64(0.09739202099736638), np.float64(0.09750413670689265), np.float64(0.09730422306670093), np.float64(0.09763621386057576), np.float64(0.09741167846076854), np.float64(0.09671410718998677), np.float64(0.09742803797799614), np.float64(0.09747654234651565), np.float64(0.09662064629169792), np.float64(0.09697402454107987), np.float64(0.09741534201416296), np.float64(0.09659600768739178), np.float64(0.09729395868545594), np.float64(0.09774890813481818), np.float64(0.09701136865081375), np.float64(0.09792846833853457), np.float64(0.09720269443518922), np.float64(0.09685953451247946), np.float64(0.09680800280109446), np.float64(0.09725088450036655), np.float64(0.09754791986257805), np.float64(0.09746641914081292), np.float64(0.09722903662471116), np.float64(0.09725225431142968), np.float64(0.09680522426124143), np.float64(0.09688279119165567), np.float64(0.09673676787917816), np.float64(0.09793456988595528), np.float64(0.09709501527763463), np.float64(0.09689362380652883), np.float64(0.09712815650012181), np.float64(0.09729596866952099), np.float64(0.0974332961067929), np.float64(0.09684653024282755), np.float64(0.09743551214008088)]\n",
      "Validation Losses: [np.float64(0.05654649462569563), np.float64(0.05719378710129309), np.float64(0.05646011189569566), np.float64(0.05626086227165081), np.float64(0.05723227182179832), np.float64(0.05693958458213941), np.float64(0.05656072667685992), np.float64(0.05633563172176607), np.float64(0.057627599639829385), np.float64(0.0575439524005731), np.float64(0.056918848701390135), np.float64(0.05654105918021174), np.float64(0.05646768638203279), np.float64(0.05800296887593099), np.float64(0.05706396592856512), np.float64(0.056539801458792095), np.float64(0.056774010550639825), np.float64(0.05649090888125247), np.float64(0.05647298728149217), np.float64(0.05628013642344472), np.float64(0.05665505712138019), np.float64(0.05654150484684624), np.float64(0.056634759712236485), np.float64(0.056875261658648715), np.float64(0.05841012606396241), np.float64(0.05730117257071395), np.float64(0.05695918435668786), np.float64(0.05647557598334606), np.float64(0.057682885687505535), np.float64(0.05697654072110623), np.float64(0.057967552038299584), np.float64(0.05644123870674566), np.float64(0.056742850946084264), np.float64(0.0565781561613573), np.float64(0.05744024387620311), np.float64(0.05642116033050037), np.float64(0.056778500525997), np.float64(0.056868824747232975), np.float64(0.056856885935882326), np.float64(0.05683005440159906), np.float64(0.0577430182296623), np.float64(0.056255388271141044), np.float64(0.056444578455423965), np.float64(0.05702172492477201), np.float64(0.05692835670601643), np.float64(0.05659493996608859), np.float64(0.057313926477966876), np.float64(0.05630996142223918), np.float64(0.05663565968907038), np.float64(0.05697232456266918), np.float64(0.059992272628371215), np.float64(0.057261749927634664), np.float64(0.056479391998322914), np.float64(0.05653376303289695), np.float64(0.05649548166246872), np.float64(0.05689629715706733), np.float64(0.057564361616579164), np.float64(0.05751154111043646), np.float64(0.05644743230030333), np.float64(0.056338339176685376), np.float64(0.05688850629495481), np.float64(0.05629975179039081), np.float64(0.05625908098870898), np.float64(0.05694748712024586), np.float64(0.056668970711699726), np.float64(0.05713176932771544), np.float64(0.05678720853622593), np.float64(0.05658880707092109), np.float64(0.05728811198892405), np.float64(0.059231639274158594), np.float64(0.06615833890703925), np.float64(0.07941759571763939), np.float64(0.09327259595037135), np.float64(0.09923615275737621), np.float64(0.10332737870650424), np.float64(0.10368758445247356), np.float64(0.10473439283164711), np.float64(0.10496967663864697), np.float64(0.10558194059864563), np.float64(0.10604248047311873), np.float64(0.10659874429361695), np.float64(0.10594371211027546), np.float64(0.10672990752649424), np.float64(0.10684726694786689), np.float64(0.10813097917848434), np.float64(0.10685714507581653), np.float64(0.10824532202433891), np.float64(0.10745149606040302), np.float64(0.10775017613329119), np.float64(0.10754076546135158), np.float64(0.10800354023503299), np.float64(0.10845494989127324), np.float64(0.10775212878769783), np.float64(0.10751205115010803), np.float64(0.10828436552119275), np.float64(0.10942318435761188), np.float64(0.10917711168563533), np.float64(0.108758030915401), np.float64(0.1079377571425292), np.float64(0.10937662362859796), np.float64(0.1079177923294147), np.float64(0.10914876239819808), np.float64(0.10994897626162092), np.float64(0.10888865291471662), np.float64(0.10892397640751401), np.float64(0.10789943773166641), np.float64(0.10941393839800764), np.float64(0.10881947910232015), np.float64(0.10851363667563828), np.float64(0.10957825195663394), np.float64(0.10909172172983155), np.float64(0.1095768773051348), np.float64(0.10888987981729141), np.float64(0.10944914300497102), np.float64(0.10917712172868031), np.float64(0.1091497139280133), np.float64(0.10881926543195593), np.float64(0.10962954480376817), np.float64(0.1089875752302437), np.float64(0.10920360548981169), np.float64(0.10998395408615474), np.float64(0.10928535982243315), np.float64(0.10989994916906813), np.float64(0.10939103015532904), np.float64(0.10919710600841138), np.float64(0.1091473776202988), np.float64(0.10896564428219718), np.float64(0.10908930985335877), np.float64(0.10871690476366165), np.float64(0.10940967066002096), np.float64(0.10905548701132695), np.float64(0.10874807424273528), np.float64(0.10912084116429117), np.float64(0.10943930272645944), np.float64(0.10884963352971583), np.float64(0.10957216164580955), np.float64(0.10971304557518881), np.float64(0.10898853602340929), np.float64(0.1085541434914999), np.float64(0.1086660461077936), np.float64(0.10899026460014963), np.float64(0.10968723199011833), np.float64(0.10968614181801518), np.float64(0.10914132700362687), np.float64(0.10920945251431168), np.float64(0.10827268175960392), np.float64(0.11011085950212127), np.float64(0.10903050991685642), np.float64(0.10852269278173422), np.float64(0.10974564593052825), np.float64(0.10888689325115145), np.float64(0.10868983580214618), np.float64(0.10947201771892841), np.float64(0.11014413460422823), np.float64(0.10962211781490633), np.float64(0.10991985063236161), np.float64(0.10926267726173261), np.float64(0.1088537776426061), np.float64(0.10946144522207579), np.float64(0.10875025187500295), np.float64(0.10965369509375311), np.float64(0.1086959520253962), np.float64(0.10970034465567072), np.float64(0.10834972307106959), np.float64(0.10983162393460068), np.float64(0.10908107854718584), np.float64(0.1094951405228738), np.float64(0.10918046671670126), np.float64(0.10864373826387042), np.float64(0.10913151840840404), np.float64(0.10977952249055953), np.float64(0.10945741300754003), np.float64(0.10998990986871882), np.float64(0.10880957232346194), np.float64(0.10930798376177674), np.float64(0.10921275023503427), np.float64(0.10930034005684922), np.float64(0.10867811400148111), np.float64(0.10879976852315687), np.float64(0.10880127951020058), np.float64(0.10920705862619508), np.float64(0.1092311651877106), np.float64(0.10845486589101087), np.float64(0.10889940879387414), np.float64(0.10894096449134487), np.float64(0.1089420208169578), np.float64(0.10968759030790448), np.float64(0.10941818296024336), np.float64(0.10852265047096825), np.float64(0.10923286300226753), np.float64(0.10960798039930193), np.float64(0.1093468348690174), np.float64(0.10962036537221741), np.float64(0.10906610543977184), np.float64(0.10931130907234662), np.float64(0.10863167446860937), np.float64(0.10904471419239245), np.float64(0.10947934259464524), np.float64(0.1090048840527447), np.float64(0.10927140557831576), np.float64(0.1102091110414881), np.float64(0.10895388640359498), np.float64(0.10894349127665222), np.float64(0.10940381817080018), np.float64(0.10871714558104069), np.float64(0.10912912859376704), np.float64(0.10917931593782938), np.float64(0.10907618522740999), np.float64(0.10983597553397415), np.float64(0.10930861069377971), np.float64(0.10993895255000519), np.float64(0.10972192062913676), np.float64(0.1088139414880413), np.float64(0.10914965245029187), np.float64(0.10836624425483754), np.float64(0.10878743443171236), np.float64(0.10910410677550733), np.float64(0.10848194794185341), np.float64(0.10910124435852742), np.float64(0.10886318530724029), np.float64(0.1087197069369411), np.float64(0.10851557156436935), np.float64(0.10873316772142216), np.float64(0.10946166668406399), np.float64(0.10911172126770442), np.float64(0.10977364431210367), np.float64(0.10851786191448605), np.float64(0.1085083438221858), np.float64(0.10870372936611027), np.float64(0.10867675496115714), np.float64(0.10945475885482786), np.float64(0.1090086360201499), np.float64(0.10763923440741849), np.float64(0.10837606672994113), np.float64(0.10860758188784603), np.float64(0.10977367650845661), np.float64(0.10860878924331863), np.float64(0.10850109818009149), np.float64(0.1088383763489436), np.float64(0.10847235232303946), np.float64(0.10915907146062402), np.float64(0.10918849681835605), np.float64(0.1093899059420775), np.float64(0.10862342095666953), np.float64(0.11002414459309097), np.float64(0.10906181644982776), np.float64(0.10866435250683823), np.float64(0.10897367133842352), np.float64(0.10936964943652336), np.float64(0.10953221261177035), np.float64(0.10931532375945009), np.float64(0.10893017133152488), np.float64(0.1086214570228516), np.float64(0.10883213303911228), np.float64(0.10883541344408013), np.float64(0.10905926129022409), np.float64(0.10892224941409547), np.float64(0.10916436879468046), np.float64(0.1091206267278724), np.float64(0.10889404698921981), np.float64(0.10876132738824873), np.float64(0.10907762727487548), np.float64(0.10913776142146647), np.float64(0.10804379056983127), np.float64(0.10891855008795115), np.float64(0.10877785963704488), np.float64(0.10890499522020064), np.float64(0.1096981911383517), np.float64(0.10862023346919289), np.float64(0.1092209854460939), np.float64(0.10875979278147335), np.float64(0.1092352973847858), np.float64(0.10862390176310913), np.float64(0.10870810924122674), np.float64(0.10897003551533935), np.float64(0.10864714677822446), np.float64(0.10896891179997689), np.float64(0.1085149625959245), np.float64(0.10856622440670961), np.float64(0.10930779312720645), np.float64(0.10957328675449576), np.float64(0.10940483253067045), np.float64(0.10959196875530154), np.float64(0.10914224042871132), np.float64(0.10898004230802562), np.float64(0.10863945199300284), np.float64(0.1083763451487292), np.float64(0.10914432610684033), np.float64(0.10869881846536625), np.float64(0.10889470422198225), np.float64(0.10906386666942475), np.float64(0.10892691052675511), np.float64(0.10832632692314938), np.float64(0.10946212368593686), np.float64(0.10861064900657738), np.float64(0.10862810417015234), np.float64(0.10775546697842295), np.float64(0.10849562660868461), np.float64(0.10901802703980236), np.float64(0.1099263897105825), np.float64(0.10811137179691435), np.float64(0.10903518488397988), np.float64(0.10958331985846095), np.float64(0.10909936659630906), np.float64(0.10946283065423326), np.float64(0.10903859486792611), np.float64(0.10823836410643278), np.float64(0.10901068379567479), np.float64(0.10978059846250247), np.float64(0.10858128993605892), np.float64(0.10790179353649254), np.float64(0.10865226776805761), np.float64(0.10853397881226703), np.float64(0.10889698968755354), np.float64(0.1083574527690967), np.float64(0.10895536163847573), np.float64(0.1090820513005184), np.float64(0.10912301864790236), np.float64(0.10875006774883104), np.float64(0.10972748040487884), np.float64(0.10873882050062612), np.float64(0.10866363218352365), np.float64(0.10896681114584361), np.float64(0.11004027284596665), np.float64(0.1094309736145903), np.float64(0.10856651467462752), np.float64(0.1090825369597359), np.float64(0.10908731095401601), np.float64(0.10892201898665797), np.float64(0.10882160726281623), np.float64(0.10871045451955397), np.float64(0.10887988447303171), np.float64(0.10951085098275605), np.float64(0.11003440886436146), np.float64(0.10954060691495104), np.float64(0.10911916150806028), np.float64(0.10901036161059695), np.float64(0.10846199044694367), np.float64(0.10926127247991226), np.float64(0.10961071700661058), np.float64(0.10914050084409073), np.float64(0.10928706202810246), np.float64(0.11005252767493029), np.float64(0.10942991327179664), np.float64(0.10938740093678524), np.float64(0.10895688485561222), np.float64(0.10882976211032952), np.float64(0.1083538397992818), np.float64(0.10882364306466565), np.float64(0.10905828422687165), np.float64(0.10909989157254012), np.float64(0.10893036513610996), np.float64(0.10875436189200809), np.float64(0.10782686663234708), np.float64(0.10815592457497615), np.float64(0.10875208405092077), np.float64(0.10906295423641406), np.float64(0.10874712544493943), np.float64(0.10855178231131739), np.float64(0.1085835835287855), np.float64(0.1084414297322342), np.float64(0.10885639728760285), np.float64(0.10869130872457618), np.float64(0.10913349792794676), np.float64(0.10897351467756737), np.float64(0.10861713756882864), np.float64(0.10854201967441339), np.float64(0.10858022817984997), np.float64(0.10867316864694068), np.float64(0.10905565139704208), np.float64(0.10879036243618109), np.float64(0.10907190202167369), np.float64(0.10876400041159659), np.float64(0.10872143221540558), np.float64(0.1085778214594654), np.float64(0.10862237739449078), np.float64(0.10856237922725777), np.float64(0.10917882430956638), np.float64(0.10887167192485814), np.float64(0.10867703029325754), np.float64(0.10883288095062431), np.float64(0.10869100539043912), np.float64(0.10861332566812194), np.float64(0.1084825065887098), np.float64(0.10799661368284466), np.float64(0.10867368765884439), np.float64(0.1089428694994232), np.float64(0.10858191548352635), np.float64(0.10824724563902938), np.float64(0.10904265909002421), np.float64(0.10904465022275164), np.float64(0.10830702664051847), np.float64(0.10878275629280731), np.float64(0.10888179665213063), np.float64(0.10806865955390943), np.float64(0.10822930208580024), np.float64(0.1086354134176476), np.float64(0.10902829545797696), np.float64(0.10830434590796731), np.float64(0.1085561332676374), np.float64(0.10784564162917515), np.float64(0.108232575760952), np.float64(0.10851504665788385), np.float64(0.10810286392978502), np.float64(0.10890383635973758), np.float64(0.1083915782696939), np.float64(0.11032621567942767), np.float64(0.10805177556240185), np.float64(0.10866041277009256), np.float64(0.10895411649931322), np.float64(0.10913055351671912), np.float64(0.10906460362599037), np.float64(0.10830218456243564), np.float64(0.10841483185352692), np.float64(0.10847650795142695), np.float64(0.1082728389405914), np.float64(0.10819519489052715), np.float64(0.10836680701141185), np.float64(0.10844988552202857), np.float64(0.10891260130317643), np.float64(0.10942289025896206), np.float64(0.10877759426889931), np.float64(0.1082879132445572), np.float64(0.10787623440038223), np.float64(0.10830505151172558), np.float64(0.10831692478027881), np.float64(0.10951025952061225), np.float64(0.10912171792542648), np.float64(0.10870835346880506), np.float64(0.1090833203631329), np.float64(0.10953036743918376), np.float64(0.10922082533572511), np.float64(0.10964870829175576), np.float64(0.10807752469067979), np.float64(0.10835966649005004), np.float64(0.10981140918254155), np.float64(0.10788422923426562), np.float64(0.10810857832579684), np.float64(0.1084570396353373), np.float64(0.10849393718017762), np.float64(0.10802436076327686), np.float64(0.10883538821016023), np.float64(0.10777582985026686), np.float64(0.10875101326330337), np.float64(0.10830368465505563), np.float64(0.10896645348775287), np.float64(0.10907312408384334), np.float64(0.10827421049715853), np.float64(0.10899849306136102), np.float64(0.10859390893080224), np.float64(0.109242985391645), np.float64(0.10855865789829973), np.float64(0.10804765518227905), np.float64(0.10834823472696624), np.float64(0.10905719704200395), np.float64(0.10832637326566623), np.float64(0.1090902693939866), np.float64(0.10880659067474532), np.float64(0.10909250767807453), np.float64(0.10795591587643479), np.float64(0.10840656289548065), np.float64(0.10779800971753058), np.float64(0.10896730652612191), np.float64(0.10855485465843623), np.float64(0.10877362587140245), np.float64(0.10874022695605198), np.float64(0.10884249008058428), np.float64(0.10862133800837397), np.float64(0.10900776291257841), np.float64(0.1087301023311523), np.float64(0.1079482020598015), np.float64(0.10874192612732818), np.float64(0.10881889068114797), np.float64(0.10782024325495364), np.float64(0.10824548547848567), np.float64(0.1087451859555371), np.float64(0.10779614784029871), np.float64(0.10859303670439241), np.float64(0.10911763664402983), np.float64(0.10828414108108456), np.float64(0.10931121496548432), np.float64(0.10846554572835608), np.float64(0.10809200500026087), np.float64(0.10803958605454278), np.float64(0.10856551990161259), np.float64(0.10891126711440469), np.float64(0.10882673646424369), np.float64(0.10856997359954271), np.float64(0.10856907751442377), np.float64(0.10804410254042027), np.float64(0.10815701641528162), np.float64(0.10793766639460381), np.float64(0.10933155198929492), np.float64(0.1083882933852127), np.float64(0.10815355871162799), np.float64(0.10843814681871343), np.float64(0.10860059548674593), np.float64(0.10876385306264177), np.float64(0.10809889186672125), np.float64(0.10875971720074555)]\n",
      "         Layers  Epochs  Learning Rate  Momentum Activation       MSE  \\\n",
      "6  [9, 8, 4, 1]     500          0.001       0.5       relu  0.055458   \n",
      "2  [9, 8, 4, 1]     100          0.001       0.5       relu  0.055499   \n",
      "3  [9, 8, 4, 1]     100          0.001       0.9       relu  0.106749   \n",
      "7  [9, 8, 4, 1]     500          0.001       0.9       relu  0.108874   \n",
      "1  [9, 8, 4, 1]     100          0.010       0.9       relu  0.108968   \n",
      "0  [9, 8, 4, 1]     100          0.010       0.5       relu  0.255640   \n",
      "5  [9, 8, 4, 1]     500          0.010       0.9       relu  0.255640   \n",
      "4  [9, 8, 4, 1]     500          0.010       0.5       relu  0.255640   \n",
      "\n",
      "        MAE       MAPE                                       Train Losses  \\\n",
      "6  0.202168  65.317042  [0.06320291364261621, 0.05020025010534154, 0.0...   \n",
      "2  0.202159  65.178681  [0.06364850292505377, 0.05063164981172148, 0.0...   \n",
      "3  0.264762  84.708398  [0.049970647488157584, 0.04935643873980883, 0....   \n",
      "7  0.266317  85.041015  [0.04939193985859111, 0.049410725508206174, 0....   \n",
      "1  0.266330  85.103141  [0.05216032598843711, 0.049634546226013126, 0....   \n",
      "0  0.448027  99.999968  [0.2283074815770358, 0.2283074815770359, 0.228...   \n",
      "5  0.448027  99.999968  [0.2283074815770358, 0.22830748157703584, 0.22...   \n",
      "4  0.448027  99.999968  [0.22830748157703584, 0.22830748157703581, 0.2...   \n",
      "\n",
      "                                   Validation Losses  \n",
      "6  [0.06518888642217772, 0.05629018532091398, 0.0...  \n",
      "2  [0.06554743158118707, 0.05641325560282457, 0.0...  \n",
      "3  [0.058556813051305515, 0.0567343097862911, 0.0...  \n",
      "7  [0.05654649462569563, 0.05719378710129309, 0.0...  \n",
      "1  [0.05714368270546784, 0.05784588772181822, 0.0...  \n",
      "0  [0.2161498589965763, 0.2161498589965763, 0.216...  \n",
      "5  [0.2161498589965763, 0.2161498589965763, 0.216...  \n",
      "4  [0.2161498589965763, 0.2161498589965763, 0.216...  \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T09:59:54.343727Z",
     "start_time": "2024-12-05T09:59:40.732525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Best configuration\n",
    "best_params = results.loc[results[\"MSE\"].idxmin()]\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Scatter plot for best configuration\n",
    "nn_best = NeuralNet(\n",
    "    best_params[\"Layers\"],\n",
    "    best_params[\"Epochs\"],\n",
    "    best_params[\"Learning Rate\"],\n",
    "    best_params[\"Momentum\"],\n",
    "    best_params[\"Activation\"],\n",
    "    val_split=0.2\n",
    ")\n",
    "train_losses, val_losses = nn_best.fit(X_train, y_train)\n",
    "y_best_pred = nn_best.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_best_pred)\n",
    "plt.title(\"Predicted vs. True Values for Best Configuration\")\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.show()\n",
    "\n",
    "# Loss plot for best configuration\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs, train_losses, label=\"Training Loss\")\n",
    "plt.plot(epochs, val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.title(\"Training and Validation Loss Evolution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "ce085bdef70b03f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: Layers                                                    [9, 8, 4, 1]\n",
      "Epochs                                                             500\n",
      "Learning Rate                                                    0.001\n",
      "Momentum                                                           0.5\n",
      "Activation                                                        relu\n",
      "MSE                                                           0.055458\n",
      "MAE                                                           0.202168\n",
      "MAPE                                                         65.317042\n",
      "Train Losses         [0.06320291364261621, 0.05020025010534154, 0.0...\n",
      "Validation Losses    [0.06518888642217772, 0.05629018532091398, 0.0...\n",
      "Name: 6, dtype: object\n",
      "Epoch 1/500, Train Loss: 0.0639929183445628, Val Loss: 0.06582557291509679\n",
      "Epoch 2/500, Train Loss: 0.05046678934046366, Val Loss: 0.056358944660188294\n",
      "Epoch 3/500, Train Loss: 0.049415936939686274, Val Loss: 0.056490562185078204\n",
      "Epoch 4/500, Train Loss: 0.04936720782809739, Val Loss: 0.056640936360414826\n",
      "Epoch 5/500, Train Loss: 0.049366467354566144, Val Loss: 0.05664514448646339\n",
      "Epoch 6/500, Train Loss: 0.04936083724172939, Val Loss: 0.05668398644387469\n",
      "Epoch 7/500, Train Loss: 0.04937092875575869, Val Loss: 0.05662177420730601\n",
      "Epoch 8/500, Train Loss: 0.04936142890427024, Val Loss: 0.05667912060847719\n",
      "Epoch 9/500, Train Loss: 0.049358822179247225, Val Loss: 0.05688814316529349\n",
      "Epoch 10/500, Train Loss: 0.04936502451764442, Val Loss: 0.05694966940531852\n",
      "Epoch 11/500, Train Loss: 0.049355670441793904, Val Loss: 0.056749809678651376\n",
      "Epoch 12/500, Train Loss: 0.049357320835724694, Val Loss: 0.05672086973171263\n",
      "Epoch 13/500, Train Loss: 0.04935553006848183, Val Loss: 0.05675336618808008\n",
      "Epoch 14/500, Train Loss: 0.04935931290976948, Val Loss: 0.056697910727365804\n",
      "Epoch 15/500, Train Loss: 0.049358754740046924, Val Loss: 0.056703657375986476\n",
      "Epoch 16/500, Train Loss: 0.04935630658689725, Val Loss: 0.05684939892053338\n",
      "Epoch 17/500, Train Loss: 0.04935599549643143, Val Loss: 0.05674261025240217\n",
      "Epoch 18/500, Train Loss: 0.04935531748520297, Val Loss: 0.05675954335261531\n",
      "Epoch 19/500, Train Loss: 0.04935518005740646, Val Loss: 0.056819485268570766\n",
      "Epoch 20/500, Train Loss: 0.04937041358805185, Val Loss: 0.056990009691945155\n",
      "Epoch 21/500, Train Loss: 0.04940523184166265, Val Loss: 0.05717080537736967\n",
      "Epoch 22/500, Train Loss: 0.04935486586008528, Val Loss: 0.05678226401932395\n",
      "Epoch 23/500, Train Loss: 0.049358192192623045, Val Loss: 0.05687990198730367\n",
      "Epoch 24/500, Train Loss: 0.04936222358577332, Val Loss: 0.05667295630220473\n",
      "Epoch 25/500, Train Loss: 0.04935486142455777, Val Loss: 0.05678278477020823\n",
      "Epoch 26/500, Train Loss: 0.049362863581836544, Val Loss: 0.056930905508783845\n",
      "Epoch 27/500, Train Loss: 0.049358060384888366, Val Loss: 0.05687808980034274\n",
      "Epoch 28/500, Train Loss: 0.049359762607911896, Val Loss: 0.05669356103943832\n",
      "Epoch 29/500, Train Loss: 0.04935566824653967, Val Loss: 0.05683491223104031\n",
      "Epoch 30/500, Train Loss: 0.0493591598594503, Val Loss: 0.05689231271150159\n",
      "Epoch 31/500, Train Loss: 0.0493914721360873, Val Loss: 0.05710859112851832\n",
      "Epoch 32/500, Train Loss: 0.049359133685308434, Val Loss: 0.05689199486937275\n",
      "Epoch 33/500, Train Loss: 0.04936201673463574, Val Loss: 0.05692294834642049\n",
      "Epoch 34/500, Train Loss: 0.049359120014350735, Val Loss: 0.05689182847043659\n",
      "Epoch 35/500, Train Loss: 0.049368158631801114, Val Loss: 0.05663574446574686\n",
      "Epoch 36/500, Train Loss: 0.0493566683075246, Val Loss: 0.056730506622663664\n",
      "Epoch 37/500, Train Loss: 0.049354829006518657, Val Loss: 0.05678875233572309\n",
      "Epoch 38/500, Train Loss: 0.04935483141421318, Val Loss: 0.05679515299531605\n",
      "Epoch 39/500, Train Loss: 0.049354927636194784, Val Loss: 0.056806459223695455\n",
      "Epoch 40/500, Train Loss: 0.049359846858735096, Val Loss: 0.05669277053418113\n",
      "Epoch 41/500, Train Loss: 0.0493581589909414, Val Loss: 0.05671030723562458\n",
      "Epoch 42/500, Train Loss: 0.04935908021566186, Val Loss: 0.056891342593981625\n",
      "Epoch 43/500, Train Loss: 0.04936336871213634, Val Loss: 0.05666470122353293\n",
      "Epoch 44/500, Train Loss: 0.04935940622883698, Val Loss: 0.05689526134013542\n",
      "Epoch 45/500, Train Loss: 0.04935499125845621, Val Loss: 0.05681057562893571\n",
      "Epoch 46/500, Train Loss: 0.04935540403903932, Val Loss: 0.05682735779966526\n",
      "Epoch 47/500, Train Loss: 0.049354956583647844, Val Loss: 0.056774896332609855\n",
      "Epoch 48/500, Train Loss: 0.04935664335142234, Val Loss: 0.05685581509779035\n",
      "Epoch 49/500, Train Loss: 0.04935846645472453, Val Loss: 0.05688356927732336\n",
      "Epoch 50/500, Train Loss: 0.0493570976686334, Val Loss: 0.05672399390098128\n",
      "Epoch 51/500, Train Loss: 0.04935483615563818, Val Loss: 0.056786742785031624\n",
      "Epoch 52/500, Train Loss: 0.049357456530170866, Val Loss: 0.05671904127079439\n",
      "Epoch 53/500, Train Loss: 0.0493550263540901, Val Loss: 0.056812510348702557\n",
      "Epoch 54/500, Train Loss: 0.049366105448026616, Val Loss: 0.05695839016137102\n",
      "Epoch 55/500, Train Loss: 0.04935869746812529, Val Loss: 0.05688656077945682\n",
      "Epoch 56/500, Train Loss: 0.04935763416333371, Val Loss: 0.056871980649454555\n",
      "Epoch 57/500, Train Loss: 0.04936728308857624, Val Loss: 0.056967486683901114\n",
      "Epoch 58/500, Train Loss: 0.04935785736819253, Val Loss: 0.056713921689334514\n",
      "Epoch 59/500, Train Loss: 0.04935749795374198, Val Loss: 0.05671849334228909\n",
      "Epoch 60/500, Train Loss: 0.04935506269179585, Val Loss: 0.0567692157893446\n",
      "Epoch 61/500, Train Loss: 0.04936243101683276, Val Loss: 0.05692688931564394\n",
      "Epoch 62/500, Train Loss: 0.04935692506101293, Val Loss: 0.05686076085978432\n",
      "Epoch 63/500, Train Loss: 0.04935528361037179, Val Loss: 0.05676064635580531\n",
      "Epoch 64/500, Train Loss: 0.049358725424649565, Val Loss: 0.05688691681298974\n",
      "Epoch 65/500, Train Loss: 0.049355066553021444, Val Loss: 0.05676903665206323\n",
      "Epoch 66/500, Train Loss: 0.049355267831138916, Val Loss: 0.05676117503815502\n",
      "Epoch 67/500, Train Loss: 0.04935705872210239, Val Loss: 0.0568629976321426\n",
      "Epoch 68/500, Train Loss: 0.04935503719940403, Val Loss: 0.056770436324529196\n",
      "Epoch 69/500, Train Loss: 0.04936174608601111, Val Loss: 0.056676611021449955\n",
      "Epoch 70/500, Train Loss: 0.04935725672749541, Val Loss: 0.056721749874469915\n",
      "Epoch 71/500, Train Loss: 0.0493607265718323, Val Loss: 0.056684924092381545\n",
      "Epoch 72/500, Train Loss: 0.049361238215608644, Val Loss: 0.056915252306306625\n",
      "Epoch 73/500, Train Loss: 0.0493591144628497, Val Loss: 0.056699904607069376\n",
      "Epoch 74/500, Train Loss: 0.04936082544091414, Val Loss: 0.05691100164952858\n",
      "Epoch 75/500, Train Loss: 0.049355030050294346, Val Loss: 0.056770791722758875\n",
      "Epoch 76/500, Train Loss: 0.04935502952513701, Val Loss: 0.05677081805925512\n",
      "Epoch 77/500, Train Loss: 0.04935568330262335, Val Loss: 0.056835303644617065\n",
      "Epoch 78/500, Train Loss: 0.04935567488381632, Val Loss: 0.056835084161023\n",
      "Epoch 79/500, Train Loss: 0.049358870676684326, Val Loss: 0.056702426661460414\n",
      "Epoch 80/500, Train Loss: 0.049355478096363425, Val Loss: 0.05675477333586653\n",
      "Epoch 81/500, Train Loss: 0.049354845590205795, Val Loss: 0.05679815014481004\n",
      "Epoch 82/500, Train Loss: 0.049358499463090164, Val Loss: 0.05670643258127203\n",
      "Epoch 83/500, Train Loss: 0.049355181094803816, Val Loss: 0.05681952430172696\n",
      "Epoch 84/500, Train Loss: 0.04936747212659011, Val Loss: 0.056639468146570594\n",
      "Epoch 85/500, Train Loss: 0.049360884531368436, Val Loss: 0.05668358553289034\n",
      "Epoch 86/500, Train Loss: 0.049354825477585546, Val Loss: 0.05679104981237208\n",
      "Epoch 87/500, Train Loss: 0.04936910262550552, Val Loss: 0.056630801923259776\n",
      "Epoch 88/500, Train Loss: 0.04935614367289649, Val Loss: 0.056846042906802\n",
      "Epoch 89/500, Train Loss: 0.04936014827890534, Val Loss: 0.05669000046646445\n",
      "Epoch 90/500, Train Loss: 0.049358696546852696, Val Loss: 0.056704279190977855\n",
      "Epoch 91/500, Train Loss: 0.049355074439185256, Val Loss: 0.056814907754740754\n",
      "Epoch 92/500, Train Loss: 0.049355715523762035, Val Loss: 0.05674873103793097\n",
      "Epoch 93/500, Train Loss: 0.04935620073764024, Val Loss: 0.056847238564174195\n",
      "Epoch 94/500, Train Loss: 0.0493639041961932, Val Loss: 0.05694018498890146\n",
      "Epoch 95/500, Train Loss: 0.049354863083259023, Val Loss: 0.056782583865042\n",
      "Epoch 96/500, Train Loss: 0.049359756312982374, Val Loss: 0.05689932752177193\n",
      "Epoch 97/500, Train Loss: 0.049354931179223266, Val Loss: 0.05680671478902026\n",
      "Epoch 98/500, Train Loss: 0.04937181071634662, Val Loss: 0.056999422849603694\n",
      "Epoch 99/500, Train Loss: 0.04935736740463488, Val Loss: 0.0568679336852929\n",
      "Epoch 100/500, Train Loss: 0.0493552221810391, Val Loss: 0.05676276058286165\n",
      "Epoch 101/500, Train Loss: 0.04938862762288041, Val Loss: 0.056556046643243214\n",
      "Epoch 102/500, Train Loss: 0.04936645775409173, Val Loss: 0.056961150773147465\n",
      "Epoch 103/500, Train Loss: 0.049354921276583356, Val Loss: 0.056777292607507815\n",
      "Epoch 104/500, Train Loss: 0.049368378376140366, Val Loss: 0.05697561503808211\n",
      "Epoch 105/500, Train Loss: 0.04935493524159966, Val Loss: 0.05680700495682996\n",
      "Epoch 106/500, Train Loss: 0.04935956314655975, Val Loss: 0.0566954592173393\n",
      "Epoch 107/500, Train Loss: 0.04936236421217356, Val Loss: 0.05667190235240113\n",
      "Epoch 108/500, Train Loss: 0.04935539979008756, Val Loss: 0.056757010149288016\n",
      "Epoch 109/500, Train Loss: 0.04935683407190089, Val Loss: 0.05672790258533414\n",
      "Epoch 110/500, Train Loss: 0.049355047290389614, Val Loss: 0.05676994269189363\n",
      "Epoch 111/500, Train Loss: 0.0493585493522308, Val Loss: 0.056705880456546\n",
      "Epoch 112/500, Train Loss: 0.049356198361312435, Val Loss: 0.056847188228344815\n",
      "Epoch 113/500, Train Loss: 0.0493592860703553, Val Loss: 0.056893829065514157\n",
      "Epoch 114/500, Train Loss: 0.04936887270470661, Val Loss: 0.05663198586765295\n",
      "Epoch 115/500, Train Loss: 0.049356076291397565, Val Loss: 0.05684459713887297\n",
      "Epoch 116/500, Train Loss: 0.04935826479161179, Val Loss: 0.05670907857729364\n",
      "Epoch 117/500, Train Loss: 0.049355132725957124, Val Loss: 0.0568175274149399\n",
      "Epoch 118/500, Train Loss: 0.04935539298966605, Val Loss: 0.05682700541784509\n",
      "Epoch 119/500, Train Loss: 0.049355189142565085, Val Loss: 0.05681984121006708\n",
      "Epoch 120/500, Train Loss: 0.049355244629074854, Val Loss: 0.05676196805768055\n",
      "Epoch 121/500, Train Loss: 0.0493567850765476, Val Loss: 0.05672865851212609\n",
      "Epoch 122/500, Train Loss: 0.049370621676248574, Val Loss: 0.05699142934078303\n",
      "Epoch 123/500, Train Loss: 0.04935835491797969, Val Loss: 0.056708050140149124\n",
      "Epoch 124/500, Train Loss: 0.04935746214480264, Val Loss: 0.05671896372385301\n",
      "Epoch 125/500, Train Loss: 0.04935513154231007, Val Loss: 0.05681747625032188\n",
      "Epoch 126/500, Train Loss: 0.04935537031474656, Val Loss: 0.056757892245742673\n",
      "Epoch 127/500, Train Loss: 0.04936052089991558, Val Loss: 0.056686694165585715\n",
      "Epoch 128/500, Train Loss: 0.049361177413431066, Val Loss: 0.05668115337831558\n",
      "Epoch 129/500, Train Loss: 0.049359536081497735, Val Loss: 0.056695719367948205\n",
      "Epoch 130/500, Train Loss: 0.049355719120434724, Val Loss: 0.05683622299333796\n",
      "Epoch 131/500, Train Loss: 0.049356803434571966, Val Loss: 0.05672837330687304\n",
      "Epoch 132/500, Train Loss: 0.04935600045441624, Val Loss: 0.05684292532549705\n",
      "Epoch 133/500, Train Loss: 0.04935483389403453, Val Loss: 0.05678727071257603\n",
      "Epoch 134/500, Train Loss: 0.049355052239362325, Val Loss: 0.05681382890855767\n",
      "Epoch 135/500, Train Loss: 0.04935538882422328, Val Loss: 0.05682687190904457\n",
      "Epoch 136/500, Train Loss: 0.04935676980889394, Val Loss: 0.056858072638457456\n",
      "Epoch 137/500, Train Loss: 0.04937153790551571, Val Loss: 0.05699760815650811\n",
      "Epoch 138/500, Train Loss: 0.049356427923001676, Val Loss: 0.05673450598045605\n",
      "Epoch 139/500, Train Loss: 0.04935913516080372, Val Loss: 0.056892007401824346\n",
      "Epoch 140/500, Train Loss: 0.049356911383478703, Val Loss: 0.056860523951665416\n",
      "Epoch 141/500, Train Loss: 0.04935509199485332, Val Loss: 0.05681572320535604\n",
      "Epoch 142/500, Train Loss: 0.04935790510580287, Val Loss: 0.05687590479464494\n",
      "Epoch 143/500, Train Loss: 0.04935483301545124, Val Loss: 0.05678749556156162\n",
      "Epoch 144/500, Train Loss: 0.04935611797798299, Val Loss: 0.05684549303945226\n",
      "Epoch 145/500, Train Loss: 0.049363714232965004, Val Loss: 0.0566623319473606\n",
      "Epoch 146/500, Train Loss: 0.04936473586416496, Val Loss: 0.0569472655954106\n",
      "Epoch 147/500, Train Loss: 0.04935964937682679, Val Loss: 0.056898095932385366\n",
      "Epoch 148/500, Train Loss: 0.04936062319080871, Val Loss: 0.05690886628817055\n",
      "Epoch 149/500, Train Loss: 0.04935653429158534, Val Loss: 0.05685379844447686\n",
      "Epoch 150/500, Train Loss: 0.04935482553206036, Val Loss: 0.05679213638708424\n",
      "Epoch 151/500, Train Loss: 0.04935776269417678, Val Loss: 0.05687386013275257\n",
      "Epoch 152/500, Train Loss: 0.04935589176688671, Val Loss: 0.05684043689292624\n",
      "Epoch 153/500, Train Loss: 0.04935613324393466, Val Loss: 0.05673987499367363\n",
      "Epoch 154/500, Train Loss: 0.04935962399104993, Val Loss: 0.05689780194566246\n",
      "Epoch 155/500, Train Loss: 0.04935506981016385, Val Loss: 0.05676888213549943\n",
      "Epoch 156/500, Train Loss: 0.049357239294099686, Val Loss: 0.05672198745108353\n",
      "Epoch 157/500, Train Loss: 0.04935489522161165, Val Loss: 0.056803850185251574\n",
      "Epoch 158/500, Train Loss: 0.04935482903591477, Val Loss: 0.05678873572711538\n",
      "Epoch 159/500, Train Loss: 0.04935525053714294, Val Loss: 0.05676176092651283\n",
      "Epoch 160/500, Train Loss: 0.04936008658163317, Val Loss: 0.05690304213008096\n",
      "Epoch 161/500, Train Loss: 0.04937185354854949, Val Loss: 0.056999701546613185\n",
      "Epoch 162/500, Train Loss: 0.04939265881871892, Val Loss: 0.05711427305953307\n",
      "Epoch 163/500, Train Loss: 0.04935510767952036, Val Loss: 0.05681643071088261\n",
      "Epoch 164/500, Train Loss: 0.04935900498625454, Val Loss: 0.05670102264229012\n",
      "Epoch 165/500, Train Loss: 0.049356911442823954, Val Loss: 0.05672672428860765\n",
      "Epoch 166/500, Train Loss: 0.049360235990972286, Val Loss: 0.05668920720282796\n",
      "Epoch 167/500, Train Loss: 0.049362339142465725, Val Loss: 0.05667208557787395\n",
      "Epoch 168/500, Train Loss: 0.0493640968464302, Val Loss: 0.05665977231197026\n",
      "Epoch 169/500, Train Loss: 0.04935724582015966, Val Loss: 0.05672189587429048\n",
      "Epoch 170/500, Train Loss: 0.04936453048185876, Val Loss: 0.05694553928459852\n",
      "Epoch 171/500, Train Loss: 0.04935689350561078, Val Loss: 0.056860216355708905\n",
      "Epoch 172/500, Train Loss: 0.04935629488485968, Val Loss: 0.05684915581910441\n",
      "Epoch 173/500, Train Loss: 0.049363015685128776, Val Loss: 0.05693228560374318\n",
      "Epoch 174/500, Train Loss: 0.049355172250101075, Val Loss: 0.05676460347341444\n",
      "Epoch 175/500, Train Loss: 0.049361365018335185, Val Loss: 0.05667962669484312\n",
      "Epoch 176/500, Train Loss: 0.049364830456322374, Val Loss: 0.0566550318047128\n",
      "Epoch 177/500, Train Loss: 0.049357405457534434, Val Loss: 0.05671971649515854\n",
      "Epoch 178/500, Train Loss: 0.049355015923064946, Val Loss: 0.05677150767992366\n",
      "Epoch 179/500, Train Loss: 0.04936104915537338, Val Loss: 0.0569133139559903\n",
      "Epoch 180/500, Train Loss: 0.049354962962767084, Val Loss: 0.05680885540801756\n",
      "Epoch 181/500, Train Loss: 0.049369050066069946, Val Loss: 0.056631066950626516\n",
      "Epoch 182/500, Train Loss: 0.04935841716744795, Val Loss: 0.05670734461682052\n",
      "Epoch 183/500, Train Loss: 0.049355404407891185, Val Loss: 0.0568273613168012\n",
      "Epoch 184/500, Train Loss: 0.049367110579094486, Val Loss: 0.05696616957235308\n",
      "Epoch 185/500, Train Loss: 0.04935526728629075, Val Loss: 0.056822769174027093\n",
      "Epoch 186/500, Train Loss: 0.049362891356540525, Val Loss: 0.056931150121483365\n",
      "Epoch 187/500, Train Loss: 0.04935486621088571, Val Loss: 0.05678221568436698\n",
      "Epoch 188/500, Train Loss: 0.049356741509195626, Val Loss: 0.05672933527456062\n",
      "Epoch 189/500, Train Loss: 0.04935575500563455, Val Loss: 0.05674780577597558\n",
      "Epoch 190/500, Train Loss: 0.049354827437769797, Val Loss: 0.05678942995137386\n",
      "Epoch 191/500, Train Loss: 0.04935549380758972, Val Loss: 0.05675433451395527\n",
      "Epoch 192/500, Train Loss: 0.04935483520715664, Val Loss: 0.056786950527646186\n",
      "Epoch 193/500, Train Loss: 0.049358255603959685, Val Loss: 0.05688075172553584\n",
      "Epoch 194/500, Train Loss: 0.04935486708792386, Val Loss: 0.056801037623357066\n",
      "Epoch 195/500, Train Loss: 0.049355592052495345, Val Loss: 0.05683285849636707\n",
      "Epoch 196/500, Train Loss: 0.049357994757822404, Val Loss: 0.0567122441915134\n",
      "Epoch 197/500, Train Loss: 0.04935833268500021, Val Loss: 0.05670829729909414\n",
      "Epoch 198/500, Train Loss: 0.04936168943765638, Val Loss: 0.05691975062070423\n",
      "Epoch 199/500, Train Loss: 0.04935559711594453, Val Loss: 0.05683299686899892\n",
      "Epoch 200/500, Train Loss: 0.04935553786119492, Val Loss: 0.05675314972089996\n",
      "Epoch 201/500, Train Loss: 0.04936476250859569, Val Loss: 0.05665546025675949\n",
      "Epoch 202/500, Train Loss: 0.04935623761065111, Val Loss: 0.05673790252199213\n",
      "Epoch 203/500, Train Loss: 0.04935632002619031, Val Loss: 0.056736401515673406\n",
      "Epoch 204/500, Train Loss: 0.04935541881456002, Val Loss: 0.056827809333429534\n",
      "Epoch 205/500, Train Loss: 0.04936369638636814, Val Loss: 0.05693836151506156\n",
      "Epoch 206/500, Train Loss: 0.04935798589264275, Val Loss: 0.05671234987691481\n",
      "Epoch 207/500, Train Loss: 0.04936217965202861, Val Loss: 0.056924498489978125\n",
      "Epoch 208/500, Train Loss: 0.04935954490351145, Val Loss: 0.05689687803736534\n",
      "Epoch 209/500, Train Loss: 0.049371439118551984, Val Loss: 0.056996941688659326\n",
      "Epoch 210/500, Train Loss: 0.04935834541258548, Val Loss: 0.056708151670354943\n",
      "Epoch 211/500, Train Loss: 0.04935504169209632, Val Loss: 0.05681329277296622\n",
      "Epoch 212/500, Train Loss: 0.0493597702594609, Val Loss: 0.05669347905918007\n",
      "Epoch 213/500, Train Loss: 0.04935997016326063, Val Loss: 0.05690173837443388\n",
      "Epoch 214/500, Train Loss: 0.04935988451587813, Val Loss: 0.056692409967905005\n",
      "Epoch 215/500, Train Loss: 0.049356901044020025, Val Loss: 0.05672687653813274\n",
      "Epoch 216/500, Train Loss: 0.049357123686318394, Val Loss: 0.05672361126996103\n",
      "Epoch 217/500, Train Loss: 0.04935503479983917, Val Loss: 0.056812939127881615\n",
      "Epoch 218/500, Train Loss: 0.04935689623142109, Val Loss: 0.05672694878192177\n",
      "Epoch 219/500, Train Loss: 0.04935508395776265, Val Loss: 0.056768237316935526\n",
      "Epoch 220/500, Train Loss: 0.04936685567387156, Val Loss: 0.05696421708543796\n",
      "Epoch 221/500, Train Loss: 0.04935820404645188, Val Loss: 0.05688004969781506\n",
      "Epoch 222/500, Train Loss: 0.04936762642399191, Val Loss: 0.05663861206746456\n",
      "Epoch 223/500, Train Loss: 0.049358654673675034, Val Loss: 0.05670472242032041\n",
      "Epoch 224/500, Train Loss: 0.04936031873432607, Val Loss: 0.05690558621654219\n",
      "Epoch 225/500, Train Loss: 0.049381306694627584, Val Loss: 0.05705636798382706\n",
      "Epoch 226/500, Train Loss: 0.04935947109358789, Val Loss: 0.0566963427091797\n",
      "Epoch 227/500, Train Loss: 0.049377768729591105, Val Loss: 0.05659261265134337\n",
      "Epoch 228/500, Train Loss: 0.04936795515660934, Val Loss: 0.056972496322984935\n",
      "Epoch 229/500, Train Loss: 0.04935769844981727, Val Loss: 0.05671589375196162\n",
      "Epoch 230/500, Train Loss: 0.04935614355174046, Val Loss: 0.0568460285185056\n",
      "Epoch 231/500, Train Loss: 0.04938099968868004, Val Loss: 0.05705467437460704\n",
      "Epoch 232/500, Train Loss: 0.04936302426994296, Val Loss: 0.05693235667345192\n",
      "Epoch 233/500, Train Loss: 0.049354911537629824, Val Loss: 0.05677802046214771\n",
      "Epoch 234/500, Train Loss: 0.04935487677179937, Val Loss: 0.05680208308377448\n",
      "Epoch 235/500, Train Loss: 0.04935508477436794, Val Loss: 0.05676819902291484\n",
      "Epoch 236/500, Train Loss: 0.04935864003294265, Val Loss: 0.05670487958450348\n",
      "Epoch 237/500, Train Loss: 0.049362562484663315, Val Loss: 0.056928104864996894\n",
      "Epoch 238/500, Train Loss: 0.049355669627465855, Val Loss: 0.05683493302184753\n",
      "Epoch 239/500, Train Loss: 0.049356683539354795, Val Loss: 0.05685652658791313\n",
      "Epoch 240/500, Train Loss: 0.049356268556537755, Val Loss: 0.05684861618198787\n",
      "Epoch 241/500, Train Loss: 0.049354825505179695, Val Loss: 0.05679206353186869\n",
      "Epoch 242/500, Train Loss: 0.04935860338932988, Val Loss: 0.056705277607267776\n",
      "Epoch 243/500, Train Loss: 0.04935489949947677, Val Loss: 0.05677899238671087\n",
      "Epoch 244/500, Train Loss: 0.04937278566797318, Val Loss: 0.05661319382011269\n",
      "Epoch 245/500, Train Loss: 0.04935671412804999, Val Loss: 0.05672976130042077\n",
      "Epoch 246/500, Train Loss: 0.04935667731221287, Val Loss: 0.05685641332112585\n",
      "Epoch 247/500, Train Loss: 0.04938275596165816, Val Loss: 0.057064248250290814\n",
      "Epoch 248/500, Train Loss: 0.049389571805271176, Val Loss: 0.057099302645476954\n",
      "Epoch 249/500, Train Loss: 0.04935826753917339, Val Loss: 0.05670903573499789\n",
      "Epoch 250/500, Train Loss: 0.049356910475710086, Val Loss: 0.05686049650236152\n",
      "Epoch 251/500, Train Loss: 0.0493548421942003, Val Loss: 0.05678553779165319\n",
      "Epoch 252/500, Train Loss: 0.049355964638285926, Val Loss: 0.05684210570722163\n",
      "Epoch 253/500, Train Loss: 0.04935863325608476, Val Loss: 0.05670495096836414\n",
      "Epoch 254/500, Train Loss: 0.049355357690238695, Val Loss: 0.05682585378283875\n",
      "Epoch 255/500, Train Loss: 0.049373292600975595, Val Loss: 0.05661094840180625\n",
      "Epoch 256/500, Train Loss: 0.04935511652787336, Val Loss: 0.05681681117282456\n",
      "Epoch 257/500, Train Loss: 0.04936203592716163, Val Loss: 0.05692311366361651\n",
      "Epoch 258/500, Train Loss: 0.049365765303779924, Val Loss: 0.05695566708087564\n",
      "Epoch 259/500, Train Loss: 0.04936158879790166, Val Loss: 0.0566778320789293\n",
      "Epoch 260/500, Train Loss: 0.049363068587544925, Val Loss: 0.05666678531894408\n",
      "Epoch 261/500, Train Loss: 0.04936328960853805, Val Loss: 0.05693474628933602\n",
      "Epoch 262/500, Train Loss: 0.04935563007359316, Val Loss: 0.05683388086664068\n",
      "Epoch 263/500, Train Loss: 0.04936258226857877, Val Loss: 0.056928285039141734\n",
      "Epoch 264/500, Train Loss: 0.049358764977615224, Val Loss: 0.056703531002511104\n",
      "Epoch 265/500, Train Loss: 0.049357396215427285, Val Loss: 0.056868362610429414\n",
      "Epoch 266/500, Train Loss: 0.049359341693019344, Val Loss: 0.05669760801119067\n",
      "Epoch 267/500, Train Loss: 0.04935790924461399, Val Loss: 0.05671327000299822\n",
      "Epoch 268/500, Train Loss: 0.04935580734384613, Val Loss: 0.0567466084631796\n",
      "Epoch 269/500, Train Loss: 0.0493563995618781, Val Loss: 0.0568512130529859\n",
      "Epoch 270/500, Train Loss: 0.049362756360919316, Val Loss: 0.05692989702201408\n",
      "Epoch 271/500, Train Loss: 0.049363830578106394, Val Loss: 0.05693952438005827\n",
      "Epoch 272/500, Train Loss: 0.04936252136421231, Val Loss: 0.05692771446470099\n",
      "Epoch 273/500, Train Loss: 0.04935499613318847, Val Loss: 0.05677255518098656\n",
      "Epoch 274/500, Train Loss: 0.04937051480019659, Val Loss: 0.05662374753350349\n",
      "Epoch 275/500, Train Loss: 0.0493549259408502, Val Loss: 0.0568063125597752\n",
      "Epoch 276/500, Train Loss: 0.04936169138604754, Val Loss: 0.0566770217206761\n",
      "Epoch 277/500, Train Loss: 0.049367993923399495, Val Loss: 0.05663661020566533\n",
      "Epoch 278/500, Train Loss: 0.049363572767303056, Val Loss: 0.056663279988461115\n",
      "Epoch 279/500, Train Loss: 0.04935494887275446, Val Loss: 0.05680792338484151\n",
      "Epoch 280/500, Train Loss: 0.049359116551775155, Val Loss: 0.056891762540955064\n",
      "Epoch 281/500, Train Loss: 0.04935629141278279, Val Loss: 0.056849070434351556\n",
      "Epoch 282/500, Train Loss: 0.049354956640823955, Val Loss: 0.05680843450775928\n",
      "Epoch 283/500, Train Loss: 0.049356697673576665, Val Loss: 0.05685677212296307\n",
      "Epoch 284/500, Train Loss: 0.04936878433051966, Val Loss: 0.056978532531101814\n",
      "Epoch 285/500, Train Loss: 0.04935494939650286, Val Loss: 0.05677533447530696\n",
      "Epoch 286/500, Train Loss: 0.049355140566824975, Val Loss: 0.05681784010434182\n",
      "Epoch 287/500, Train Loss: 0.04935505476608012, Val Loss: 0.05681393403406379\n",
      "Epoch 288/500, Train Loss: 0.04935725662649288, Val Loss: 0.05672173098969588\n",
      "Epoch 289/500, Train Loss: 0.04936552479032336, Val Loss: 0.05665071392188653\n",
      "Epoch 290/500, Train Loss: 0.04937090544960794, Val Loss: 0.05662186526526813\n",
      "Epoch 291/500, Train Loss: 0.04935642920453695, Val Loss: 0.05673446587627574\n",
      "Epoch 292/500, Train Loss: 0.04935829067434103, Val Loss: 0.0567087628972381\n",
      "Epoch 293/500, Train Loss: 0.049379275855326095, Val Loss: 0.05658693944275196\n",
      "Epoch 294/500, Train Loss: 0.04940466900913058, Val Loss: 0.056514357707021255\n",
      "Epoch 295/500, Train Loss: 0.04935560352191658, Val Loss: 0.056751439322596256\n",
      "Epoch 296/500, Train Loss: 0.0493591620694668, Val Loss: 0.05689231152145489\n",
      "Epoch 297/500, Train Loss: 0.0493644494096681, Val Loss: 0.05694483302085707\n",
      "Epoch 298/500, Train Loss: 0.04935586309502064, Val Loss: 0.05674537297424649\n",
      "Epoch 299/500, Train Loss: 0.049357838838102165, Val Loss: 0.05687493633774702\n",
      "Epoch 300/500, Train Loss: 0.049357434444726504, Val Loss: 0.05671931151305916\n",
      "Epoch 301/500, Train Loss: 0.0493569847652282, Val Loss: 0.05672561360107048\n",
      "Epoch 302/500, Train Loss: 0.04935552033442675, Val Loss: 0.05675360007617728\n",
      "Epoch 303/500, Train Loss: 0.04935900255559655, Val Loss: 0.05689035930770932\n",
      "Epoch 304/500, Train Loss: 0.049356430451385665, Val Loss: 0.056851802419485085\n",
      "Epoch 305/500, Train Loss: 0.049354846097422654, Val Loss: 0.05679820211173631\n",
      "Epoch 306/500, Train Loss: 0.04935485037064754, Val Loss: 0.056784220723012854\n",
      "Epoch 307/500, Train Loss: 0.049356506771967734, Val Loss: 0.05673313773807118\n",
      "Epoch 308/500, Train Loss: 0.04935514482053621, Val Loss: 0.056765657059382385\n",
      "Epoch 309/500, Train Loss: 0.04936178048699934, Val Loss: 0.056920621823654066\n",
      "Epoch 310/500, Train Loss: 0.04936101129942141, Val Loss: 0.05691289979372169\n",
      "Epoch 311/500, Train Loss: 0.049355922890799014, Val Loss: 0.05684113516141439\n",
      "Epoch 312/500, Train Loss: 0.049364298580555445, Val Loss: 0.05694354621535003\n",
      "Epoch 313/500, Train Loss: 0.049355420552582706, Val Loss: 0.05675637656748555\n",
      "Epoch 314/500, Train Loss: 0.04935533391803768, Val Loss: 0.05682505162723142\n",
      "Epoch 315/500, Train Loss: 0.049356256880890896, Val Loss: 0.056848361427637925\n",
      "Epoch 316/500, Train Loss: 0.049354846889954535, Val Loss: 0.05679832463300334\n",
      "Epoch 317/500, Train Loss: 0.04935569447950219, Val Loss: 0.05683556102467046\n",
      "Epoch 318/500, Train Loss: 0.04935538521557523, Val Loss: 0.05675741670200704\n",
      "Epoch 319/500, Train Loss: 0.049382582419904744, Val Loss: 0.05706329166188456\n",
      "Epoch 320/500, Train Loss: 0.04935762914351101, Val Loss: 0.05687187099449555\n",
      "Epoch 321/500, Train Loss: 0.049356580878974654, Val Loss: 0.05673189827652115\n",
      "Epoch 322/500, Train Loss: 0.04935557476176851, Val Loss: 0.056752164997708424\n",
      "Epoch 323/500, Train Loss: 0.0493548600175512, Val Loss: 0.05680016237774518\n",
      "Epoch 324/500, Train Loss: 0.04935961209382077, Val Loss: 0.05669496067213487\n",
      "Epoch 325/500, Train Loss: 0.04935797327893592, Val Loss: 0.05671247966030516\n",
      "Epoch 326/500, Train Loss: 0.04935490146163027, Val Loss: 0.056778811739410656\n",
      "Epoch 327/500, Train Loss: 0.049358364241647974, Val Loss: 0.056707916049491415\n",
      "Epoch 328/500, Train Loss: 0.04935505388751041, Val Loss: 0.05681387656318549\n",
      "Epoch 329/500, Train Loss: 0.04935577544180428, Val Loss: 0.0567473125728498\n",
      "Epoch 330/500, Train Loss: 0.04935624526837566, Val Loss: 0.056737736584953985\n",
      "Epoch 331/500, Train Loss: 0.049356684792011295, Val Loss: 0.05685652482147197\n",
      "Epoch 332/500, Train Loss: 0.04935523250821311, Val Loss: 0.056821466451407954\n",
      "Epoch 333/500, Train Loss: 0.04935578480197817, Val Loss: 0.05683783308358996\n",
      "Epoch 334/500, Train Loss: 0.04935741030626827, Val Loss: 0.05686855827725279\n",
      "Epoch 335/500, Train Loss: 0.04938020109152961, Val Loss: 0.05705020139590841\n",
      "Epoch 336/500, Train Loss: 0.049358435726992965, Val Loss: 0.056883122364666125\n",
      "Epoch 337/500, Train Loss: 0.049355378874668156, Val Loss: 0.05682651590240627\n",
      "Epoch 338/500, Train Loss: 0.04935542812419671, Val Loss: 0.056828065097811443\n",
      "Epoch 339/500, Train Loss: 0.04935777066802002, Val Loss: 0.0568739376594558\n",
      "Epoch 340/500, Train Loss: 0.04935651020736188, Val Loss: 0.05673306854051155\n",
      "Epoch 341/500, Train Loss: 0.049364339313974555, Val Loss: 0.05665815288400032\n",
      "Epoch 342/500, Train Loss: 0.04935501983483152, Val Loss: 0.05677127451402544\n",
      "Epoch 343/500, Train Loss: 0.049354838851328214, Val Loss: 0.05678614822859105\n",
      "Epoch 344/500, Train Loss: 0.04935491878369503, Val Loss: 0.056805746936602175\n",
      "Epoch 345/500, Train Loss: 0.049355059430905464, Val Loss: 0.056814140526510036\n",
      "Epoch 346/500, Train Loss: 0.04936029265181108, Val Loss: 0.05690526709837988\n",
      "Epoch 347/500, Train Loss: 0.04935663933553611, Val Loss: 0.05673093330662926\n",
      "Epoch 348/500, Train Loss: 0.04935619331362692, Val Loss: 0.05684703836386119\n",
      "Epoch 349/500, Train Loss: 0.049417995127660416, Val Loss: 0.05722279120340157\n",
      "Epoch 350/500, Train Loss: 0.049362232512261246, Val Loss: 0.056924962042892796\n",
      "Epoch 351/500, Train Loss: 0.04935703837900227, Val Loss: 0.05672480975380231\n",
      "Epoch 352/500, Train Loss: 0.049358378854807414, Val Loss: 0.05688236094865491\n",
      "Epoch 353/500, Train Loss: 0.04936212008106424, Val Loss: 0.05692388745508139\n",
      "Epoch 354/500, Train Loss: 0.0493565303599814, Val Loss: 0.05685367865941451\n",
      "Epoch 355/500, Train Loss: 0.04935517060493492, Val Loss: 0.05676462946610719\n",
      "Epoch 356/500, Train Loss: 0.049356318456607665, Val Loss: 0.05673639406233262\n",
      "Epoch 357/500, Train Loss: 0.04935488598333504, Val Loss: 0.05680295135664497\n",
      "Epoch 358/500, Train Loss: 0.04935708136319268, Val Loss: 0.056863316757803935\n",
      "Epoch 359/500, Train Loss: 0.04935606275199369, Val Loss: 0.056741210657715466\n",
      "Epoch 360/500, Train Loss: 0.04935623320530038, Val Loss: 0.05684785520195873\n",
      "Epoch 361/500, Train Loss: 0.04935639214886991, Val Loss: 0.05685103287089146\n",
      "Epoch 362/500, Train Loss: 0.04937517984222324, Val Loss: 0.056602883908729903\n",
      "Epoch 363/500, Train Loss: 0.049362798871089714, Val Loss: 0.05666867874592002\n",
      "Epoch 364/500, Train Loss: 0.04935647629634991, Val Loss: 0.056733631331080774\n",
      "Epoch 365/500, Train Loss: 0.04935568954060081, Val Loss: 0.05683540819787674\n",
      "Epoch 366/500, Train Loss: 0.049358050171400915, Val Loss: 0.056877887186044536\n",
      "Epoch 367/500, Train Loss: 0.04935615043336886, Val Loss: 0.056739499780515575\n",
      "Epoch 368/500, Train Loss: 0.04935596770695079, Val Loss: 0.05684213152582375\n",
      "Epoch 369/500, Train Loss: 0.04935826677608279, Val Loss: 0.056709007824630876\n",
      "Epoch 370/500, Train Loss: 0.049356194308191104, Val Loss: 0.05673866640637033\n",
      "Epoch 371/500, Train Loss: 0.049355784594441336, Val Loss: 0.056837805183944254\n",
      "Epoch 372/500, Train Loss: 0.04935483637349924, Val Loss: 0.05678666154236511\n",
      "Epoch 373/500, Train Loss: 0.04935622867991852, Val Loss: 0.05673802285470055\n",
      "Epoch 374/500, Train Loss: 0.049355078840908846, Val Loss: 0.056815050635298237\n",
      "Epoch 375/500, Train Loss: 0.049356763124263583, Val Loss: 0.056857893050734\n",
      "Epoch 376/500, Train Loss: 0.049355009828504326, Val Loss: 0.05681155282209087\n",
      "Epoch 377/500, Train Loss: 0.04935501510753189, Val Loss: 0.05677150300872341\n",
      "Epoch 378/500, Train Loss: 0.04936910604813332, Val Loss: 0.056630733864356214\n",
      "Epoch 379/500, Train Loss: 0.0493557683772865, Val Loss: 0.056837397345833256\n",
      "Epoch 380/500, Train Loss: 0.049356247902337946, Val Loss: 0.056848140911791516\n",
      "Epoch 381/500, Train Loss: 0.04938489722724227, Val Loss: 0.05707553831941981\n",
      "Epoch 382/500, Train Loss: 0.049369548966219104, Val Loss: 0.05698392235963687\n",
      "Epoch 383/500, Train Loss: 0.04935817465450941, Val Loss: 0.05671006463471317\n",
      "Epoch 384/500, Train Loss: 0.04938205091275071, Val Loss: 0.05657703348541175\n",
      "Epoch 385/500, Train Loss: 0.049358806657020804, Val Loss: 0.05688787039735819\n",
      "Epoch 386/500, Train Loss: 0.0493560885974861, Val Loss: 0.05684479097518556\n",
      "Epoch 387/500, Train Loss: 0.049364409053351946, Val Loss: 0.056657675552364443\n",
      "Epoch 388/500, Train Loss: 0.04935483911474783, Val Loss: 0.056796885088072735\n",
      "Epoch 389/500, Train Loss: 0.049356577436275195, Val Loss: 0.056854527688001186\n",
      "Epoch 390/500, Train Loss: 0.04935734783104386, Val Loss: 0.05672043585433935\n",
      "Epoch 391/500, Train Loss: 0.04935502479149032, Val Loss: 0.05677099542249868\n",
      "Epoch 392/500, Train Loss: 0.04935856270703961, Val Loss: 0.05670567001483471\n",
      "Epoch 393/500, Train Loss: 0.04935487464325122, Val Loss: 0.05678125550336304\n",
      "Epoch 394/500, Train Loss: 0.04935489957548945, Val Loss: 0.05680414259161729\n",
      "Epoch 395/500, Train Loss: 0.049355585511537986, Val Loss: 0.05675185075302814\n",
      "Epoch 396/500, Train Loss: 0.049369142652972056, Val Loss: 0.05663053374527192\n",
      "Epoch 397/500, Train Loss: 0.04935493874581058, Val Loss: 0.056807159189559336\n",
      "Epoch 398/500, Train Loss: 0.04936469044782546, Val Loss: 0.05665585864890549\n",
      "Epoch 399/500, Train Loss: 0.04937715309655675, Val Loss: 0.056594939838506636\n",
      "Epoch 400/500, Train Loss: 0.04935934837211423, Val Loss: 0.0566974859073352\n",
      "Epoch 401/500, Train Loss: 0.049355458723229155, Val Loss: 0.05682894672183126\n",
      "Epoch 402/500, Train Loss: 0.04935829295727955, Val Loss: 0.05688117011101777\n",
      "Epoch 403/500, Train Loss: 0.04935484206979975, Val Loss: 0.05678553164586953\n",
      "Epoch 404/500, Train Loss: 0.049358073617726185, Val Loss: 0.0567112347384062\n",
      "Epoch 405/500, Train Loss: 0.04936146800217685, Val Loss: 0.05691746623235408\n",
      "Epoch 406/500, Train Loss: 0.04935530768239627, Val Loss: 0.056824094019392646\n",
      "Epoch 407/500, Train Loss: 0.049359261833648055, Val Loss: 0.0568934405762663\n",
      "Epoch 408/500, Train Loss: 0.0493896324797809, Val Loss: 0.05709950602522259\n",
      "Epoch 409/500, Train Loss: 0.04936196530083743, Val Loss: 0.056922345766895574\n",
      "Epoch 410/500, Train Loss: 0.04935779657213593, Val Loss: 0.056874251497463064\n",
      "Epoch 411/500, Train Loss: 0.049362381615820634, Val Loss: 0.056926316212412106\n",
      "Epoch 412/500, Train Loss: 0.04936236314142892, Val Loss: 0.056671830133527716\n",
      "Epoch 413/500, Train Loss: 0.04935866380155517, Val Loss: 0.05688602076183986\n",
      "Epoch 414/500, Train Loss: 0.04936991288045132, Val Loss: 0.05698642974710452\n",
      "Epoch 415/500, Train Loss: 0.049371477722314816, Val Loss: 0.056997092237448053\n",
      "Epoch 416/500, Train Loss: 0.04935842706982292, Val Loss: 0.05688293659533668\n",
      "Epoch 417/500, Train Loss: 0.04935993305778357, Val Loss: 0.05690121709299129\n",
      "Epoch 418/500, Train Loss: 0.049365800445793, Val Loss: 0.05664898298874322\n",
      "Epoch 419/500, Train Loss: 0.04936730675708751, Val Loss: 0.056640297150518715\n",
      "Epoch 420/500, Train Loss: 0.04935504403048216, Val Loss: 0.056770016269290624\n",
      "Epoch 421/500, Train Loss: 0.04935761376161704, Val Loss: 0.05687155632562314\n",
      "Epoch 422/500, Train Loss: 0.0493598957148891, Val Loss: 0.056692219970115455\n",
      "Epoch 423/500, Train Loss: 0.04936011893345718, Val Loss: 0.05690328047334934\n",
      "Epoch 424/500, Train Loss: 0.04936952273402326, Val Loss: 0.05698368054897997\n",
      "Epoch 425/500, Train Loss: 0.04939896810301996, Val Loss: 0.057143278021055254\n",
      "Epoch 426/500, Train Loss: 0.0493582051505735, Val Loss: 0.05687994631811787\n",
      "Epoch 427/500, Train Loss: 0.04935624648273945, Val Loss: 0.05673764438354739\n",
      "Epoch 428/500, Train Loss: 0.04935876331963565, Val Loss: 0.05688726324746673\n",
      "Epoch 429/500, Train Loss: 0.04935804425682105, Val Loss: 0.056711554486831364\n",
      "Epoch 430/500, Train Loss: 0.049355140583644666, Val Loss: 0.056765753558493046\n",
      "Epoch 431/500, Train Loss: 0.04935785735364228, Val Loss: 0.056713813348723593\n",
      "Epoch 432/500, Train Loss: 0.049368416113661065, Val Loss: 0.05663427300359786\n",
      "Epoch 433/500, Train Loss: 0.049356909080069594, Val Loss: 0.056726653576620614\n",
      "Epoch 434/500, Train Loss: 0.04935490963320872, Val Loss: 0.05680489792498638\n",
      "Epoch 435/500, Train Loss: 0.049355621368760996, Val Loss: 0.05683351314759838\n",
      "Epoch 436/500, Train Loss: 0.049356129854697686, Val Loss: 0.0567398294933553\n",
      "Epoch 437/500, Train Loss: 0.04935846097796517, Val Loss: 0.05688334275716525\n",
      "Epoch 438/500, Train Loss: 0.04935484258993448, Val Loss: 0.05678545474348642\n",
      "Epoch 439/500, Train Loss: 0.049354837838827964, Val Loss: 0.05678637745814559\n",
      "Epoch 440/500, Train Loss: 0.049355019861042654, Val Loss: 0.056771205654940766\n",
      "Epoch 441/500, Train Loss: 0.04935503981601278, Val Loss: 0.0567702007171569\n",
      "Epoch 442/500, Train Loss: 0.04936849958073411, Val Loss: 0.05663381739628389\n",
      "Epoch 443/500, Train Loss: 0.04935700875671733, Val Loss: 0.056725156611992136\n",
      "Epoch 444/500, Train Loss: 0.04937693619860892, Val Loss: 0.05659573556382007\n",
      "Epoch 445/500, Train Loss: 0.0493613891240916, Val Loss: 0.05667930931790549\n",
      "Epoch 446/500, Train Loss: 0.049355347962088604, Val Loss: 0.05682536519966896\n",
      "Epoch 447/500, Train Loss: 0.049363880790903945, Val Loss: 0.05693979910861079\n",
      "Epoch 448/500, Train Loss: 0.04936657272659941, Val Loss: 0.05696185757898142\n",
      "Epoch 449/500, Train Loss: 0.04935482808141764, Val Loss: 0.056789388521049505\n",
      "Epoch 450/500, Train Loss: 0.049355192845989874, Val Loss: 0.056819786210732894\n",
      "Epoch 451/500, Train Loss: 0.04935618460575195, Val Loss: 0.05673875975769112\n",
      "Epoch 452/500, Train Loss: 0.04935621193971716, Val Loss: 0.05684727459923742\n",
      "Epoch 453/500, Train Loss: 0.049362275717931864, Val Loss: 0.05692522183022387\n",
      "Epoch 454/500, Train Loss: 0.04935490820239262, Val Loss: 0.056778202425300905\n",
      "Epoch 455/500, Train Loss: 0.04935598359304156, Val Loss: 0.056742704600114685\n",
      "Epoch 456/500, Train Loss: 0.049357333605667984, Val Loss: 0.05672054076572062\n",
      "Epoch 457/500, Train Loss: 0.04935852509555455, Val Loss: 0.05688412347490075\n",
      "Epoch 458/500, Train Loss: 0.04935518171693911, Val Loss: 0.056764111246886746\n",
      "Epoch 459/500, Train Loss: 0.04936810344922971, Val Loss: 0.05663588600030893\n",
      "Epoch 460/500, Train Loss: 0.04937591175989411, Val Loss: 0.05659978399692934\n",
      "Epoch 461/500, Train Loss: 0.049354880397311035, Val Loss: 0.056780662560863275\n",
      "Epoch 462/500, Train Loss: 0.04935491058928613, Val Loss: 0.05680484469213348\n",
      "Epoch 463/500, Train Loss: 0.0493862714649835, Val Loss: 0.056563098433910615\n",
      "Epoch 464/500, Train Loss: 0.04936818953476676, Val Loss: 0.05663541355066647\n",
      "Epoch 465/500, Train Loss: 0.049355111388470964, Val Loss: 0.056766914312624144\n",
      "Epoch 466/500, Train Loss: 0.04936007831987314, Val Loss: 0.05669045861638388\n",
      "Epoch 467/500, Train Loss: 0.04935489894654992, Val Loss: 0.05680382996276305\n",
      "Epoch 468/500, Train Loss: 0.049374341003005445, Val Loss: 0.05660626701590706\n",
      "Epoch 469/500, Train Loss: 0.049355165709495594, Val Loss: 0.056818610249128945\n",
      "Epoch 470/500, Train Loss: 0.04935482725250667, Val Loss: 0.0567906783351449\n",
      "Epoch 471/500, Train Loss: 0.04935705262876716, Val Loss: 0.056862622656670296\n",
      "Epoch 472/500, Train Loss: 0.049355039483284575, Val Loss: 0.05677018351074091\n",
      "Epoch 473/500, Train Loss: 0.049357368286268105, Val Loss: 0.05672002633938403\n",
      "Epoch 474/500, Train Loss: 0.04935997539813993, Val Loss: 0.05690151994333845\n",
      "Epoch 475/500, Train Loss: 0.049358342799124655, Val Loss: 0.05688163714526329\n",
      "Epoch 476/500, Train Loss: 0.049354883746047885, Val Loss: 0.05678036092109639\n",
      "Epoch 477/500, Train Loss: 0.04935549414979123, Val Loss: 0.05675414453772838\n",
      "Epoch 478/500, Train Loss: 0.04937087609151571, Val Loss: 0.05662181955410217\n",
      "Epoch 479/500, Train Loss: 0.049359704702814, Val Loss: 0.05669388922954547\n",
      "Epoch 480/500, Train Loss: 0.04935625191962358, Val Loss: 0.05673743481717594\n",
      "Epoch 481/500, Train Loss: 0.04935484174550866, Val Loss: 0.05678582587224654\n",
      "Epoch 482/500, Train Loss: 0.049362057877102725, Val Loss: 0.05667398030022131\n",
      "Epoch 483/500, Train Loss: 0.04935484754560963, Val Loss: 0.05679774201732424\n",
      "Epoch 484/500, Train Loss: 0.04935484564613838, Val Loss: 0.05678514533115091\n",
      "Epoch 485/500, Train Loss: 0.04936974096456478, Val Loss: 0.0569849805838019\n",
      "Epoch 486/500, Train Loss: 0.049358600423635775, Val Loss: 0.05670507875837976\n",
      "Epoch 487/500, Train Loss: 0.049362665096919264, Val Loss: 0.056669444055988026\n",
      "Epoch 488/500, Train Loss: 0.04935888641225649, Val Loss: 0.05670200958323234\n",
      "Epoch 489/500, Train Loss: 0.04936656664422232, Val Loss: 0.05664431699397115\n",
      "Epoch 490/500, Train Loss: 0.04935519681774503, Val Loss: 0.05681967353320084\n",
      "Epoch 491/500, Train Loss: 0.04935689974641552, Val Loss: 0.05672664877882031\n",
      "Epoch 492/500, Train Loss: 0.04936299971363362, Val Loss: 0.05693173306119764\n",
      "Epoch 493/500, Train Loss: 0.04936214994311573, Val Loss: 0.05667323488853301\n",
      "Epoch 494/500, Train Loss: 0.04935640323619821, Val Loss: 0.05685085318882527\n",
      "Epoch 495/500, Train Loss: 0.04935487035974285, Val Loss: 0.05678187766193586\n",
      "Epoch 496/500, Train Loss: 0.04936500648816567, Val Loss: 0.056653642030745334\n",
      "Epoch 497/500, Train Loss: 0.04935613328108346, Val Loss: 0.05684533322368005\n",
      "Epoch 498/500, Train Loss: 0.049355622379591964, Val Loss: 0.056750741263666686\n",
      "Epoch 499/500, Train Loss: 0.04936698564871337, Val Loss: 0.05664187933569897\n",
      "Epoch 500/500, Train Loss: 0.04935647038620055, Val Loss: 0.056852077534294276\n",
      "Returning from fit...\n",
      "Train Losses: [np.float64(0.0639929183445628), np.float64(0.05046678934046366), np.float64(0.049415936939686274), np.float64(0.04936720782809739), np.float64(0.049366467354566144), np.float64(0.04936083724172939), np.float64(0.04937092875575869), np.float64(0.04936142890427024), np.float64(0.049358822179247225), np.float64(0.04936502451764442), np.float64(0.049355670441793904), np.float64(0.049357320835724694), np.float64(0.04935553006848183), np.float64(0.04935931290976948), np.float64(0.049358754740046924), np.float64(0.04935630658689725), np.float64(0.04935599549643143), np.float64(0.04935531748520297), np.float64(0.04935518005740646), np.float64(0.04937041358805185), np.float64(0.04940523184166265), np.float64(0.04935486586008528), np.float64(0.049358192192623045), np.float64(0.04936222358577332), np.float64(0.04935486142455777), np.float64(0.049362863581836544), np.float64(0.049358060384888366), np.float64(0.049359762607911896), np.float64(0.04935566824653967), np.float64(0.0493591598594503), np.float64(0.0493914721360873), np.float64(0.049359133685308434), np.float64(0.04936201673463574), np.float64(0.049359120014350735), np.float64(0.049368158631801114), np.float64(0.0493566683075246), np.float64(0.049354829006518657), np.float64(0.04935483141421318), np.float64(0.049354927636194784), np.float64(0.049359846858735096), np.float64(0.0493581589909414), np.float64(0.04935908021566186), np.float64(0.04936336871213634), np.float64(0.04935940622883698), np.float64(0.04935499125845621), np.float64(0.04935540403903932), np.float64(0.049354956583647844), np.float64(0.04935664335142234), np.float64(0.04935846645472453), np.float64(0.0493570976686334), np.float64(0.04935483615563818), np.float64(0.049357456530170866), np.float64(0.0493550263540901), np.float64(0.049366105448026616), np.float64(0.04935869746812529), np.float64(0.04935763416333371), np.float64(0.04936728308857624), np.float64(0.04935785736819253), np.float64(0.04935749795374198), np.float64(0.04935506269179585), np.float64(0.04936243101683276), np.float64(0.04935692506101293), np.float64(0.04935528361037179), np.float64(0.049358725424649565), np.float64(0.049355066553021444), np.float64(0.049355267831138916), np.float64(0.04935705872210239), np.float64(0.04935503719940403), np.float64(0.04936174608601111), np.float64(0.04935725672749541), np.float64(0.0493607265718323), np.float64(0.049361238215608644), np.float64(0.0493591144628497), np.float64(0.04936082544091414), np.float64(0.049355030050294346), np.float64(0.04935502952513701), np.float64(0.04935568330262335), np.float64(0.04935567488381632), np.float64(0.049358870676684326), np.float64(0.049355478096363425), np.float64(0.049354845590205795), np.float64(0.049358499463090164), np.float64(0.049355181094803816), np.float64(0.04936747212659011), np.float64(0.049360884531368436), np.float64(0.049354825477585546), np.float64(0.04936910262550552), np.float64(0.04935614367289649), np.float64(0.04936014827890534), np.float64(0.049358696546852696), np.float64(0.049355074439185256), np.float64(0.049355715523762035), np.float64(0.04935620073764024), np.float64(0.0493639041961932), np.float64(0.049354863083259023), np.float64(0.049359756312982374), np.float64(0.049354931179223266), np.float64(0.04937181071634662), np.float64(0.04935736740463488), np.float64(0.0493552221810391), np.float64(0.04938862762288041), np.float64(0.04936645775409173), np.float64(0.049354921276583356), np.float64(0.049368378376140366), np.float64(0.04935493524159966), np.float64(0.04935956314655975), np.float64(0.04936236421217356), np.float64(0.04935539979008756), np.float64(0.04935683407190089), np.float64(0.049355047290389614), np.float64(0.0493585493522308), np.float64(0.049356198361312435), np.float64(0.0493592860703553), np.float64(0.04936887270470661), np.float64(0.049356076291397565), np.float64(0.04935826479161179), np.float64(0.049355132725957124), np.float64(0.04935539298966605), np.float64(0.049355189142565085), np.float64(0.049355244629074854), np.float64(0.0493567850765476), np.float64(0.049370621676248574), np.float64(0.04935835491797969), np.float64(0.04935746214480264), np.float64(0.04935513154231007), np.float64(0.04935537031474656), np.float64(0.04936052089991558), np.float64(0.049361177413431066), np.float64(0.049359536081497735), np.float64(0.049355719120434724), np.float64(0.049356803434571966), np.float64(0.04935600045441624), np.float64(0.04935483389403453), np.float64(0.049355052239362325), np.float64(0.04935538882422328), np.float64(0.04935676980889394), np.float64(0.04937153790551571), np.float64(0.049356427923001676), np.float64(0.04935913516080372), np.float64(0.049356911383478703), np.float64(0.04935509199485332), np.float64(0.04935790510580287), np.float64(0.04935483301545124), np.float64(0.04935611797798299), np.float64(0.049363714232965004), np.float64(0.04936473586416496), np.float64(0.04935964937682679), np.float64(0.04936062319080871), np.float64(0.04935653429158534), np.float64(0.04935482553206036), np.float64(0.04935776269417678), np.float64(0.04935589176688671), np.float64(0.04935613324393466), np.float64(0.04935962399104993), np.float64(0.04935506981016385), np.float64(0.049357239294099686), np.float64(0.04935489522161165), np.float64(0.04935482903591477), np.float64(0.04935525053714294), np.float64(0.04936008658163317), np.float64(0.04937185354854949), np.float64(0.04939265881871892), np.float64(0.04935510767952036), np.float64(0.04935900498625454), np.float64(0.049356911442823954), np.float64(0.049360235990972286), np.float64(0.049362339142465725), np.float64(0.0493640968464302), np.float64(0.04935724582015966), np.float64(0.04936453048185876), np.float64(0.04935689350561078), np.float64(0.04935629488485968), np.float64(0.049363015685128776), np.float64(0.049355172250101075), np.float64(0.049361365018335185), np.float64(0.049364830456322374), np.float64(0.049357405457534434), np.float64(0.049355015923064946), np.float64(0.04936104915537338), np.float64(0.049354962962767084), np.float64(0.049369050066069946), np.float64(0.04935841716744795), np.float64(0.049355404407891185), np.float64(0.049367110579094486), np.float64(0.04935526728629075), np.float64(0.049362891356540525), np.float64(0.04935486621088571), np.float64(0.049356741509195626), np.float64(0.04935575500563455), np.float64(0.049354827437769797), np.float64(0.04935549380758972), np.float64(0.04935483520715664), np.float64(0.049358255603959685), np.float64(0.04935486708792386), np.float64(0.049355592052495345), np.float64(0.049357994757822404), np.float64(0.04935833268500021), np.float64(0.04936168943765638), np.float64(0.04935559711594453), np.float64(0.04935553786119492), np.float64(0.04936476250859569), np.float64(0.04935623761065111), np.float64(0.04935632002619031), np.float64(0.04935541881456002), np.float64(0.04936369638636814), np.float64(0.04935798589264275), np.float64(0.04936217965202861), np.float64(0.04935954490351145), np.float64(0.049371439118551984), np.float64(0.04935834541258548), np.float64(0.04935504169209632), np.float64(0.0493597702594609), np.float64(0.04935997016326063), np.float64(0.04935988451587813), np.float64(0.049356901044020025), np.float64(0.049357123686318394), np.float64(0.04935503479983917), np.float64(0.04935689623142109), np.float64(0.04935508395776265), np.float64(0.04936685567387156), np.float64(0.04935820404645188), np.float64(0.04936762642399191), np.float64(0.049358654673675034), np.float64(0.04936031873432607), np.float64(0.049381306694627584), np.float64(0.04935947109358789), np.float64(0.049377768729591105), np.float64(0.04936795515660934), np.float64(0.04935769844981727), np.float64(0.04935614355174046), np.float64(0.04938099968868004), np.float64(0.04936302426994296), np.float64(0.049354911537629824), np.float64(0.04935487677179937), np.float64(0.04935508477436794), np.float64(0.04935864003294265), np.float64(0.049362562484663315), np.float64(0.049355669627465855), np.float64(0.049356683539354795), np.float64(0.049356268556537755), np.float64(0.049354825505179695), np.float64(0.04935860338932988), np.float64(0.04935489949947677), np.float64(0.04937278566797318), np.float64(0.04935671412804999), np.float64(0.04935667731221287), np.float64(0.04938275596165816), np.float64(0.049389571805271176), np.float64(0.04935826753917339), np.float64(0.049356910475710086), np.float64(0.0493548421942003), np.float64(0.049355964638285926), np.float64(0.04935863325608476), np.float64(0.049355357690238695), np.float64(0.049373292600975595), np.float64(0.04935511652787336), np.float64(0.04936203592716163), np.float64(0.049365765303779924), np.float64(0.04936158879790166), np.float64(0.049363068587544925), np.float64(0.04936328960853805), np.float64(0.04935563007359316), np.float64(0.04936258226857877), np.float64(0.049358764977615224), np.float64(0.049357396215427285), np.float64(0.049359341693019344), np.float64(0.04935790924461399), np.float64(0.04935580734384613), np.float64(0.0493563995618781), np.float64(0.049362756360919316), np.float64(0.049363830578106394), np.float64(0.04936252136421231), np.float64(0.04935499613318847), np.float64(0.04937051480019659), np.float64(0.0493549259408502), np.float64(0.04936169138604754), np.float64(0.049367993923399495), np.float64(0.049363572767303056), np.float64(0.04935494887275446), np.float64(0.049359116551775155), np.float64(0.04935629141278279), np.float64(0.049354956640823955), np.float64(0.049356697673576665), np.float64(0.04936878433051966), np.float64(0.04935494939650286), np.float64(0.049355140566824975), np.float64(0.04935505476608012), np.float64(0.04935725662649288), np.float64(0.04936552479032336), np.float64(0.04937090544960794), np.float64(0.04935642920453695), np.float64(0.04935829067434103), np.float64(0.049379275855326095), np.float64(0.04940466900913058), np.float64(0.04935560352191658), np.float64(0.0493591620694668), np.float64(0.0493644494096681), np.float64(0.04935586309502064), np.float64(0.049357838838102165), np.float64(0.049357434444726504), np.float64(0.0493569847652282), np.float64(0.04935552033442675), np.float64(0.04935900255559655), np.float64(0.049356430451385665), np.float64(0.049354846097422654), np.float64(0.04935485037064754), np.float64(0.049356506771967734), np.float64(0.04935514482053621), np.float64(0.04936178048699934), np.float64(0.04936101129942141), np.float64(0.049355922890799014), np.float64(0.049364298580555445), np.float64(0.049355420552582706), np.float64(0.04935533391803768), np.float64(0.049356256880890896), np.float64(0.049354846889954535), np.float64(0.04935569447950219), np.float64(0.04935538521557523), np.float64(0.049382582419904744), np.float64(0.04935762914351101), np.float64(0.049356580878974654), np.float64(0.04935557476176851), np.float64(0.0493548600175512), np.float64(0.04935961209382077), np.float64(0.04935797327893592), np.float64(0.04935490146163027), np.float64(0.049358364241647974), np.float64(0.04935505388751041), np.float64(0.04935577544180428), np.float64(0.04935624526837566), np.float64(0.049356684792011295), np.float64(0.04935523250821311), np.float64(0.04935578480197817), np.float64(0.04935741030626827), np.float64(0.04938020109152961), np.float64(0.049358435726992965), np.float64(0.049355378874668156), np.float64(0.04935542812419671), np.float64(0.04935777066802002), np.float64(0.04935651020736188), np.float64(0.049364339313974555), np.float64(0.04935501983483152), np.float64(0.049354838851328214), np.float64(0.04935491878369503), np.float64(0.049355059430905464), np.float64(0.04936029265181108), np.float64(0.04935663933553611), np.float64(0.04935619331362692), np.float64(0.049417995127660416), np.float64(0.049362232512261246), np.float64(0.04935703837900227), np.float64(0.049358378854807414), np.float64(0.04936212008106424), np.float64(0.0493565303599814), np.float64(0.04935517060493492), np.float64(0.049356318456607665), np.float64(0.04935488598333504), np.float64(0.04935708136319268), np.float64(0.04935606275199369), np.float64(0.04935623320530038), np.float64(0.04935639214886991), np.float64(0.04937517984222324), np.float64(0.049362798871089714), np.float64(0.04935647629634991), np.float64(0.04935568954060081), np.float64(0.049358050171400915), np.float64(0.04935615043336886), np.float64(0.04935596770695079), np.float64(0.04935826677608279), np.float64(0.049356194308191104), np.float64(0.049355784594441336), np.float64(0.04935483637349924), np.float64(0.04935622867991852), np.float64(0.049355078840908846), np.float64(0.049356763124263583), np.float64(0.049355009828504326), np.float64(0.04935501510753189), np.float64(0.04936910604813332), np.float64(0.0493557683772865), np.float64(0.049356247902337946), np.float64(0.04938489722724227), np.float64(0.049369548966219104), np.float64(0.04935817465450941), np.float64(0.04938205091275071), np.float64(0.049358806657020804), np.float64(0.0493560885974861), np.float64(0.049364409053351946), np.float64(0.04935483911474783), np.float64(0.049356577436275195), np.float64(0.04935734783104386), np.float64(0.04935502479149032), np.float64(0.04935856270703961), np.float64(0.04935487464325122), np.float64(0.04935489957548945), np.float64(0.049355585511537986), np.float64(0.049369142652972056), np.float64(0.04935493874581058), np.float64(0.04936469044782546), np.float64(0.04937715309655675), np.float64(0.04935934837211423), np.float64(0.049355458723229155), np.float64(0.04935829295727955), np.float64(0.04935484206979975), np.float64(0.049358073617726185), np.float64(0.04936146800217685), np.float64(0.04935530768239627), np.float64(0.049359261833648055), np.float64(0.0493896324797809), np.float64(0.04936196530083743), np.float64(0.04935779657213593), np.float64(0.049362381615820634), np.float64(0.04936236314142892), np.float64(0.04935866380155517), np.float64(0.04936991288045132), np.float64(0.049371477722314816), np.float64(0.04935842706982292), np.float64(0.04935993305778357), np.float64(0.049365800445793), np.float64(0.04936730675708751), np.float64(0.04935504403048216), np.float64(0.04935761376161704), np.float64(0.0493598957148891), np.float64(0.04936011893345718), np.float64(0.04936952273402326), np.float64(0.04939896810301996), np.float64(0.0493582051505735), np.float64(0.04935624648273945), np.float64(0.04935876331963565), np.float64(0.04935804425682105), np.float64(0.049355140583644666), np.float64(0.04935785735364228), np.float64(0.049368416113661065), np.float64(0.049356909080069594), np.float64(0.04935490963320872), np.float64(0.049355621368760996), np.float64(0.049356129854697686), np.float64(0.04935846097796517), np.float64(0.04935484258993448), np.float64(0.049354837838827964), np.float64(0.049355019861042654), np.float64(0.04935503981601278), np.float64(0.04936849958073411), np.float64(0.04935700875671733), np.float64(0.04937693619860892), np.float64(0.0493613891240916), np.float64(0.049355347962088604), np.float64(0.049363880790903945), np.float64(0.04936657272659941), np.float64(0.04935482808141764), np.float64(0.049355192845989874), np.float64(0.04935618460575195), np.float64(0.04935621193971716), np.float64(0.049362275717931864), np.float64(0.04935490820239262), np.float64(0.04935598359304156), np.float64(0.049357333605667984), np.float64(0.04935852509555455), np.float64(0.04935518171693911), np.float64(0.04936810344922971), np.float64(0.04937591175989411), np.float64(0.049354880397311035), np.float64(0.04935491058928613), np.float64(0.0493862714649835), np.float64(0.04936818953476676), np.float64(0.049355111388470964), np.float64(0.04936007831987314), np.float64(0.04935489894654992), np.float64(0.049374341003005445), np.float64(0.049355165709495594), np.float64(0.04935482725250667), np.float64(0.04935705262876716), np.float64(0.049355039483284575), np.float64(0.049357368286268105), np.float64(0.04935997539813993), np.float64(0.049358342799124655), np.float64(0.049354883746047885), np.float64(0.04935549414979123), np.float64(0.04937087609151571), np.float64(0.049359704702814), np.float64(0.04935625191962358), np.float64(0.04935484174550866), np.float64(0.049362057877102725), np.float64(0.04935484754560963), np.float64(0.04935484564613838), np.float64(0.04936974096456478), np.float64(0.049358600423635775), np.float64(0.049362665096919264), np.float64(0.04935888641225649), np.float64(0.04936656664422232), np.float64(0.04935519681774503), np.float64(0.04935689974641552), np.float64(0.04936299971363362), np.float64(0.04936214994311573), np.float64(0.04935640323619821), np.float64(0.04935487035974285), np.float64(0.04936500648816567), np.float64(0.04935613328108346), np.float64(0.049355622379591964), np.float64(0.04936698564871337), np.float64(0.04935647038620055)]\n",
      "Validation Losses: [np.float64(0.06582557291509679), np.float64(0.056358944660188294), np.float64(0.056490562185078204), np.float64(0.056640936360414826), np.float64(0.05664514448646339), np.float64(0.05668398644387469), np.float64(0.05662177420730601), np.float64(0.05667912060847719), np.float64(0.05688814316529349), np.float64(0.05694966940531852), np.float64(0.056749809678651376), np.float64(0.05672086973171263), np.float64(0.05675336618808008), np.float64(0.056697910727365804), np.float64(0.056703657375986476), np.float64(0.05684939892053338), np.float64(0.05674261025240217), np.float64(0.05675954335261531), np.float64(0.056819485268570766), np.float64(0.056990009691945155), np.float64(0.05717080537736967), np.float64(0.05678226401932395), np.float64(0.05687990198730367), np.float64(0.05667295630220473), np.float64(0.05678278477020823), np.float64(0.056930905508783845), np.float64(0.05687808980034274), np.float64(0.05669356103943832), np.float64(0.05683491223104031), np.float64(0.05689231271150159), np.float64(0.05710859112851832), np.float64(0.05689199486937275), np.float64(0.05692294834642049), np.float64(0.05689182847043659), np.float64(0.05663574446574686), np.float64(0.056730506622663664), np.float64(0.05678875233572309), np.float64(0.05679515299531605), np.float64(0.056806459223695455), np.float64(0.05669277053418113), np.float64(0.05671030723562458), np.float64(0.056891342593981625), np.float64(0.05666470122353293), np.float64(0.05689526134013542), np.float64(0.05681057562893571), np.float64(0.05682735779966526), np.float64(0.056774896332609855), np.float64(0.05685581509779035), np.float64(0.05688356927732336), np.float64(0.05672399390098128), np.float64(0.056786742785031624), np.float64(0.05671904127079439), np.float64(0.056812510348702557), np.float64(0.05695839016137102), np.float64(0.05688656077945682), np.float64(0.056871980649454555), np.float64(0.056967486683901114), np.float64(0.056713921689334514), np.float64(0.05671849334228909), np.float64(0.0567692157893446), np.float64(0.05692688931564394), np.float64(0.05686076085978432), np.float64(0.05676064635580531), np.float64(0.05688691681298974), np.float64(0.05676903665206323), np.float64(0.05676117503815502), np.float64(0.0568629976321426), np.float64(0.056770436324529196), np.float64(0.056676611021449955), np.float64(0.056721749874469915), np.float64(0.056684924092381545), np.float64(0.056915252306306625), np.float64(0.056699904607069376), np.float64(0.05691100164952858), np.float64(0.056770791722758875), np.float64(0.05677081805925512), np.float64(0.056835303644617065), np.float64(0.056835084161023), np.float64(0.056702426661460414), np.float64(0.05675477333586653), np.float64(0.05679815014481004), np.float64(0.05670643258127203), np.float64(0.05681952430172696), np.float64(0.056639468146570594), np.float64(0.05668358553289034), np.float64(0.05679104981237208), np.float64(0.056630801923259776), np.float64(0.056846042906802), np.float64(0.05669000046646445), np.float64(0.056704279190977855), np.float64(0.056814907754740754), np.float64(0.05674873103793097), np.float64(0.056847238564174195), np.float64(0.05694018498890146), np.float64(0.056782583865042), np.float64(0.05689932752177193), np.float64(0.05680671478902026), np.float64(0.056999422849603694), np.float64(0.0568679336852929), np.float64(0.05676276058286165), np.float64(0.056556046643243214), np.float64(0.056961150773147465), np.float64(0.056777292607507815), np.float64(0.05697561503808211), np.float64(0.05680700495682996), np.float64(0.0566954592173393), np.float64(0.05667190235240113), np.float64(0.056757010149288016), np.float64(0.05672790258533414), np.float64(0.05676994269189363), np.float64(0.056705880456546), np.float64(0.056847188228344815), np.float64(0.056893829065514157), np.float64(0.05663198586765295), np.float64(0.05684459713887297), np.float64(0.05670907857729364), np.float64(0.0568175274149399), np.float64(0.05682700541784509), np.float64(0.05681984121006708), np.float64(0.05676196805768055), np.float64(0.05672865851212609), np.float64(0.05699142934078303), np.float64(0.056708050140149124), np.float64(0.05671896372385301), np.float64(0.05681747625032188), np.float64(0.056757892245742673), np.float64(0.056686694165585715), np.float64(0.05668115337831558), np.float64(0.056695719367948205), np.float64(0.05683622299333796), np.float64(0.05672837330687304), np.float64(0.05684292532549705), np.float64(0.05678727071257603), np.float64(0.05681382890855767), np.float64(0.05682687190904457), np.float64(0.056858072638457456), np.float64(0.05699760815650811), np.float64(0.05673450598045605), np.float64(0.056892007401824346), np.float64(0.056860523951665416), np.float64(0.05681572320535604), np.float64(0.05687590479464494), np.float64(0.05678749556156162), np.float64(0.05684549303945226), np.float64(0.0566623319473606), np.float64(0.0569472655954106), np.float64(0.056898095932385366), np.float64(0.05690886628817055), np.float64(0.05685379844447686), np.float64(0.05679213638708424), np.float64(0.05687386013275257), np.float64(0.05684043689292624), np.float64(0.05673987499367363), np.float64(0.05689780194566246), np.float64(0.05676888213549943), np.float64(0.05672198745108353), np.float64(0.056803850185251574), np.float64(0.05678873572711538), np.float64(0.05676176092651283), np.float64(0.05690304213008096), np.float64(0.056999701546613185), np.float64(0.05711427305953307), np.float64(0.05681643071088261), np.float64(0.05670102264229012), np.float64(0.05672672428860765), np.float64(0.05668920720282796), np.float64(0.05667208557787395), np.float64(0.05665977231197026), np.float64(0.05672189587429048), np.float64(0.05694553928459852), np.float64(0.056860216355708905), np.float64(0.05684915581910441), np.float64(0.05693228560374318), np.float64(0.05676460347341444), np.float64(0.05667962669484312), np.float64(0.0566550318047128), np.float64(0.05671971649515854), np.float64(0.05677150767992366), np.float64(0.0569133139559903), np.float64(0.05680885540801756), np.float64(0.056631066950626516), np.float64(0.05670734461682052), np.float64(0.0568273613168012), np.float64(0.05696616957235308), np.float64(0.056822769174027093), np.float64(0.056931150121483365), np.float64(0.05678221568436698), np.float64(0.05672933527456062), np.float64(0.05674780577597558), np.float64(0.05678942995137386), np.float64(0.05675433451395527), np.float64(0.056786950527646186), np.float64(0.05688075172553584), np.float64(0.056801037623357066), np.float64(0.05683285849636707), np.float64(0.0567122441915134), np.float64(0.05670829729909414), np.float64(0.05691975062070423), np.float64(0.05683299686899892), np.float64(0.05675314972089996), np.float64(0.05665546025675949), np.float64(0.05673790252199213), np.float64(0.056736401515673406), np.float64(0.056827809333429534), np.float64(0.05693836151506156), np.float64(0.05671234987691481), np.float64(0.056924498489978125), np.float64(0.05689687803736534), np.float64(0.056996941688659326), np.float64(0.056708151670354943), np.float64(0.05681329277296622), np.float64(0.05669347905918007), np.float64(0.05690173837443388), np.float64(0.056692409967905005), np.float64(0.05672687653813274), np.float64(0.05672361126996103), np.float64(0.056812939127881615), np.float64(0.05672694878192177), np.float64(0.056768237316935526), np.float64(0.05696421708543796), np.float64(0.05688004969781506), np.float64(0.05663861206746456), np.float64(0.05670472242032041), np.float64(0.05690558621654219), np.float64(0.05705636798382706), np.float64(0.0566963427091797), np.float64(0.05659261265134337), np.float64(0.056972496322984935), np.float64(0.05671589375196162), np.float64(0.0568460285185056), np.float64(0.05705467437460704), np.float64(0.05693235667345192), np.float64(0.05677802046214771), np.float64(0.05680208308377448), np.float64(0.05676819902291484), np.float64(0.05670487958450348), np.float64(0.056928104864996894), np.float64(0.05683493302184753), np.float64(0.05685652658791313), np.float64(0.05684861618198787), np.float64(0.05679206353186869), np.float64(0.056705277607267776), np.float64(0.05677899238671087), np.float64(0.05661319382011269), np.float64(0.05672976130042077), np.float64(0.05685641332112585), np.float64(0.057064248250290814), np.float64(0.057099302645476954), np.float64(0.05670903573499789), np.float64(0.05686049650236152), np.float64(0.05678553779165319), np.float64(0.05684210570722163), np.float64(0.05670495096836414), np.float64(0.05682585378283875), np.float64(0.05661094840180625), np.float64(0.05681681117282456), np.float64(0.05692311366361651), np.float64(0.05695566708087564), np.float64(0.0566778320789293), np.float64(0.05666678531894408), np.float64(0.05693474628933602), np.float64(0.05683388086664068), np.float64(0.056928285039141734), np.float64(0.056703531002511104), np.float64(0.056868362610429414), np.float64(0.05669760801119067), np.float64(0.05671327000299822), np.float64(0.0567466084631796), np.float64(0.0568512130529859), np.float64(0.05692989702201408), np.float64(0.05693952438005827), np.float64(0.05692771446470099), np.float64(0.05677255518098656), np.float64(0.05662374753350349), np.float64(0.0568063125597752), np.float64(0.0566770217206761), np.float64(0.05663661020566533), np.float64(0.056663279988461115), np.float64(0.05680792338484151), np.float64(0.056891762540955064), np.float64(0.056849070434351556), np.float64(0.05680843450775928), np.float64(0.05685677212296307), np.float64(0.056978532531101814), np.float64(0.05677533447530696), np.float64(0.05681784010434182), np.float64(0.05681393403406379), np.float64(0.05672173098969588), np.float64(0.05665071392188653), np.float64(0.05662186526526813), np.float64(0.05673446587627574), np.float64(0.0567087628972381), np.float64(0.05658693944275196), np.float64(0.056514357707021255), np.float64(0.056751439322596256), np.float64(0.05689231152145489), np.float64(0.05694483302085707), np.float64(0.05674537297424649), np.float64(0.05687493633774702), np.float64(0.05671931151305916), np.float64(0.05672561360107048), np.float64(0.05675360007617728), np.float64(0.05689035930770932), np.float64(0.056851802419485085), np.float64(0.05679820211173631), np.float64(0.056784220723012854), np.float64(0.05673313773807118), np.float64(0.056765657059382385), np.float64(0.056920621823654066), np.float64(0.05691289979372169), np.float64(0.05684113516141439), np.float64(0.05694354621535003), np.float64(0.05675637656748555), np.float64(0.05682505162723142), np.float64(0.056848361427637925), np.float64(0.05679832463300334), np.float64(0.05683556102467046), np.float64(0.05675741670200704), np.float64(0.05706329166188456), np.float64(0.05687187099449555), np.float64(0.05673189827652115), np.float64(0.056752164997708424), np.float64(0.05680016237774518), np.float64(0.05669496067213487), np.float64(0.05671247966030516), np.float64(0.056778811739410656), np.float64(0.056707916049491415), np.float64(0.05681387656318549), np.float64(0.0567473125728498), np.float64(0.056737736584953985), np.float64(0.05685652482147197), np.float64(0.056821466451407954), np.float64(0.05683783308358996), np.float64(0.05686855827725279), np.float64(0.05705020139590841), np.float64(0.056883122364666125), np.float64(0.05682651590240627), np.float64(0.056828065097811443), np.float64(0.0568739376594558), np.float64(0.05673306854051155), np.float64(0.05665815288400032), np.float64(0.05677127451402544), np.float64(0.05678614822859105), np.float64(0.056805746936602175), np.float64(0.056814140526510036), np.float64(0.05690526709837988), np.float64(0.05673093330662926), np.float64(0.05684703836386119), np.float64(0.05722279120340157), np.float64(0.056924962042892796), np.float64(0.05672480975380231), np.float64(0.05688236094865491), np.float64(0.05692388745508139), np.float64(0.05685367865941451), np.float64(0.05676462946610719), np.float64(0.05673639406233262), np.float64(0.05680295135664497), np.float64(0.056863316757803935), np.float64(0.056741210657715466), np.float64(0.05684785520195873), np.float64(0.05685103287089146), np.float64(0.056602883908729903), np.float64(0.05666867874592002), np.float64(0.056733631331080774), np.float64(0.05683540819787674), np.float64(0.056877887186044536), np.float64(0.056739499780515575), np.float64(0.05684213152582375), np.float64(0.056709007824630876), np.float64(0.05673866640637033), np.float64(0.056837805183944254), np.float64(0.05678666154236511), np.float64(0.05673802285470055), np.float64(0.056815050635298237), np.float64(0.056857893050734), np.float64(0.05681155282209087), np.float64(0.05677150300872341), np.float64(0.056630733864356214), np.float64(0.056837397345833256), np.float64(0.056848140911791516), np.float64(0.05707553831941981), np.float64(0.05698392235963687), np.float64(0.05671006463471317), np.float64(0.05657703348541175), np.float64(0.05688787039735819), np.float64(0.05684479097518556), np.float64(0.056657675552364443), np.float64(0.056796885088072735), np.float64(0.056854527688001186), np.float64(0.05672043585433935), np.float64(0.05677099542249868), np.float64(0.05670567001483471), np.float64(0.05678125550336304), np.float64(0.05680414259161729), np.float64(0.05675185075302814), np.float64(0.05663053374527192), np.float64(0.056807159189559336), np.float64(0.05665585864890549), np.float64(0.056594939838506636), np.float64(0.0566974859073352), np.float64(0.05682894672183126), np.float64(0.05688117011101777), np.float64(0.05678553164586953), np.float64(0.0567112347384062), np.float64(0.05691746623235408), np.float64(0.056824094019392646), np.float64(0.0568934405762663), np.float64(0.05709950602522259), np.float64(0.056922345766895574), np.float64(0.056874251497463064), np.float64(0.056926316212412106), np.float64(0.056671830133527716), np.float64(0.05688602076183986), np.float64(0.05698642974710452), np.float64(0.056997092237448053), np.float64(0.05688293659533668), np.float64(0.05690121709299129), np.float64(0.05664898298874322), np.float64(0.056640297150518715), np.float64(0.056770016269290624), np.float64(0.05687155632562314), np.float64(0.056692219970115455), np.float64(0.05690328047334934), np.float64(0.05698368054897997), np.float64(0.057143278021055254), np.float64(0.05687994631811787), np.float64(0.05673764438354739), np.float64(0.05688726324746673), np.float64(0.056711554486831364), np.float64(0.056765753558493046), np.float64(0.056713813348723593), np.float64(0.05663427300359786), np.float64(0.056726653576620614), np.float64(0.05680489792498638), np.float64(0.05683351314759838), np.float64(0.0567398294933553), np.float64(0.05688334275716525), np.float64(0.05678545474348642), np.float64(0.05678637745814559), np.float64(0.056771205654940766), np.float64(0.0567702007171569), np.float64(0.05663381739628389), np.float64(0.056725156611992136), np.float64(0.05659573556382007), np.float64(0.05667930931790549), np.float64(0.05682536519966896), np.float64(0.05693979910861079), np.float64(0.05696185757898142), np.float64(0.056789388521049505), np.float64(0.056819786210732894), np.float64(0.05673875975769112), np.float64(0.05684727459923742), np.float64(0.05692522183022387), np.float64(0.056778202425300905), np.float64(0.056742704600114685), np.float64(0.05672054076572062), np.float64(0.05688412347490075), np.float64(0.056764111246886746), np.float64(0.05663588600030893), np.float64(0.05659978399692934), np.float64(0.056780662560863275), np.float64(0.05680484469213348), np.float64(0.056563098433910615), np.float64(0.05663541355066647), np.float64(0.056766914312624144), np.float64(0.05669045861638388), np.float64(0.05680382996276305), np.float64(0.05660626701590706), np.float64(0.056818610249128945), np.float64(0.0567906783351449), np.float64(0.056862622656670296), np.float64(0.05677018351074091), np.float64(0.05672002633938403), np.float64(0.05690151994333845), np.float64(0.05688163714526329), np.float64(0.05678036092109639), np.float64(0.05675414453772838), np.float64(0.05662181955410217), np.float64(0.05669388922954547), np.float64(0.05673743481717594), np.float64(0.05678582587224654), np.float64(0.05667398030022131), np.float64(0.05679774201732424), np.float64(0.05678514533115091), np.float64(0.0569849805838019), np.float64(0.05670507875837976), np.float64(0.056669444055988026), np.float64(0.05670200958323234), np.float64(0.05664431699397115), np.float64(0.05681967353320084), np.float64(0.05672664877882031), np.float64(0.05693173306119764), np.float64(0.05667323488853301), np.float64(0.05685085318882527), np.float64(0.05678187766193586), np.float64(0.056653642030745334), np.float64(0.05684533322368005), np.float64(0.056750741263666686), np.float64(0.05664187933569897), np.float64(0.056852077534294276)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
